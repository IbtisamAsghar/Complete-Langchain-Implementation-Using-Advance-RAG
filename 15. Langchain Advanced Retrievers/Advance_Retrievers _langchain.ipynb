{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98003a0665204053b29f62f940459ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8205c2f4ccb419fba633af699ad2505",
              "IPY_MODEL_e792158880d44c02874ca65af55d36bb",
              "IPY_MODEL_e88f90653f924033aa4c467906c1d142"
            ],
            "layout": "IPY_MODEL_4957cb329fb344f2ae1085b0543cdc92"
          }
        },
        "c8205c2f4ccb419fba633af699ad2505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d18c0e17b55a48539911fa7b3c5cb13b",
            "placeholder": "​",
            "style": "IPY_MODEL_18562dd744a14258a57b7b18680d7578",
            "value": "modules.json: 100%"
          }
        },
        "e792158880d44c02874ca65af55d36bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d16680442704c55ace12aae87f4cb46",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0b4bc7659614b579bec27ff881cf040",
            "value": 349
          }
        },
        "e88f90653f924033aa4c467906c1d142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79329a542ea43a79435a5ed2856e4e9",
            "placeholder": "​",
            "style": "IPY_MODEL_7e62125744de42e2a84ecf92514f7402",
            "value": " 349/349 [00:00&lt;00:00, 30.0kB/s]"
          }
        },
        "4957cb329fb344f2ae1085b0543cdc92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18c0e17b55a48539911fa7b3c5cb13b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18562dd744a14258a57b7b18680d7578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d16680442704c55ace12aae87f4cb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0b4bc7659614b579bec27ff881cf040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c79329a542ea43a79435a5ed2856e4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e62125744de42e2a84ecf92514f7402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5a7311aee29464cb38d7dd8e5e1694c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e64733bc623e4e3684bbdc94028efec0",
              "IPY_MODEL_1b07f98f2bb84c6083cd6410b85ebfd9",
              "IPY_MODEL_76a3d714f6a4455194ff9a2a6c3cc96d"
            ],
            "layout": "IPY_MODEL_deaf8dd424f34382bfc9d2ce4b4b7fe9"
          }
        },
        "e64733bc623e4e3684bbdc94028efec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd3bed2144e541beb18596d4c8461fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_82c57d4fe02f4572b3d508e5d9181483",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "1b07f98f2bb84c6083cd6410b85ebfd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f982e749f98544b38a8d313456d894a5",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dad22e02b6c5411ea99082952c2ed695",
            "value": 116
          }
        },
        "76a3d714f6a4455194ff9a2a6c3cc96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d955aa80d914e1f8a6a918e3523a65c",
            "placeholder": "​",
            "style": "IPY_MODEL_4d62c538fa2b4003b3629fd6cf0acf0a",
            "value": " 116/116 [00:00&lt;00:00, 8.41kB/s]"
          }
        },
        "deaf8dd424f34382bfc9d2ce4b4b7fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3bed2144e541beb18596d4c8461fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c57d4fe02f4572b3d508e5d9181483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f982e749f98544b38a8d313456d894a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad22e02b6c5411ea99082952c2ed695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d955aa80d914e1f8a6a918e3523a65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d62c538fa2b4003b3629fd6cf0acf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b60b0b0341874b6d8ccd45a087ee384b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a563b7e8ca044229987f735b4d867c3",
              "IPY_MODEL_093e71a09d324e9f8fdf90195f681042",
              "IPY_MODEL_8589882b9dfd4aabbda14caa6e6b940c"
            ],
            "layout": "IPY_MODEL_c9e4ae2961db4c94bb001f48d5985d44"
          }
        },
        "2a563b7e8ca044229987f735b4d867c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c596966af2174cf1927a42834e18cab5",
            "placeholder": "​",
            "style": "IPY_MODEL_3387141c7e2c495d9622c8acc43d1fb5",
            "value": "README.md: "
          }
        },
        "093e71a09d324e9f8fdf90195f681042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d403febedf7346c990ccf5db8f145a28",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ae224a7ebb4fb6bc96051f8cab0614",
            "value": 1
          }
        },
        "8589882b9dfd4aabbda14caa6e6b940c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517b19ae6f2a4d3c89e497e1a0f17783",
            "placeholder": "​",
            "style": "IPY_MODEL_64f8f61797a049588f753fedd4c7dfcb",
            "value": " 10.5k/? [00:00&lt;00:00, 582kB/s]"
          }
        },
        "c9e4ae2961db4c94bb001f48d5985d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c596966af2174cf1927a42834e18cab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3387141c7e2c495d9622c8acc43d1fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d403febedf7346c990ccf5db8f145a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a6ae224a7ebb4fb6bc96051f8cab0614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "517b19ae6f2a4d3c89e497e1a0f17783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f8f61797a049588f753fedd4c7dfcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ebb8d65ea449e0b2959a7ed79714d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1031d75f6e2494e9b29d66019748910",
              "IPY_MODEL_ec335d23db5d4714a9621606fab4bf13",
              "IPY_MODEL_521bdd106f0f4c9aa4a93f644262db47"
            ],
            "layout": "IPY_MODEL_5e25047f8d1a414294f6b1940f6ef5a3"
          }
        },
        "d1031d75f6e2494e9b29d66019748910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad80bbf3197470d9dc1d49c87c34570",
            "placeholder": "​",
            "style": "IPY_MODEL_687edd75aec942d4ba889ae3ad823314",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "ec335d23db5d4714a9621606fab4bf13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ab33b652224b0ca08f64518699fe71",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67920abcb8a74d91a906e3d77f9ae835",
            "value": 53
          }
        },
        "521bdd106f0f4c9aa4a93f644262db47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b82019801b4cabab89cb1e748e26f1",
            "placeholder": "​",
            "style": "IPY_MODEL_2a9899e0adb4453d9bfcd1f4e83e146f",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.64kB/s]"
          }
        },
        "5e25047f8d1a414294f6b1940f6ef5a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad80bbf3197470d9dc1d49c87c34570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687edd75aec942d4ba889ae3ad823314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ab33b652224b0ca08f64518699fe71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67920abcb8a74d91a906e3d77f9ae835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b82019801b4cabab89cb1e748e26f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9899e0adb4453d9bfcd1f4e83e146f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50d9dfc720c34d27893f32c123ae459c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21f29643538d4d0da5260054529c1692",
              "IPY_MODEL_b9537c96819b4bb7ac5875321e265168",
              "IPY_MODEL_940d2705add14931ac38bf628168d654"
            ],
            "layout": "IPY_MODEL_f24edd2ef4ae43e6b3a3914ec00e5e00"
          }
        },
        "21f29643538d4d0da5260054529c1692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21a3bfd9bc34c4192217ef26be4d859",
            "placeholder": "​",
            "style": "IPY_MODEL_4d4d19134bc044cb8cfbf21ce3751579",
            "value": "config.json: 100%"
          }
        },
        "b9537c96819b4bb7ac5875321e265168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea1b5d486f4475680708ef588cce942",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_711e0f9d12714e6184a5ebcce192e572",
            "value": 612
          }
        },
        "940d2705add14931ac38bf628168d654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44c8cab3eb98489b95e2d9d884aa01ce",
            "placeholder": "​",
            "style": "IPY_MODEL_6421f5e7484f4cd0b4245610b9fbfc96",
            "value": " 612/612 [00:00&lt;00:00, 52.8kB/s]"
          }
        },
        "f24edd2ef4ae43e6b3a3914ec00e5e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21a3bfd9bc34c4192217ef26be4d859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4d19134bc044cb8cfbf21ce3751579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dea1b5d486f4475680708ef588cce942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711e0f9d12714e6184a5ebcce192e572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44c8cab3eb98489b95e2d9d884aa01ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6421f5e7484f4cd0b4245610b9fbfc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0655951d8bf349dda8aa1b71441cffe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0069531ccd1a4d48a2eb625c0b329140",
              "IPY_MODEL_defb62266f1945149d9eb455e4b0dea4",
              "IPY_MODEL_994d62df10ca48cf883de5a94baeb2ea"
            ],
            "layout": "IPY_MODEL_cb1ca77fa5d3476fb7deabfb435662a3"
          }
        },
        "0069531ccd1a4d48a2eb625c0b329140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cbbae79c3074c77bae8d6faae55e814",
            "placeholder": "​",
            "style": "IPY_MODEL_0c203ea2f62446ce9fda647749b8dca0",
            "value": "model.safetensors: 100%"
          }
        },
        "defb62266f1945149d9eb455e4b0dea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7774f33754448369d428598b3f33bbf",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dde6fbe91b8f4ef2b5e4f45ad9f79a6b",
            "value": 90868376
          }
        },
        "994d62df10ca48cf883de5a94baeb2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bedd667c20644ada6519497d31a838e",
            "placeholder": "​",
            "style": "IPY_MODEL_a84c7400cf1646369f9c78021a1f778c",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 55.9MB/s]"
          }
        },
        "cb1ca77fa5d3476fb7deabfb435662a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbbae79c3074c77bae8d6faae55e814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c203ea2f62446ce9fda647749b8dca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7774f33754448369d428598b3f33bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde6fbe91b8f4ef2b5e4f45ad9f79a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bedd667c20644ada6519497d31a838e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84c7400cf1646369f9c78021a1f778c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "118c9a1a9e6145119d1bd3c2ba2e92d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b05589d8ddc043b9a2ecb7262ee8fb4f",
              "IPY_MODEL_337ad77f8c5e4784935df6215158a429",
              "IPY_MODEL_be56ec99e672412bac9e8315cbb24304"
            ],
            "layout": "IPY_MODEL_bb8977b07dd44417ba76df58dc8eb2d2"
          }
        },
        "b05589d8ddc043b9a2ecb7262ee8fb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2448492cb0f946e4b7234b16598eb4ce",
            "placeholder": "​",
            "style": "IPY_MODEL_a2c10328d32145f9b2c80ec706fa6910",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "337ad77f8c5e4784935df6215158a429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2130715787654f2998295b7064703406",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3c43ba37d4c43219f7753c7074285f0",
            "value": 350
          }
        },
        "be56ec99e672412bac9e8315cbb24304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75bac2cd9f4c4471a2ebb281b3135b91",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a3533115c0449f84cfaef7dd025612",
            "value": " 350/350 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "bb8977b07dd44417ba76df58dc8eb2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2448492cb0f946e4b7234b16598eb4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c10328d32145f9b2c80ec706fa6910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2130715787654f2998295b7064703406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c43ba37d4c43219f7753c7074285f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75bac2cd9f4c4471a2ebb281b3135b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a3533115c0449f84cfaef7dd025612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdc5efca36ed45848d6f2a77662c6dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6f35b036eee49afbcec7a81e9ac3bce",
              "IPY_MODEL_c42a4c11e3294194a40610e716f23712",
              "IPY_MODEL_53b47a66c47941bc902657fe180e5d1b"
            ],
            "layout": "IPY_MODEL_a23a39a904a84159b83f0a1b3d0c0095"
          }
        },
        "a6f35b036eee49afbcec7a81e9ac3bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa18f0dedf0946338fc3c204766208a8",
            "placeholder": "​",
            "style": "IPY_MODEL_13ebede809f146519ee47c258d709043",
            "value": "vocab.txt: "
          }
        },
        "c42a4c11e3294194a40610e716f23712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51aa7d194e8c462ba3ee1f5c7392330e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52f3a51d0d6b4a2caa954672028ed6ba",
            "value": 1
          }
        },
        "53b47a66c47941bc902657fe180e5d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f53f7757fc11455c98fa96a922342093",
            "placeholder": "​",
            "style": "IPY_MODEL_02ed82ddc4084da1b9775ca4b8908f88",
            "value": " 232k/? [00:00&lt;00:00, 5.64MB/s]"
          }
        },
        "a23a39a904a84159b83f0a1b3d0c0095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa18f0dedf0946338fc3c204766208a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ebede809f146519ee47c258d709043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51aa7d194e8c462ba3ee1f5c7392330e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52f3a51d0d6b4a2caa954672028ed6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f53f7757fc11455c98fa96a922342093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ed82ddc4084da1b9775ca4b8908f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d78498623309459c8f1609f5c399330c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a82bc873262c4800a12dc2f76003de85",
              "IPY_MODEL_f508b7103a43436bbfad401b9c1e2abc",
              "IPY_MODEL_3a8956954f5a4401b259d5ed274ac8b5"
            ],
            "layout": "IPY_MODEL_4a1f850d40f14708ac251fd842b96096"
          }
        },
        "a82bc873262c4800a12dc2f76003de85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33901fd2ea5446eaa3004065ca2d95be",
            "placeholder": "​",
            "style": "IPY_MODEL_5bf2f332fb6a4ab59df82c2844afdeb8",
            "value": "tokenizer.json: "
          }
        },
        "f508b7103a43436bbfad401b9c1e2abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fec490b30311474d945844c370c6e4b3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_212e5c2bead44da4a75bf76ef3b87d17",
            "value": 1
          }
        },
        "3a8956954f5a4401b259d5ed274ac8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5641c9bde1cf4a4d973e0d0fd8aba98b",
            "placeholder": "​",
            "style": "IPY_MODEL_bc576241ef264c27b6f2f5b2d4fc8969",
            "value": " 466k/? [00:00&lt;00:00, 17.9MB/s]"
          }
        },
        "4a1f850d40f14708ac251fd842b96096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33901fd2ea5446eaa3004065ca2d95be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf2f332fb6a4ab59df82c2844afdeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fec490b30311474d945844c370c6e4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "212e5c2bead44da4a75bf76ef3b87d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5641c9bde1cf4a4d973e0d0fd8aba98b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc576241ef264c27b6f2f5b2d4fc8969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ababfe4e00b64dec9f27a7a5f2d0dd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0c121033b014293ba26562087fefcf9",
              "IPY_MODEL_9903497b5261491c8ba47d8b81fc9b30",
              "IPY_MODEL_7e152540f205479780b5505ac6cf0840"
            ],
            "layout": "IPY_MODEL_3abfdc3f707a423aacaf4435ca07f83b"
          }
        },
        "a0c121033b014293ba26562087fefcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_304c83da5b55456992dc95b6146b4aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_a01903b99fa84f1f8a6c332a3f02503e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9903497b5261491c8ba47d8b81fc9b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95af1183bee84559aa398725906e0be7",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cebcdf1f69f4ce7bbc90c8b54ac2066",
            "value": 112
          }
        },
        "7e152540f205479780b5505ac6cf0840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e3150749b614133a38eb7e39540f220",
            "placeholder": "​",
            "style": "IPY_MODEL_09e5eeb34f5a44beaae4723807d1061d",
            "value": " 112/112 [00:00&lt;00:00, 8.15kB/s]"
          }
        },
        "3abfdc3f707a423aacaf4435ca07f83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304c83da5b55456992dc95b6146b4aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01903b99fa84f1f8a6c332a3f02503e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95af1183bee84559aa398725906e0be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cebcdf1f69f4ce7bbc90c8b54ac2066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e3150749b614133a38eb7e39540f220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e5eeb34f5a44beaae4723807d1061d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9f8f9fefc704e50af6f2b2393034ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dd52e5318d84bc8af92eded0dddf3d5",
              "IPY_MODEL_44ec8eb1875849c98c047876e1253a58",
              "IPY_MODEL_90d430596fd446f98470fbbb0f396a3a"
            ],
            "layout": "IPY_MODEL_e7384a73c2ce4542b00619817d0fe478"
          }
        },
        "0dd52e5318d84bc8af92eded0dddf3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a2c8125810749ab93cd794ee5426744",
            "placeholder": "​",
            "style": "IPY_MODEL_5609dad8bc474906b3adb166ad6fa48d",
            "value": "config.json: 100%"
          }
        },
        "44ec8eb1875849c98c047876e1253a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66fafcfc3d9f4eb181001353c718199c",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d235c08537f84ec5959efb5efa8e2705",
            "value": 190
          }
        },
        "90d430596fd446f98470fbbb0f396a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906683cd7c60493eb415c9807592a160",
            "placeholder": "​",
            "style": "IPY_MODEL_713e43d5042842138a0f2123f3a5e295",
            "value": " 190/190 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "e7384a73c2ce4542b00619817d0fe478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2c8125810749ab93cd794ee5426744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5609dad8bc474906b3adb166ad6fa48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66fafcfc3d9f4eb181001353c718199c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d235c08537f84ec5959efb5efa8e2705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "906683cd7c60493eb415c9807592a160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713e43d5042842138a0f2123f3a5e295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet rank_bm25 langchain_community langchain_core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnWmeHqTMiGE",
        "outputId": "b2d8d1d8-e737-46a2-f613-5b0796d750e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever"
      ],
      "metadata": {
        "id": "0Dbpt3cUMn_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create New Retriever with Texts"
      ],
      "metadata": {
        "id": "dW-jFfInM_FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = BM25Retriever.from_texts([\"foo\", \"bar\", \"world\", \"hello\", \"foo bar\"])"
      ],
      "metadata": {
        "id": "6JrgIE-8NGPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complex_retrieve = BM25Retriever.from_texts(\n",
        "    texts = [\n",
        "    \"LangChain is a framework for building applications with large language models.\",\n",
        "    \"BM25 is a ranking function used by search engines to rank documents.\",\n",
        "    \"Python is a popular programming language for AI and data science.\",\n",
        "    \"Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.\",\n",
        "    \"Elasticsearch is a powerful search engine based on Lucene.\"\n",
        "],\n",
        "    k = 2\n",
        ")"
      ],
      "metadata": {
        "id": "FsfNyuauZ31t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = complex_retrieve.invoke(\"How does BM25 work?\")"
      ],
      "metadata": {
        "id": "QiLAyJgUNdJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i , doc in enumerate(result) :\n",
        "  print(f\"{i}. {doc.page_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93HKRzEAadCf",
        "outputId": "14dd6beb-67d0-471f-dccd-39533619770c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0. BM25 is a ranking function used by search engines to rank documents.\n",
            "1. Elasticsearch is a powerful search engine based on Lucene.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a New Retriever with Documents"
      ],
      "metadata": {
        "id": "fmzxeyHWNO46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"LangChain is a framework for building applications with large language models.\",\n",
        "    \"BM25 is a ranking function used by search engines to rank documents.\",\n",
        "    \"Python is a popular programming language for AI and data science.\",\n",
        "    \"Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.\",\n",
        "    \"Elasticsearch is a powerful search engine based on Lucene.\"\n",
        "]"
      ],
      "metadata": {
        "id": "PmxA7R2zbgrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [Document(page_content = doc ) for doc in texts]"
      ],
      "metadata": {
        "id": "0W7uT5vSbP_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document"
      ],
      "metadata": {
        "id": "8k1QR835NTpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = BM25Retriever.from_documents(docs,k=1)"
      ],
      "metadata": {
        "id": "StRJON3DNxTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke('\"How does BM25 work?\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxyREMePbyYO",
        "outputId": "bc6152c6-d420-4717-a9f1-71f773131726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='BM25 is a ranking function used by search engines to rank documents.')]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Function"
      ],
      "metadata": {
        "id": "FJ0jeXODN0LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsWlBG9LPgNB",
        "outputId": "cd515378-fdcf-4bf7-c199-1e12f804ebb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POQINgftQRAH",
        "outputId": "17c9c49d-6304-45a2-aad5-99d9c952acc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "retriever = BM25Retriever.from_documents(docs , k=2 , preprocess_func = word_tokenize,)"
      ],
      "metadata": {
        "id": "9uMhBKdkcdqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"How does BM25 work?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcxNeaidEhB",
        "outputId": "d6b2110c-cad0-41be-dd24-dfcaa933e353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='BM25 is a ranking function used by search engines to rank documents.'),\n",
              " Document(metadata={}, page_content='Elasticsearch is a powerful search engine based on Lucene.')]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever with more preprocessing Function"
      ],
      "metadata": {
        "id": "dA9mzjTAcL5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25 nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c07kR-QvRUlm",
        "outputId": "70fa1fc9-e61e-4675-b2f8-660d53b39651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank-bm25) (2.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_core.documents import Document\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n"
      ],
      "metadata": {
        "id": "xAcUODJzRZQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the NLTK stopwords\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsRPJ-bDVEkc",
        "outputId": "d47793a8-27ef-4cd9-ef1a-30e34b690692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step_1 Preprocessing functions"
      ],
      "metadata": {
        "id": "EffHDQ6FVS1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "VQCt20gCVYR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess (text : str) -> str :\n",
        "\n",
        "  # lower the text\n",
        "  text = text.lower()\n",
        "\n",
        "  # 3 reove the special character\n",
        "  text = re.sub (r\"[^a-zA-Z0-9]\",\" \",text)\n",
        "\n",
        "  # make the token\n",
        "  tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words ]\n",
        "\n",
        "  return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "dzxaIOU9VjEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess(\"Hello my name is ibtisam, I love to play soccerr!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CkYjMLKMYPWO",
        "outputId": "ec2daa59-11fc-453c-b162-5970aad4341c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello name ibtisam love play soccerr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_docs = [\n",
        "    \"LangChain is a framework for building applications with large language models.\",\n",
        "    \"BM25 is a ranking function used by search engines to rank documents.\",\n",
        "    \"Python is a popular programming language for AI and data science.\",\n",
        "    \"Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.\",\n",
        "    \"Elasticsearch is a powerful search engine based on Lucene.\"\n",
        "]"
      ],
      "metadata": {
        "id": "pwPAlXYaYXvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrievers = BM25Retriever.from_documents(\n",
        "    [Document(page_content=doc) for doc in raw_docs],\n",
        "    preprocess_func=preprocess\n",
        ")"
      ],
      "metadata": {
        "id": "1QPp3y0BZKj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How does BM25 work?\"\n",
        "retrieved_docs = retrievers.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "x1tYdfKgY9ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIBjcP2TZUZK",
        "outputId": "06579fe1-2c54-43c8-b8e9-6ebf85731c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='BM25 is a ranking function used by search engines to rank documents.'),\n",
              " Document(metadata={}, page_content='Python is a popular programming language for AI and data science.'),\n",
              " Document(metadata={}, page_content='Elasticsearch is a powerful search engine based on Lucene.'),\n",
              " Document(metadata={}, page_content='LangChain is a framework for building applications with large language models.')]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_core.documents import Document\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# -------------------------\n",
        "# Step 1: Preprocessing function\n",
        "# -------------------------\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(text: str) -> str:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Step 2: Prepare documents\n",
        "# -------------------------\n",
        "raw_docs = [\n",
        "    \"LangChain is a framework for building applications with large language models.\",\n",
        "    \"BM25 is a ranking function used by search engines to rank documents.\",\n",
        "    \"Python is a popular programming language for AI and data science.\",\n",
        "    \"Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.\",\n",
        "    \"Elasticsearch is a powerful search engine based on Lucene.\"\n",
        "]\n",
        "\n",
        "# -------------------------\n",
        "# Step 3: Create BM25 Retriever\n",
        "# -------------------------\n",
        "bm25_retriever = BM25Retriever.from_texts(\n",
        "    texts=raw_docs,\n",
        "    k = 2,\n",
        "    preprocess_func=preprocess  # Use the preprocess function\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Step 4: Use the retriever\n",
        "# -------------------------\n",
        "query = \"How does BM25 work?\"\n",
        "retrieved_docs = bm25_retriever.get_relevant_documents(query)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "for i, doc in enumerate(retrieved_docs, 1):\n",
        "    print(f\"{i}.\", doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJM7z6nzZZ92",
        "outputId": "78de5175-a12c-4e07-e894-05dd8edc3b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How does BM25 work?\n",
            "1. BM25 is a ranking function used by search engines to rank documents.\n",
            "2. Python is a popular programming language for AI and data science.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Retrievers"
      ],
      "metadata": {
        "id": "zOzbpILJZhHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUOCecNcjcqm",
        "outputId": "42cf36fe-4792-47eb-eb16-5307127cf22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import TFIDFRetriever"
      ],
      "metadata": {
        "id": "ZWNowVkYjLwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create the new retriever with the text"
      ],
      "metadata": {
        "id": "bfgb3YAJjYZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_docs = [\n",
        "    \"LangChain is a framework for building applications with large language models.\",\n",
        "    \"BM25 is a ranking function used by search engines to rank documents.\",\n",
        "    \"Python is a popular programming language for AI and data science.\",\n",
        "    \"Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.\",\n",
        "    \"Elasticsearch is a powerful search engine based on Lucene.\"\n",
        "]"
      ],
      "metadata": {
        "id": "kVXpURpQkQwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs =[ Document(page_content=sentence) for sentence in raw_docs]"
      ],
      "metadata": {
        "id": "piIiyG2Lkuub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcGVp1WLlX_u",
        "outputId": "d31e3b95-4c90-412c-f984-e2aca2f7be86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='LangChain is a framework for building applications with large language models.'),\n",
              " Document(metadata={}, page_content='BM25 is a ranking function used by search engines to rank documents.'),\n",
              " Document(metadata={}, page_content='Python is a popular programming language for AI and data science.'),\n",
              " Document(metadata={}, page_content='Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.'),\n",
              " Document(metadata={}, page_content='Elasticsearch is a powerful search engine based on Lucene.')]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = TFIDFRetriever.from_texts(raw_docs)"
      ],
      "metadata": {
        "id": "lqvIAIxhkbMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrievers.invoke(\"What is BM25?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfd7rei3kg8W",
        "outputId": "aa0b3d83-7d57-47f0-a490-bb1eee05015c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='BM25 is a ranking function used by search engines to rank documents.'),\n",
              " Document(metadata={}, page_content='Python is a popular programming language for AI and data science.'),\n",
              " Document(metadata={}, page_content='Elasticsearch is a powerful search engine based on Lucene.'),\n",
              " Document(metadata={}, page_content='LangChain is a framework for building applications with large language models.')]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create the new retriever with the document"
      ],
      "metadata": {
        "id": "MAJEvboUkh1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_retriever = TFIDFRetriever.from_documents(docs)"
      ],
      "metadata": {
        "id": "UIOVcgfplL8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_retriever.invoke(\"What is BM25\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQUTw9FFlPnW",
        "outputId": "fc01d5fe-7f2a-41d5-bb2b-fa678687323e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='BM25 is a ranking function used by search engines to rank documents.'),\n",
              " Document(metadata={}, page_content='Elasticsearch is a powerful search engine based on Lucene.'),\n",
              " Document(metadata={}, page_content='Python is a popular programming language for AI and data science.'),\n",
              " Document(metadata={}, page_content='LangChain is a framework for building applications with large language models.')]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Retriever"
      ],
      "metadata": {
        "id": "oyuN9xzSl5Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "ZIWczpcDvUdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"This is a list which containing sample documents\",\n",
        "    \"Keywords are important for keyword-based search\",\n",
        "    \"Documents analysis involves extracting keywords.\",\n",
        "    \"Keywords-based search relies on sparse embedding.\"\n",
        "]"
      ],
      "metadata": {
        "id": "97mUFm2gv_c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"keyword-base search\""
      ],
      "metadata": {
        "id": "Uh1ZxD9zw98b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_text(doc) :\n",
        "  doc = doc.lower()\n",
        "\n",
        "  doc = re.sub(r\"[^\\w\\s]\",'',doc)\n",
        "\n",
        "  return doc\n"
      ],
      "metadata": {
        "id": "tw4Ouo8Pw1-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_doc = [preprocessing_text(doc) for doc in documents]"
      ],
      "metadata": {
        "id": "9Td_m3FKxp03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9jSDvlBx3S5",
        "outputId": "885b655a-dafd-4d0d-d341-5375e3f27a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is a list which containing sample documents',\n",
              " 'keywords are important for keywordbased search',\n",
              " 'documents analysis involves extracting keywords',\n",
              " 'keywordsbased search relies on sparse embedding']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# process the query\n",
        "\n",
        "processed_query = preprocessing_text(query)"
      ],
      "metadata": {
        "id": "hu_3X6aDyQ-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d6VPmwD2DUNg",
        "outputId": "420a65dc-1e91-4f8f-ff8d-39c8fac8bcb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'keywordbase search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# converting this document into the vector and this is the sparse vector using Tfidf"
      ],
      "metadata": {
        "id": "REcnXvshDV9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "alXDsIYfDnCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_sparse = vector.fit_transform(processed_doc)"
      ],
      "metadata": {
        "id": "0rp2IE1RDpj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_sparse.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TetvZ49bD00V",
        "outputId": "ce016906-8389-4d41-af4d-21b5c6a4e264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.38861429, 0.30638797, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.38861429,\n",
              "        0.        , 0.        , 0.        , 0.38861429, 0.        ,\n",
              "        0.        , 0.38861429, 0.        , 0.        , 0.38861429,\n",
              "        0.38861429],\n",
              "       [0.        , 0.43671931, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.43671931, 0.43671931, 0.        , 0.        ,\n",
              "        0.43671931, 0.34431452, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34431452, 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.48546061, 0.        , 0.        , 0.38274272, 0.        ,\n",
              "        0.48546061, 0.        , 0.        , 0.48546061, 0.        ,\n",
              "        0.        , 0.38274272, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.42176478,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.42176478, 0.        , 0.42176478,\n",
              "        0.42176478, 0.        , 0.3325242 , 0.42176478, 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_sparse.toarray()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siLBCHZmD2c4",
        "outputId": "4c36f1e6-6088-41e3-bf95-cd45dadd9e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.38861429, 0.30638797, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.38861429,\n",
              "       0.        , 0.        , 0.        , 0.38861429, 0.        ,\n",
              "       0.        , 0.38861429, 0.        , 0.        , 0.38861429,\n",
              "       0.38861429])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = vector.transform([processed_query])"
      ],
      "metadata": {
        "id": "cXqRhTQHEALb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NY8cmh4FEiJ",
        "outputId": "0331e538-07ef-4e7f-bbd1-b18959fe72f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarites = cosine_similarity(vector_sparse,query_embedding,)"
      ],
      "metadata": {
        "id": "bax67HP3FNMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarites"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrdfLIkhGvXL",
        "outputId": "12f2522a-6a6c-40f3-be46-1d5c49d8cb86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [0.34431452],\n",
              "       [0.        ],\n",
              "       [0.3325242 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ranking\n",
        "ranked_indices =  np.argsort(similarites,axis=0)[::-1].flatten()"
      ],
      "metadata": {
        "id": "QFkiaqITGwv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33HLfzFFH2t0",
        "outputId": "a00ca615-c111-41d4-fec3-bbe03556be74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_documents = [documents[i] for i in ranked_indices]"
      ],
      "metadata": {
        "id": "wKYk0MRoLNUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, doc in enumerate(ranked_documents):\n",
        "  print(f\"Rank {i+1}: {doc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfL1BjhdH3if",
        "outputId": "c223b98e-bf5a-49c1-86c3-c0518e1c006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 1: Keywords are important for keyword-based search\n",
            "Rank 2: Keywords-based search relies on sparse embedding.\n",
            "Rank 3: Documents analysis involves extracting keywords.\n",
            "Rank 4: This is a list which containing sample documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Search Retriever"
      ],
      "metadata": {
        "id": "kgt7XGK-K3En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-\""
      ],
      "metadata": {
        "id": "3hFsWDtQOzrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_path = \"/content/Internship Day 2 Report.pdf\""
      ],
      "metadata": {
        "id": "umP50e3_Mxvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOFttHaAM5P6",
        "outputId": "61b0f6ea-deca-4585-f8d7-08b1cfd986ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.74)\n",
            "Collecting openai<2.0.0,>=1.99.9 (from langchain_openai)\n",
            "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, langchain_openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.8\n",
            "    Uninstalling openai-1.99.8:\n",
            "      Successfully uninstalled openai-1.99.8\n",
            "Successfully installed langchain_openai-0.3.30 openai-1.99.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import BM25Retriever  , EnsembleRetriever\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings , ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "Kx9_9v0EM-w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(doc_path)"
      ],
      "metadata": {
        "id": "fTUdBSLDN02z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = loader.load()"
      ],
      "metadata": {
        "id": "zI-vAq-HN9NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4au-F3pOCMw",
        "outputId": "5ad462f3-5224-42ec-ca74-3b3c958d86d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='Retrieval  Augmented  Generation  (RAG)   What  is  RAG  ?   RAG  is  a  technique  used  in  LLM  application  to  combine  external  knowledge  retrieval  \\nwith\\n \\ngenerative\\n \\nAI\\n \\nto\\n \\nproduce\\n \\naccurate,\\n \\nup\\n \\nto\\n \\ndate,\\n \\nand\\n \\ncontext\\n \\naware\\n \\nresponse\\n  Why  need  RAG  ?   Many  LLMs  Like  GPT,  Claude  or  LLaMA  trained  on  the  huge  dataset  from  the  \\ninternet\\n \\nbut\\n \\nthey\\n \\nface\\n \\nsome\\n \\nissues\\n \\nwhile\\n \\ngenerating\\n \\nthe\\n \\nresponse.\\n 1.  Outdated  knowledge  cutoff  (GPT-4  /  GPT-4o   October  2023)  2.  Hallucinate  (Generate  make  up  facts  with  the  high  confident)  3.  Can’t  Know  private  data  unless  trained  or  fine  tune  on  it.  RAG  Advantage  :   1.  Retrieves  relevant  information  from  the  knowledge  base  like  database,vector  \\nstores,APIs)\\n 2.  Can’t  Hallucinate  because  the  extra  knowledge  is  fed  with  proper  context.  3.  Have  no  knowledge  cut  off  date  we  can  add  the  latest  news  article,  facts  in  \\nour\\n \\nknowledge\\n \\nbase.\\n Understanding  RAG  :   \\n Complete  RAG  Pipeline  :   Given  below  are  the  important  components  in  the  RAG  pipeline.  1.  Indexing  2.  Retrieval  3.  Augmentation  4.  Generation   Indexing  :   Indexing  is  the  process  of  preparing  our  knowledge  base  so  that  it  can  be  efficiently  \\nsearched\\n \\nat\\n \\nquery\\n \\ntime.Indexing\\n \\nconsists\\n \\nof\\n \\n4\\n \\nsub\\n \\nsteps\\n \\n.\\n \\n 1.  Document  Ingestion  :   In  this  step  we  load  our  source  knowledge  into  the  memory  from  the  different  \\nsources\\n \\nlike:'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='●  PDF  Reports  ●  Youtube  Transcription  ●  SQL  REcords  ●  Scraped  webpages   \\n 2.  Text  Chunking  :  In  this  step  the  load  data  is  break  down  into  small,  \\nsemantically\\n \\nmeaningful\\n \\nchunks\\n \\nbecause\\n \\n:\\n \\n ●  LLMs  have  context  limits  (e.g  4k-32k  tokens)  ●  Small  chunks  have  better  semantic  search   \\n 3.  Embedding  Generation: After  Chunking  the  embedding  generation  happens  \\nwhere\\n \\neach\\n \\nchunk\\n \\nis\\n \\nconverted\\n \\ninto\\n \\nthe\\n \\ndense\\n \\nvector\\n \\nthat\\n \\ncaptures\\n \\nits\\n \\nmeaning.Text\\n \\nis\\n \\nconverted\\n \\ninto\\n \\nvector\\n \\nbecause:\\n ●  Similar  meaning  words  are  close  together  in  vector  space.  ●  Allow  Fast,Efficient  semantic  search   TOOLS:  OpenAIEMbeddings,SentenceTransformerEmbeddings  etc'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='4.  Vector  Store  :  Store  the  vector  along  with  the  original  chunk  text   +  metadata  \\nin\\n \\na\\n \\nvector\\n \\ndatabase.Different\\n \\nVector\\n \\nDB\\n \\noptions\\n \\nare:\\n ●  Local  :  FAISS,  Chroma  ●  Cloud  :  Pinecone,Weaviet,Qdrant   \\n Retrieval:   Retrieval  is  the  real-time  process  of  finding  the  most  relevant  pieces  of  information  \\nfrom\\n \\na\\n \\npre-built\\n \\nindex\\n \\n(created\\n \\nduring\\n \\nindexing)\\n \\nbased\\n \\non\\n \\nthe\\n \\nuser’s\\n \\nquestion.\\n  Example  :  From  all  the  knowledge  base  I  have,  which  3-5  chunks  are  most  helpful  \\nto\\n \\nanswer\\n \\nthis\\n \\nquery.\\n When  a  user  asks  a  question:  \\n1.  Convert  query  to  vector  2.  Search  the  vector  store  for  most  similar  documents  3.  Retrieve  top-N  chunks  (e.g.,  top  3  or  top  5)'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='Augmentation:   Augmentation  refers  to  the  step  where  the  retrieved  documents  (chunks  of  relevant  \\ncontext)\\n \\nare\\n \\ncombined\\n \\nwith\\n \\nthe\\n \\nuser’s\\n \\nquery\\n \\nto\\n \\nform\\n \\na\\n \\nnew,\\n \\nenriched\\n \\nprompt\\n \\nfor\\n \\nthe\\n \\nLLM.\\n Example  system  prompt  :   You  are  an  assistant  answering  questions  about  company  policies.  Use  the  following  context  from  our  knowledge  base  to  answer:  <context  from  retrieved  chunks  here>'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Generation  :   Generation  is  the  final  step  where  a  Large  Language  Model  (LLM)  uses  the  user’s  \\nquery\\n \\nand\\n \\nthe\\n \\nretrieved\\n \\n&\\n \\naugmented\\n \\ncontext\\n \\nto\\n \\ngenerate\\n \\na\\n \\nresponse.\\n \\nThe\\n \\nLLM\\n \\nnow\\n \\nanswers\\n \\nthe\\n \\nuser’s\\n \\nquestion\\n \\nusing:\\n ●  Its  training  knowledge  ●  The  provided  up-to-date  retrieved  context  This  generation  reduces  hallucinations,  made  up  facts  and  increases  accuracy  of  the  \\ngenerated\\n \\ntext.\\n  \\n   Youtube  Chatbot  using  Langchain,RAG  and  Streamlit  :    GOAL:  Building  a  RAG  system  to  chat  with  youtube  at  realtime  using  lanchain    Plan  Of  Action  :   The  complete  plain  of  action  to  build  the  RAG  system  is  given  below:   Indexing  :   1.  Load  the  youtube  video  transcript  through  youtube  api  this  transcript  act  as  a  \\nknowledge\\n \\nbase\\n \\nfor\\n \\nour\\n \\nRAG\\n \\nsystem\\n \\n 2.  Since  the  loaded  transcript  might  be  too  lengthy,  we  can  use  the  technique  of  \\nRecursive\\n \\ntext\\n \\nsplitter\\n \\nto\\n \\nmake\\n \\nsmall\\n \\nchunks\\n \\nof\\n \\nthese\\n \\nloaded\\n \\ntranscripts\\n \\nto\\n \\nmake\\n \\nthe\\n \\nretrieval\\n \\nefficient\\n \\nand\\n \\nfast.\\n 3.  Then  in  the  next  step  we  will  create  the  embedding  of  the  chunks  with  the  \\nhelp\\n \\nof\\n \\nthe\\n \\nOpenAIEmbedding\\n \\nmodel\\n \\nwhich\\n \\nconverts\\n \\nthese\\n \\nchunks\\n \\ninto\\n \\nthe\\n \\nvector.\\n 4.  The  created  vectors  are  now  to  be  stored  in  to  the  vector  store  for  the  retrieval   Retrieval  :   1.  The  Next  step  is  to  create  the  retrieval.'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='2.  I  will  use  a  simple  Similarity  search  base  retrieval  to  fetch  the  relevant  \\ndocument.\\n 3.  Then  a  query  will  send  to  the  retrieval  the  retrieval  embed  the  user  query  and  \\nperform\\n \\nthe\\n \\nsemantic\\n \\nsearch\\n \\nin\\n \\nthe\\n \\nvector\\n \\nstore\\n \\nand\\n \\nget\\n \\nthe\\n \\nrelevant\\n \\ndocuments.\\n Augmentation  :   1.  Once  the  relevant  chunks  are  retrieved  from  the  vector  store  then  we  will  \\nmerge\\n \\nit\\n \\nwith\\n \\nthe\\n \\nuser\\n \\nquery\\n \\nand\\n \\nmake\\n \\nthe\\n \\nsystem\\n \\nprompt.\\n Generation  :   1.  The  system  prompt  is  then  fed  to  the  LLM   2.  LLM  then  generates  the  response.  Langchain  Implementation  :   Converting  the  RAG  Pipeline  into  the  Langchain  chain  so  the  output  of  one  \\ncomponent\\n \\nwill\\n \\nbecome\\n \\nthe\\n \\ninput\\n \\nfor\\n \\nthe\\n \\nother\\n \\ncomponent\\n \\nand\\n \\nwith\\n \\nthe\\n \\nhelp\\n \\nof\\n \\ninvoke\\n \\nfunction\\n \\nwe\\n \\nrun\\n \\nthe\\n \\nwhole\\n \\npipeline\\n \\nat\\n \\none\\n \\ngo.\\n  Complete  RAG  Pipeline  flow  :    \\n  \\nRunnables  in  Langchain  :    In  LangChain,  a  Runnable  is  a  core  abstraction,  basically  a  standard  way  to  \\nrepresent\\n \\nsomething\\n \\nthat\\n \\ncan\\n \\nrun\\n \\nwhen\\n \\nyou\\n \\ngive\\n \\nit\\n \\ninput\\n \\nand\\n \\nproduce\\n \\noutput.It\\n \\nis\\n \\na\\n \\nblock\\n \\nof\\n \\nwork\\n \\nthat\\n \\ncan\\n \\ntake\\n \\ndata\\n \\nin,\\n \\ndo\\n \\nsomething\\n \\nwith\\n \\nit,\\n \\nand\\n \\ngive\\n \\nyou\\n \\nback\\n \\na\\n \\nresult.\\n So  we  will  use  the  runnable  parallel  because  the  LLM  model  takes  question  and  \\ncontext\\n \\nboth\\n \\nas\\n \\ninput.\\n Why  LangChain  introduced  Runnables  :   Problem  :'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='1.  Before  Runnables,  LangChain  had  many  separate  classes  that  each  used  \\ndifferent\\n \\nways\\n \\nto\\n \\nrun\\n \\nthe\\n \\ncomponent\\n \\n(some\\n \\nof\\n \\nthem\\n \\nused\\n \\n.run(),some\\n \\nused.call()).\\n \\n 2.  So  its  very  hard  to  combine  all  the  components  and  chain  them  together   Solution:  1.  Make  a  single  interface  ( Runnable )  so  everything  behaves  the  same  way.  2.  No  matter  what  the  component  is,  you  can  just  call:  ●  component.invoke(input)  ●  component.batch(inputs)  ●  component.stream(input)  ●   \\nCoding  of  chatbot   :    Youtube_video_URL  =  https://youtube.com\\\\watch^v=-HzgcbRXUK8  Libraries  Used  :   1.  Streamlit  2.  Youtube-transcript-api  3.  Langchain.text_splitter  4.  Langchain_openai  5.  Lanchain_core.prompts  6.  Langchain_core.runnables  7.  Langchain_core.ouput_parser  8.  dotenv  Tools  inside  these  Libraries  :   1.  OpenAI  API  (for  embedding  and  chat  responses)  2.  FAISS  (for  vector  similarity  search)  Streamlit  APP:'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='TOOLS  IN  LANGCHAIN    What  is  a  Tool  ?    A  tool  is  just  a  Python  function  (or  API)  that  is  packaged  in  a  way  the  LLM  can  \\nunderstand\\n \\nand\\n \\ncall\\n \\nwhen\\n \\nneeded.\\n  Why  do  we  need  tools  ?   LLMs  (like  GPT)  are  great  at:  ●  Reasoning  ●  Generating  Text  But  they  can  not  do  things  like:   ●  Access  Live  data  (like  weather  ,  news,  article  etc)  ●  They  are  not  reliable  in  maths  specific  problem  because  the  train  more  on  \\nlanguage\\n \\ntext\\n ●  Call  API  to  fetch  data  ●  Run  the  code   ●  They  are  unable  to  interact  with  a  database   Types  of  tools  in  langchain  :   There  are  two  types  of  tools  in  langchain  :   1.  Built-in  Tools  2.  Custom  Tools   How  tools  fits  into  the  Agent  ecosystem  :   An  AI  gent  is  an  LLM  Powered  system  that  can  autonomously  think,  decide,  and  take  \\nactions\\n \\nusing\\n \\nexternal\\n \\ntools\\n \\nor\\n \\nAPIs\\n \\nto\\n \\nachieve\\n \\na\\n \\nspecific\\n \\ngoal.'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='Built-in  Tools  in  langchain   A  built-in  tool  is  a  tool  that  LangChain  already  provides  for  us.  It  is  pre-built,  \\nproduction\\n \\nready,\\n \\nand\\n \\nrequires\\n \\nminimal\\n \\nor\\n \\nno\\n \\nsetup.\\n \\nWe\\n \\ndon’t\\n \\nhave\\n \\nto\\n \\nwrite\\n \\nthe\\n \\nfunction\\n \\nlogic\\n \\nyourself,\\n \\nwe\\n \\njust\\n \\nimport\\n \\nand\\n \\nuse\\n \\nit.\\n Documentation  for  built-in-tools  in  lanchain  :  https://python.langchain.com/docs/integrations/tools/ Few  tools  are  :   ●  DuckDuckGOSearchRun  ●  WikipediaQueryRun  ●  GmailSendMessageTool  ●  ShellTool  ●  SQLDataBaseQueryTool  Working  with  built-in-tool  :   \\n1.\\n \\nDuckDuckGo\\n \\nSearch\\n \\n 2.  Shell  Tool'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Custom  Tools  :    A  custom  tool  is  a  tool  that  you  define  yourself.  We  use  custom  tool  when:  1.  We  want  to  call  our  own  APIs  2.  Want  the  LLM  to  interact  with  our  database,product,  or  app  Ways  to  Create  Customs  Tools  :  There  are  three  ways  to  create  the  custom  tools  in  the  langchain.  1.  Using  @tool  decorator  2.  Using  structure  &  pydantic  3.  Using  BaseTool  class   Method  1  :  Built  tool  (Using  @tool  decorator)  :   In  three  steps  we  can  create  a  tool  using  @tool  decorator.  1.  Step  1  is  creating  a  function  2.  In  step  2  we  add  the  type  hints  3.  We  add  the  tool  decorator  \\n  We  can  also  check  the  model  name,  description  and  args.'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='Important  :  When  we  connect  the  tool  to  the  LLM  the  LLM  get  the  json  schema  rather  \\nthan\\n \\nthe\\n \\ntool\\n \\nfunction.\\n \\n   Method  2  -  Using  Structured  Tool  A  Structured  Tool  in  LangChain  is  a  special  type  of  tool  where  the  input  to  the  tool  \\nfollows\\n \\na\\n \\nstructured\\n \\nschema,\\n \\ntypically\\n \\ndefined\\n \\nusing\\n \\na\\n \\nPydantic\\n \\nmodel.'),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content=\"Method  3  -  Using  a  BaseTool  :   Base  Tool  :  BaseTool  is  the  abstract  base  class  for  all  tools  in  LangChain.  It  defines  the  core  \\nstructure\\n \\nand\\n \\ninterface\\n \\nthat\\n \\nany\\n \\ntool\\n \\nmust\\n \\nfollow,\\n \\nwhether\\n \\nit's\\n \\na\\n \\nsimple\\n \\none-liner\\n \\nor\\n \\na\\n \\nfully\\n \\ncustomized\\n \\nfunction.\\n \\nAll\\n \\nother\\n \\ntool\\n \\ntypes\\n \\nlike\\n \\n@tool,\\n \\nStructuredTool\\n \\nare\\n \\nbuilt\\n \\non\\n \\ntop\\n \\nof\\n \\nBaseTool.\\n \\n  Tool  Calling  in  Langchain    Tool  Binding  :   Tool  binding  is  the  step  in  the  langchain  where  we  register  tools  with  a  LLM  so  that:  1.  LLM  knows  what  tools  are  available  2.  It  knows  what  each  tool  does  (with  the  help  of  description)  3.  It  knows  what  input  format  to  use  (via  schema)   First  create  the  custom  tool  to  finding  the  area  of  the  cylinder  so  i  can  bind  it  with  the  \\nLLM.\"),\n",
              " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Internship Day 2 Report', 'source': '/content/Internship Day 2 Report.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='Now  the  tool  is  ready  now  we  bind  the  calulate_cylinder_area  tool  with  the  LLM.  \\n  Tool  Calling  :   Tool  calling  is  the  process  where  the  LLM(language  model)  decides,  during  a  \\nconservation\\n \\nor\\n \\ntask,\\n \\nthat\\n \\nit\\n \\nneeds\\n \\nto\\n \\nuse\\n \\na\\n \\nspecific\\n \\ntool\\n \\nand\\n \\ngenerated\\n \\na\\n \\nstructured\\n \\noutput\\n \\nwith:\\n 1.  The  name  of  the  tool  2.  The  Arguments  to  call  it  with    Note  :  The  LLM  does  not  actually  run  the  tool  it  just  suggests  the  tool  and  the  input  \\narguments.\\n \\nThe\\n \\nactual\\n \\nexecution\\n \\nis\\n \\nhandled\\n \\nby\\n \\nlangchain\\n \\nor\\n \\nus.')]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = OpenAIEmbeddings()\n",
        "chat_model = ChatOpenAI()"
      ],
      "metadata": {
        "id": "S5CGqoP3ODH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 400 , chunk_overlap = 40)"
      ],
      "metadata": {
        "id": "1r6QLpDxOxDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitting = splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "5QkaoLtJQgKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for keyword search we use the sparse embdedings which is based on the vocabulary"
      ],
      "metadata": {
        "id": "PSAwAOL9QurI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Ztr4uKRKkr",
        "outputId": "e6e57e21-c508-43b4-f5bb-d6692658e840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.17-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.4)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.17-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=37b28d661ca9a22c65c31ed438628216076b05dbbdb8b1745b42b16092bcd62a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.17 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "nAp3YIWmRUr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = Chroma.from_documents(text_splitting,embedding_model)"
      ],
      "metadata": {
        "id": "qbPxWmEQRdUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_type='similarity' , search_kwargs={'k':3})"
      ],
      "metadata": {
        "id": "o0BeToQIRyIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R92t0EcmSDen",
        "outputId": "35c2f0ec-e57c-4abc-a897-33cf4ed00b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7d389057d2d0>, search_kwargs={'k': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_retriever = BM25Retriever.from_documents(text_splitting , k=3)"
      ],
      "metadata": {
        "id": "InKKXZJ7SEk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make the ensemble retriever\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers = [retriever , keyword_retriever],\n",
        "    weights = [0.3,0.7]\n",
        ")"
      ],
      "metadata": {
        "id": "kCLWzHg4TT3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "You are a helpful assistant. Use the context below to answer the question.\n",
        "If the answer is not in the context, say you don't know.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eKu8VGIpgBLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n"
      ],
      "metadata": {
        "id": "ptQYQREtjrUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "# Separate the retrieval from the formatting and generation\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel({\n",
        "        \"context\": ensemble_retriever | format_docs,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    })\n",
        "    | prompt\n",
        "    | chat_model\n",
        ")"
      ],
      "metadata": {
        "id": "4qCsNyUpii2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\"What are the key topic mentions releated to the RAG\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YvBe4aUkKQx",
        "outputId": "41ec32a8-a766-4b25-aac6-b7acc093cfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The key topic mentions related to RAG include indexing, retrieval, augmentation, and generation. These are the important components in the RAG pipeline.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "# ------------------------\n",
        "# Helper function for formatting\n",
        "# ------------------------\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "# ------------------------\n",
        "# Main RAG pipeline builder\n",
        "# ------------------------\n",
        "def build_chain(pdf_path):\n",
        "    # 1. Load PDF\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    document = loader.load()\n",
        "\n",
        "    # 2. Embeddings and LLM\n",
        "    embedding_model = OpenAIEmbeddings()\n",
        "    chat_model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "    # 3. Split into chunks\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=40)\n",
        "    text_splitting = splitter.split_documents(document)\n",
        "\n",
        "    # 4. Vector store retriever\n",
        "    vector_store = Chroma.from_documents(text_splitting, embedding_model)\n",
        "    vector_retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
        "\n",
        "    # 5. Keyword retriever\n",
        "    keyword_retriever = BM25Retriever.from_documents(text_splitting, k=3)\n",
        "\n",
        "    # 6. Ensemble retriever\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[vector_retriever, keyword_retriever],\n",
        "        weights=[0.3, 0.7]\n",
        "    )\n",
        "\n",
        "    # 7. Prompt\n",
        "    prompt_template = \"\"\"\n",
        "    You are a helpful assistant. Use the context below to answer the question.\n",
        "    If the answer is not in the context, say you don't know.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    # 8. Chain\n",
        "    chain = (\n",
        "        RunnableParallel({\n",
        "            \"context\": ensemble_retriever | format_docs,\n",
        "            \"question\": RunnablePassthrough()\n",
        "        })\n",
        "        | prompt\n",
        "        | chat_model\n",
        "    )\n",
        "    return chain\n",
        "\n",
        "# ------------------------\n",
        "# Gradio Functions\n",
        "# ------------------------\n",
        "chat_chain = None  # global to store pipeline\n",
        "\n",
        "def load_pdf(file):\n",
        "    global chat_chain\n",
        "    chat_chain = build_chain(file.name)\n",
        "    return \"✅ PDF loaded and processed. You can now ask questions.\"\n",
        "\n",
        "def ask_question(query):\n",
        "    if chat_chain is None:\n",
        "        return \"⚠ Please upload a PDF first.\"\n",
        "    response = chat_chain.invoke(query)\n",
        "    return response.content\n",
        "\n",
        "# ------------------------\n",
        "# Gradio UI\n",
        "# ------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📄 RAG Chatbot with Hybrid Search (BM25 + Vector)\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            file_input = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "            load_btn = gr.Button(\"Process PDF\")\n",
        "            status_box = gr.Textbox(label=\"Status\")\n",
        "        with gr.Column():\n",
        "            query_input = gr.Textbox(label=\"Your Question\")\n",
        "            answer_box = gr.Textbox(label=\"Answer\", lines=6)\n",
        "            ask_btn = gr.Button(\"Ask\")\n",
        "\n",
        "    load_btn.click(load_pdf, inputs=file_input, outputs=status_box)\n",
        "    ask_btn.click(ask_question, inputs=query_input, outputs=answer_box)\n",
        "\n",
        "# Run app\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "5LNl4ekkkYaK",
        "outputId": "947b3bf0-6a17-4b5f-9309-99b718357420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a78f3e2d0e8737f4e4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a78f3e2d0e8737f4e4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reranking with sentence Transformer and BM25 API"
      ],
      "metadata": {
        "id": "pjVHGvm8G7F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_docs = [\n",
        "    \"LangChain is a framework for building applications with large language models.\",\n",
        "    \"BM25 is a ranking function used by search engines to rank documents.\",\n",
        "    \"Python is a popular programming language for AI and data science.\",\n",
        "    \"Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.\",\n",
        "    \"Elasticsearch is a powerful search engine based on Lucene.\",\n",
        "    \"Efficient Keyword extraction enhances search accuracy\",\n",
        "    \"Semantic similarity improves document retrieval performance\"\n",
        "]"
      ],
      "metadata": {
        "id": "89__it2Q3nxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS8VX-soHBvX",
        "outputId": "8ddb1020-004b-44d7-ab8d-3fbededfc5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.55.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.8.3)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "Txsv0_01HEEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained sentence transformer model\n",
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "98003a0665204053b29f62f940459ebb",
            "c8205c2f4ccb419fba633af699ad2505",
            "e792158880d44c02874ca65af55d36bb",
            "e88f90653f924033aa4c467906c1d142",
            "4957cb329fb344f2ae1085b0543cdc92",
            "d18c0e17b55a48539911fa7b3c5cb13b",
            "18562dd744a14258a57b7b18680d7578",
            "2d16680442704c55ace12aae87f4cb46",
            "a0b4bc7659614b579bec27ff881cf040",
            "c79329a542ea43a79435a5ed2856e4e9",
            "7e62125744de42e2a84ecf92514f7402",
            "a5a7311aee29464cb38d7dd8e5e1694c",
            "e64733bc623e4e3684bbdc94028efec0",
            "1b07f98f2bb84c6083cd6410b85ebfd9",
            "76a3d714f6a4455194ff9a2a6c3cc96d",
            "deaf8dd424f34382bfc9d2ce4b4b7fe9",
            "bd3bed2144e541beb18596d4c8461fbf",
            "82c57d4fe02f4572b3d508e5d9181483",
            "f982e749f98544b38a8d313456d894a5",
            "dad22e02b6c5411ea99082952c2ed695",
            "1d955aa80d914e1f8a6a918e3523a65c",
            "4d62c538fa2b4003b3629fd6cf0acf0a",
            "b60b0b0341874b6d8ccd45a087ee384b",
            "2a563b7e8ca044229987f735b4d867c3",
            "093e71a09d324e9f8fdf90195f681042",
            "8589882b9dfd4aabbda14caa6e6b940c",
            "c9e4ae2961db4c94bb001f48d5985d44",
            "c596966af2174cf1927a42834e18cab5",
            "3387141c7e2c495d9622c8acc43d1fb5",
            "d403febedf7346c990ccf5db8f145a28",
            "a6ae224a7ebb4fb6bc96051f8cab0614",
            "517b19ae6f2a4d3c89e497e1a0f17783",
            "64f8f61797a049588f753fedd4c7dfcb",
            "f0ebb8d65ea449e0b2959a7ed79714d7",
            "d1031d75f6e2494e9b29d66019748910",
            "ec335d23db5d4714a9621606fab4bf13",
            "521bdd106f0f4c9aa4a93f644262db47",
            "5e25047f8d1a414294f6b1940f6ef5a3",
            "dad80bbf3197470d9dc1d49c87c34570",
            "687edd75aec942d4ba889ae3ad823314",
            "91ab33b652224b0ca08f64518699fe71",
            "67920abcb8a74d91a906e3d77f9ae835",
            "a4b82019801b4cabab89cb1e748e26f1",
            "2a9899e0adb4453d9bfcd1f4e83e146f",
            "50d9dfc720c34d27893f32c123ae459c",
            "21f29643538d4d0da5260054529c1692",
            "b9537c96819b4bb7ac5875321e265168",
            "940d2705add14931ac38bf628168d654",
            "f24edd2ef4ae43e6b3a3914ec00e5e00",
            "d21a3bfd9bc34c4192217ef26be4d859",
            "4d4d19134bc044cb8cfbf21ce3751579",
            "dea1b5d486f4475680708ef588cce942",
            "711e0f9d12714e6184a5ebcce192e572",
            "44c8cab3eb98489b95e2d9d884aa01ce",
            "6421f5e7484f4cd0b4245610b9fbfc96",
            "0655951d8bf349dda8aa1b71441cffe1",
            "0069531ccd1a4d48a2eb625c0b329140",
            "defb62266f1945149d9eb455e4b0dea4",
            "994d62df10ca48cf883de5a94baeb2ea",
            "cb1ca77fa5d3476fb7deabfb435662a3",
            "7cbbae79c3074c77bae8d6faae55e814",
            "0c203ea2f62446ce9fda647749b8dca0",
            "d7774f33754448369d428598b3f33bbf",
            "dde6fbe91b8f4ef2b5e4f45ad9f79a6b",
            "1bedd667c20644ada6519497d31a838e",
            "a84c7400cf1646369f9c78021a1f778c",
            "118c9a1a9e6145119d1bd3c2ba2e92d1",
            "b05589d8ddc043b9a2ecb7262ee8fb4f",
            "337ad77f8c5e4784935df6215158a429",
            "be56ec99e672412bac9e8315cbb24304",
            "bb8977b07dd44417ba76df58dc8eb2d2",
            "2448492cb0f946e4b7234b16598eb4ce",
            "a2c10328d32145f9b2c80ec706fa6910",
            "2130715787654f2998295b7064703406",
            "c3c43ba37d4c43219f7753c7074285f0",
            "75bac2cd9f4c4471a2ebb281b3135b91",
            "c0a3533115c0449f84cfaef7dd025612",
            "bdc5efca36ed45848d6f2a77662c6dad",
            "a6f35b036eee49afbcec7a81e9ac3bce",
            "c42a4c11e3294194a40610e716f23712",
            "53b47a66c47941bc902657fe180e5d1b",
            "a23a39a904a84159b83f0a1b3d0c0095",
            "fa18f0dedf0946338fc3c204766208a8",
            "13ebede809f146519ee47c258d709043",
            "51aa7d194e8c462ba3ee1f5c7392330e",
            "52f3a51d0d6b4a2caa954672028ed6ba",
            "f53f7757fc11455c98fa96a922342093",
            "02ed82ddc4084da1b9775ca4b8908f88",
            "d78498623309459c8f1609f5c399330c",
            "a82bc873262c4800a12dc2f76003de85",
            "f508b7103a43436bbfad401b9c1e2abc",
            "3a8956954f5a4401b259d5ed274ac8b5",
            "4a1f850d40f14708ac251fd842b96096",
            "33901fd2ea5446eaa3004065ca2d95be",
            "5bf2f332fb6a4ab59df82c2844afdeb8",
            "fec490b30311474d945844c370c6e4b3",
            "212e5c2bead44da4a75bf76ef3b87d17",
            "5641c9bde1cf4a4d973e0d0fd8aba98b",
            "bc576241ef264c27b6f2f5b2d4fc8969",
            "ababfe4e00b64dec9f27a7a5f2d0dd89",
            "a0c121033b014293ba26562087fefcf9",
            "9903497b5261491c8ba47d8b81fc9b30",
            "7e152540f205479780b5505ac6cf0840",
            "3abfdc3f707a423aacaf4435ca07f83b",
            "304c83da5b55456992dc95b6146b4aaf",
            "a01903b99fa84f1f8a6c332a3f02503e",
            "95af1183bee84559aa398725906e0be7",
            "9cebcdf1f69f4ce7bbc90c8b54ac2066",
            "0e3150749b614133a38eb7e39540f220",
            "09e5eeb34f5a44beaae4723807d1061d",
            "d9f8f9fefc704e50af6f2b2393034ea2",
            "0dd52e5318d84bc8af92eded0dddf3d5",
            "44ec8eb1875849c98c047876e1253a58",
            "90d430596fd446f98470fbbb0f396a3a",
            "e7384a73c2ce4542b00619817d0fe478",
            "1a2c8125810749ab93cd794ee5426744",
            "5609dad8bc474906b3adb166ad6fa48d",
            "66fafcfc3d9f4eb181001353c718199c",
            "d235c08537f84ec5959efb5efa8e2705",
            "906683cd7c60493eb415c9807592a160",
            "713e43d5042842138a0f2123f3a5e295"
          ]
        },
        "id": "DuIwQqZZHrw-",
        "outputId": "ecbd1f58-374b-4167-e94c-98bfa0b035d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98003a0665204053b29f62f940459ebb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5a7311aee29464cb38d7dd8e5e1694c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b60b0b0341874b6d8ccd45a087ee384b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0ebb8d65ea449e0b2959a7ed79714d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50d9dfc720c34d27893f32c123ae459c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0655951d8bf349dda8aa1b71441cffe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "118c9a1a9e6145119d1bd3c2ba2e92d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdc5efca36ed45848d6f2a77662c6dad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d78498623309459c8f1609f5c399330c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ababfe4e00b64dec9f27a7a5f2d0dd89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9f8f9fefc704e50af6f2b2393034ea2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz6FOOkiH4D3",
        "outputId": "cbed6c15-22e7-4c42-9d5f-736c523d98f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LangChain is a framework for building applications with large language models.',\n",
              " 'BM25 is a ranking function used by search engines to rank documents.',\n",
              " 'Python is a popular programming language for AI and data science.',\n",
              " 'Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.',\n",
              " 'Elasticsearch is a powerful search engine based on Lucene.',\n",
              " 'Efficient Keyword extraction enhances search accuracy',\n",
              " 'Semantic similarity improves document retrieval performance']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ3kEC9sH-Wi",
        "outputId": "214224ea-3943-4402-ce4d-e6db846f1047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_embedding = model.encode(raw_docs)"
      ],
      "metadata": {
        "id": "XPShhpEpH_aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embedding.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz6LfhmXJSKd",
        "outputId": "1a015c9e-48cb-41e0-f6a9-08e4c3cfe678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(document_embedding[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ9DeQFBIUEl",
        "outputId": "2ced60aa-cffe-44d7-d0b9-4df94590ebe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i , embed in enumerate(document_embedding):\n",
        "  print(f\"Document {i+1} embedding shape : {embed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foTAbmb5IDv7",
        "outputId": "9218f20b-4fb5-4ab0-ffd9-aa87c0d54f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1 embedding shape : [-2.95994282e-02 -5.04077263e-02  1.60818640e-02 -6.06924854e-02\n",
            " -2.96175051e-02  2.35670488e-02 -6.79402947e-02  6.17748052e-02\n",
            "  8.35111365e-02 -5.23912460e-02  5.20942034e-03 -1.53448535e-02\n",
            "  2.63303686e-02  6.22840971e-02  1.14176860e-02 -1.16614923e-02\n",
            " -4.55626659e-02  7.67744109e-02 -2.98364088e-04 -1.28241956e-01\n",
            " -4.41542119e-02  9.67953634e-03 -1.90619566e-02  4.96280789e-02\n",
            "  3.76853719e-03 -4.32323292e-02  1.08705284e-02 -4.14349735e-02\n",
            "  5.25175072e-02  1.25181470e-02  1.78018305e-02  6.76568598e-02\n",
            " -9.03864484e-03  5.76379374e-02 -7.46344775e-02  1.25002936e-01\n",
            " -2.57860962e-02 -6.97813332e-02  5.92910219e-03 -3.11910771e-02\n",
            " -6.59263805e-02  5.06343320e-02  4.77103852e-02 -5.72831556e-02\n",
            "  1.06889799e-01 -8.75040591e-02 -3.27739902e-02  3.51999514e-02\n",
            " -6.41465262e-02  2.33596805e-02 -7.51506388e-02 -8.53238776e-02\n",
            "  1.75284706e-02  3.41064893e-02  1.56858768e-02 -2.71827038e-02\n",
            " -2.43727993e-02 -3.77634317e-02 -1.10043874e-02 -7.88366571e-02\n",
            " -2.41934229e-02  1.40092941e-02 -8.58632475e-02  6.61082417e-02\n",
            " -3.93689703e-03  7.31547549e-02 -4.34269104e-03  8.63028169e-02\n",
            "  4.38812980e-03  5.49924299e-02 -4.73805815e-02  3.99860600e-03\n",
            "  5.38485125e-03  2.55900472e-02 -1.82909879e-03 -3.81263569e-02\n",
            " -1.48946298e-02 -7.85993834e-05  2.59521585e-02 -7.13284984e-02\n",
            "  1.53351147e-02  9.21152309e-02  3.21124792e-02 -2.90207528e-02\n",
            "  2.01382376e-02 -9.76907741e-03  4.27037627e-02  5.43488190e-02\n",
            "  9.05653834e-03  1.28073478e-02  8.69691838e-03 -4.64120060e-02\n",
            "  1.00138739e-01 -3.77678871e-02 -6.82712123e-02  4.45093252e-02\n",
            "  2.55980268e-02  3.33015323e-02  1.37514540e-03  7.91620463e-02\n",
            "  5.33589628e-03  6.41379505e-03  7.25758821e-02 -8.89433697e-02\n",
            " -2.76206154e-02 -6.82957750e-03  1.17878849e-02 -1.65326037e-02\n",
            "  8.11376497e-02 -8.28035474e-02 -2.78930813e-02  2.60389261e-02\n",
            " -7.77106956e-02 -3.51237729e-02 -5.80377430e-02 -5.27555775e-03\n",
            " -2.04459988e-02 -6.73912019e-02  4.34752963e-02  1.29048109e-01\n",
            " -1.73384156e-02  2.50784941e-02 -1.22695174e-02 -1.65014565e-02\n",
            " -5.76263433e-03  1.52480686e-02 -2.97990981e-02 -4.79244382e-33\n",
            "  5.28013296e-02  7.33461743e-03  7.00167865e-02  6.22049384e-02\n",
            "  9.91050974e-02 -8.86292681e-02  2.95151435e-02 -1.00939022e-02\n",
            " -6.88730255e-02 -1.03564568e-01  3.45846154e-02  6.11346215e-02\n",
            " -7.45389014e-02  2.22821217e-02  6.56385943e-02 -2.02801488e-02\n",
            " -2.52943244e-02  6.42081052e-02  3.09955124e-02  2.19347924e-02\n",
            "  4.63027470e-02 -3.99163328e-02  1.81841571e-02  3.03558423e-03\n",
            "  4.62711975e-02  4.17312831e-02  1.05420142e-01 -1.64101366e-02\n",
            " -5.28567471e-03  3.23588438e-02 -4.97660562e-02 -4.57246937e-02\n",
            " -4.92537245e-02  8.22141469e-02 -5.09387022e-03 -2.69535203e-02\n",
            "  2.05985699e-02 -1.00338936e-01  9.24681798e-02 -7.28707910e-02\n",
            " -1.98381431e-02  8.96491017e-03  2.22196374e-02 -3.58843207e-02\n",
            " -1.39768394e-02  1.12140765e-02  2.73207929e-02 -4.28717621e-02\n",
            " -9.52325761e-03 -8.30746780e-04  7.40773380e-02  4.43141675e-03\n",
            " -3.47585790e-02  4.25485820e-02 -2.28007138e-03  6.99380711e-02\n",
            " -2.52641737e-02  9.38149460e-04  1.16398814e-03  6.31657764e-02\n",
            "  1.62433065e-03 -2.49053352e-02  4.81889099e-02  2.98557095e-02\n",
            "  5.40553555e-02  3.78350914e-03 -7.51993507e-02 -3.47679891e-02\n",
            "  9.13024992e-02 -1.62627697e-02 -2.91971564e-02 -6.07180037e-02\n",
            "  1.88680068e-02  1.13490611e-01 -1.04703810e-02 -2.27434691e-02\n",
            "  8.72746203e-03 -5.30350655e-02 -6.86076609e-03  2.92359255e-02\n",
            " -1.02078810e-01 -5.79522029e-02 -1.06354766e-02  1.44402345e-03\n",
            " -8.75108968e-03 -5.26745385e-03  4.35700826e-03 -5.49821593e-02\n",
            " -4.45146747e-02 -6.58725649e-02 -3.62505764e-02  3.67284985e-03\n",
            "  3.42895091e-02 -2.48545390e-02  1.15547990e-02  1.71503101e-33\n",
            " -2.98722442e-02 -4.98722196e-02 -4.45709638e-02 -1.00275250e-02\n",
            " -5.46777360e-02 -6.80583864e-02 -1.68592632e-02  8.95447955e-02\n",
            " -5.65683730e-02 -1.28280045e-02  6.47371821e-03 -3.13318633e-02\n",
            "  8.09310973e-02  3.99142951e-02  2.37287804e-02 -3.27038951e-02\n",
            "  8.50260928e-02 -4.76658866e-02  9.36628804e-02  6.85150772e-02\n",
            " -3.74760851e-02  4.24397215e-02 -8.79168138e-02  2.82782353e-02\n",
            "  1.47300111e-02 -2.78919395e-02 -1.24962457e-01  2.40772069e-02\n",
            "  6.11082138e-03  5.83407991e-02 -6.19620867e-02 -7.95459971e-02\n",
            " -3.21913175e-02  7.13235022e-06 -6.83268458e-02 -3.41291050e-03\n",
            "  5.44292666e-02 -3.05308960e-02 -1.14762690e-02  7.71048432e-03\n",
            "  6.22622594e-02 -6.24081641e-02 -6.86496794e-02 -4.82828543e-03\n",
            " -3.89486104e-02  1.51391455e-03 -1.29737377e-01  4.46654744e-02\n",
            "  2.12696735e-02 -1.15378007e-01  4.27665226e-02  2.63186730e-02\n",
            "  3.54023390e-02 -9.39959809e-02 -5.61327152e-02  6.47926470e-03\n",
            "  1.05140246e-02 -4.50021103e-02  3.89499916e-03 -3.78889777e-02\n",
            " -8.47511068e-02 -1.09744482e-02  5.00933789e-02 -1.86896417e-02\n",
            "  1.34167708e-02 -4.44801040e-02 -6.13192208e-02 -4.57159802e-02\n",
            " -8.52094311e-03 -6.73257783e-02  1.06705047e-01 -1.50398044e-02\n",
            " -7.74394125e-02  1.57625511e-01 -8.25693309e-02 -5.52605242e-02\n",
            "  1.28531281e-03 -7.19016120e-02  4.28167693e-02 -3.72042097e-02\n",
            "  5.56360632e-02  1.18082564e-03  7.36787170e-02 -3.23333591e-02\n",
            "  8.19200203e-02 -2.87157134e-03  3.99340279e-02  7.23116398e-02\n",
            " -8.36497545e-03  3.40525210e-02  1.74638666e-02  8.11351985e-02\n",
            " -1.19376229e-02  1.15841962e-01 -7.62149245e-02 -1.85255757e-08\n",
            " -3.20125222e-02 -1.77355167e-02 -9.22637247e-03 -2.59819683e-02\n",
            " -6.02092892e-02 -3.12708430e-02  4.79910411e-02  6.37567742e-03\n",
            " -4.25928831e-02  2.10380536e-02 -3.34033184e-02  5.79826608e-02\n",
            " -8.88542756e-02  3.66439484e-02 -2.80625131e-02  8.05626065e-02\n",
            "  5.73930331e-02  8.19329172e-02 -6.25170693e-02  5.15036136e-02\n",
            "  4.03375365e-02  1.25347853e-01 -3.60252000e-02  3.02398652e-02\n",
            "  3.41895297e-02  2.74788830e-02  1.54778231e-02  1.02420293e-01\n",
            "  2.33931523e-02 -4.59968299e-02  4.36004158e-03  2.75835227e-02\n",
            " -5.38331270e-02 -1.82582438e-03  1.08088097e-02  8.37563798e-02\n",
            " -5.17501123e-02 -3.43644619e-02  6.14638403e-02 -5.48160784e-02\n",
            "  6.55460507e-02  3.88206728e-02 -2.90275011e-02  1.42789888e-03\n",
            "  2.33381037e-02 -2.58280300e-02 -1.80762112e-02 -3.96715626e-02\n",
            "  6.20535426e-02  9.06024873e-03 -5.11900932e-02  1.37582207e-02\n",
            " -5.57624511e-02 -4.23544124e-02 -2.55155768e-02  1.38223013e-02\n",
            " -8.79707374e-03 -2.24828161e-02  4.62860614e-02 -4.53305505e-02\n",
            "  5.06856591e-02  3.23015675e-02  1.23245113e-01  3.44341993e-02]\n",
            "Document 2 embedding shape : [-1.52105503e-02 -4.03294452e-02 -4.30225059e-02  2.86607277e-02\n",
            "  1.37794632e-02  4.40361872e-02 -9.87525377e-03 -1.69923212e-02\n",
            " -3.53615582e-02  1.66271627e-02  1.73859373e-02  5.84392846e-02\n",
            "  8.30492303e-02 -4.55530770e-02 -7.90818557e-02  8.22227821e-02\n",
            "  1.38309551e-03 -3.04494053e-02 -4.01782207e-02 -5.44146560e-02\n",
            "  2.42237244e-02  6.73671067e-02  3.45584080e-02  9.64815728e-03\n",
            " -1.03450613e-02 -6.44609481e-02 -9.54928026e-02  3.93859334e-02\n",
            "  3.76359299e-02 -4.80186641e-02  2.94843595e-02  1.19886532e-01\n",
            "  6.30062073e-02  2.22029183e-02 -8.26340169e-02 -5.60567342e-02\n",
            " -9.03789029e-02 -6.14978373e-02  6.57904670e-02 -2.67614499e-02\n",
            " -2.50543430e-02 -2.40562242e-02 -8.45099147e-03 -8.96348897e-03\n",
            "  7.36087710e-02  2.47561354e-02 -1.18029699e-01 -2.27563493e-02\n",
            "  6.45132642e-03  7.18794391e-02 -9.19988900e-02  3.88024710e-02\n",
            " -1.05323799e-01  4.64360453e-02  6.08041435e-02  2.82575320e-02\n",
            " -7.04690665e-02 -1.61752049e-02 -7.88132939e-03 -1.11320525e-01\n",
            "  4.67742085e-02 -4.92414609e-02 -5.66732623e-02  1.82921311e-03\n",
            "  9.51783210e-02  1.27986642e-02  4.51071188e-02 -4.52839062e-02\n",
            " -1.80496071e-02 -5.50589934e-02  2.31629871e-02 -7.22156987e-02\n",
            "  2.20701732e-02  2.17444468e-02 -1.71340108e-02  1.41009679e-02\n",
            " -1.51681006e-02 -1.21712368e-02 -2.77457032e-02  2.21158061e-02\n",
            "  1.86545979e-02  1.25390226e-02  7.28878826e-02  5.18056117e-02\n",
            "  1.43402377e-02 -5.35831228e-02  6.45878240e-02 -6.51540682e-02\n",
            "  1.29512986e-02  2.85146926e-02  2.97960881e-02 -8.62750113e-02\n",
            " -4.06227335e-02 -1.89045817e-02 -5.82103729e-02 -6.31747097e-02\n",
            "  8.99206474e-03 -9.67664924e-03  1.06676139e-01  3.18349190e-02\n",
            " -2.64088903e-02  4.76952195e-02 -1.06430640e-02 -8.95315930e-02\n",
            " -6.24450445e-02 -1.81988366e-02  5.34236357e-02  6.25469536e-02\n",
            "  1.40307948e-01 -9.16964486e-02  1.42374972e-03  1.99313182e-02\n",
            " -6.78319708e-02 -4.41672467e-02 -1.29629131e-02 -2.45702546e-02\n",
            "  2.49377247e-02 -1.28460536e-02  8.07481483e-02  6.87946705e-03\n",
            "  2.81213392e-02  4.76427712e-02 -3.53419222e-02 -8.41190815e-02\n",
            " -9.95797291e-02 -1.83317047e-02 -6.59527630e-02  7.38151678e-34\n",
            "  5.95783889e-02  1.22278994e-02  1.42223937e-02  6.97830394e-02\n",
            "  2.31477804e-02  8.36073458e-02 -1.97037105e-02  3.83595703e-03\n",
            " -1.11255951e-01 -6.69862032e-02 -8.03720579e-02  6.24312833e-02\n",
            "  2.47351136e-02  8.29566177e-03  7.32762367e-02 -3.92580032e-02\n",
            " -3.55127193e-02  2.71385424e-02 -5.01280697e-03 -8.67198780e-03\n",
            "  1.07817747e-01  1.52360676e-02 -4.03730199e-03 -1.09712400e-01\n",
            "  1.49312476e-02  5.21245934e-02  1.38561977e-02 -2.10708138e-02\n",
            "  1.92769337e-02  1.30183715e-02 -2.48487256e-02  4.43573445e-02\n",
            " -7.27625191e-02 -7.11247176e-02  1.44944498e-02  1.10190986e-02\n",
            " -8.75246078e-02  1.49447350e-02 -9.79281103e-05 -6.41629100e-02\n",
            " -4.95290905e-02  2.77184099e-02 -5.23171127e-02 -2.60521341e-02\n",
            " -6.53129518e-02  1.63950585e-02  4.06668492e-04 -8.13932251e-03\n",
            "  5.76437116e-02  4.96217683e-02 -7.48200938e-02  9.67746973e-03\n",
            "  3.48223448e-02  3.35898646e-03  4.49988991e-02  9.18916389e-02\n",
            "  3.01993303e-02  3.09895072e-02 -8.61397013e-02  2.57245894e-03\n",
            "  5.49266748e-02  6.67578075e-03 -1.62766743e-02  4.93089445e-02\n",
            "  3.85990366e-02 -9.44880582e-03  5.36983721e-02  2.56893728e-02\n",
            "  7.95304105e-02  5.48810326e-03  6.06826097e-02  2.58223787e-02\n",
            "  1.01696149e-01 -3.65442261e-02 -3.41382846e-02 -1.58874113e-02\n",
            "  1.91846304e-02 -4.13339846e-02 -2.49316469e-02 -9.64059383e-02\n",
            " -2.04890538e-02 -5.31728193e-02  3.54960375e-02 -1.00539848e-01\n",
            " -5.17729670e-02  2.53503434e-02  1.48407882e-02 -5.76696023e-02\n",
            "  4.59405966e-03 -2.90029496e-02  2.55173333e-02 -6.47638664e-02\n",
            " -8.26996714e-02  3.92502099e-02 -6.82790354e-02 -1.11551154e-33\n",
            "  4.62972047e-03 -3.36933471e-02  1.93696073e-03  7.06238374e-02\n",
            " -3.35211828e-02 -3.15328920e-03  4.32768241e-02  2.91773807e-02\n",
            " -2.80574299e-02  6.07536323e-02  6.06552325e-02  4.05300669e-02\n",
            " -1.59930121e-02  3.83644626e-02  3.52373272e-02  2.14355756e-02\n",
            " -2.81309467e-02 -1.05198734e-01 -1.39560387e-01  2.74615735e-02\n",
            "  3.45287961e-04  1.01671927e-01 -3.06944083e-02  8.42122287e-02\n",
            "  1.13775954e-02  9.37459543e-02  5.86442836e-02 -3.13621499e-02\n",
            " -1.43703064e-02 -3.11896205e-02 -3.66332829e-02 -5.10983868e-03\n",
            " -3.57836634e-02 -3.79045866e-02 -4.53773327e-02  6.27232715e-02\n",
            "  6.54903650e-02 -1.69830471e-02 -4.61578108e-02  5.91576919e-02\n",
            " -5.71767800e-02  1.13301985e-01 -1.12532796e-02 -6.04920685e-02\n",
            "  7.99313188e-04  3.87882963e-02 -5.29574715e-02 -3.77782853e-03\n",
            "  7.37253278e-02 -6.77523017e-02  3.53471329e-03  2.44690273e-02\n",
            "  5.05527621e-03 -1.96408089e-02 -6.10620901e-02 -1.55753493e-02\n",
            " -1.16475418e-01  3.10569555e-02 -5.43182753e-02  4.96363640e-02\n",
            "  5.58285117e-02  7.09884567e-04  5.62790595e-02  1.79101303e-02\n",
            " -5.95803484e-02  2.90926691e-04 -1.95576474e-02 -1.85893681e-02\n",
            " -1.90812834e-02  2.26964988e-02  1.62984598e-02  3.31436880e-02\n",
            "  6.29101247e-02  3.92741375e-02 -6.93694875e-02 -3.01277861e-02\n",
            "  6.73843473e-02  2.47426275e-02 -3.87342423e-02 -3.79780643e-02\n",
            "  8.89643952e-02  2.11441852e-02 -2.19592471e-02  6.27879724e-02\n",
            " -5.71409948e-02 -1.06170520e-01  3.49261016e-02  2.65915096e-02\n",
            " -4.64919675e-03 -4.56129611e-02 -2.27367524e-02 -5.40025160e-02\n",
            " -2.46819761e-02  1.43722016e-02 -5.83404601e-02 -1.81397724e-08\n",
            " -7.11728558e-02 -4.28735688e-02 -7.97070265e-02  6.36381656e-02\n",
            " -1.29935835e-02  3.43434848e-02 -1.35898953e-02  5.05764261e-02\n",
            "  4.42129746e-03 -2.86189653e-02  6.60803691e-02 -7.86432251e-02\n",
            " -1.06628671e-01  1.49853388e-02  2.29048878e-02  7.76243806e-02\n",
            " -6.54335618e-02 -2.03819443e-02 -2.36686748e-02 -4.19627503e-02\n",
            "  3.16251907e-03  1.78448856e-02  2.77282391e-02  4.94777933e-02\n",
            "  4.75577563e-02 -1.03165768e-02  5.47244437e-02  8.85185003e-02\n",
            "  8.27645883e-02 -1.90361701e-02 -1.16989790e-02  1.58315077e-02\n",
            "  1.89188849e-02  4.53210175e-02  7.79340863e-02  1.53420731e-01\n",
            "  2.41255686e-02  1.34406630e-02 -4.81247939e-02  6.36329204e-02\n",
            "  2.45762821e-02 -5.52204214e-02 -5.49410563e-03  4.76982258e-02\n",
            "  2.70627718e-02 -1.73867699e-02 -2.78086513e-02  2.58571412e-02\n",
            "  7.32070729e-02 -5.14150113e-02  1.04566356e-02 -6.18800074e-02\n",
            "  1.23703144e-02  7.60570914e-02 -2.16313954e-02  4.47677448e-02\n",
            "  2.00354978e-02  9.11173783e-03  8.84070471e-02  6.59901369e-03\n",
            "  4.51566391e-02 -9.14515834e-03  3.58606353e-02  3.93501259e-02]\n",
            "Document 3 embedding shape : [-5.67824878e-02 -1.14644682e-02 -4.92303306e-03  4.57681566e-02\n",
            " -1.45376790e-02 -1.14061497e-01  1.02239307e-02  6.26936704e-02\n",
            " -5.93760945e-02  8.79705977e-03 -7.07040057e-02  3.80910710e-02\n",
            "  8.40173513e-02  6.62466511e-03  6.69983625e-02  1.53907249e-02\n",
            " -8.96240920e-02 -4.55722958e-02  5.91697404e-03 -1.54180512e-01\n",
            " -5.46175316e-02  5.77421561e-02 -2.89463736e-02 -3.55238095e-02\n",
            "  4.97841183e-03  1.82232857e-02  1.07299034e-02 -4.97973487e-02\n",
            " -2.46847700e-02  2.21409816e-02 -4.57634442e-02  3.52073982e-02\n",
            "  4.96756956e-02 -2.33077793e-03 -1.56080062e-02  2.53876634e-02\n",
            " -3.94237079e-02 -9.42292809e-02 -1.99125167e-02  1.96206104e-02\n",
            " -6.51230887e-02  3.13824192e-02 -3.42138298e-02 -8.04915652e-02\n",
            " -2.50941142e-02  8.19876045e-02 -6.49090633e-02 -2.79821530e-02\n",
            "  4.33088094e-02  1.55185713e-02 -1.22731507e-01  2.65639694e-03\n",
            " -1.25725986e-02 -5.02758399e-02 -9.42643359e-03 -1.08933225e-02\n",
            "  7.68151730e-02 -1.85113475e-02  9.89938434e-03 -1.11100413e-01\n",
            " -3.87739204e-02 -1.69623247e-03  4.49368879e-02  8.03796053e-02\n",
            "  9.11499932e-03 -4.16275067e-03 -2.17810646e-02  1.96667966e-02\n",
            "  7.00255856e-02 -7.60504529e-02 -8.53833258e-02  1.83993205e-02\n",
            "  9.37820645e-04  8.97482410e-02  4.59415764e-02 -8.58943537e-02\n",
            "  5.43982089e-02 -3.99103910e-02  7.01209083e-02  9.74975526e-03\n",
            " -1.03232004e-02 -1.68161057e-02 -6.52361140e-02  8.81932601e-02\n",
            "  7.92446267e-03 -3.99676599e-02  2.32107006e-02  7.27656186e-02\n",
            " -2.06218939e-02 -2.05784524e-03  4.80416603e-02 -3.89330462e-02\n",
            "  3.64737436e-02  3.71056944e-02  8.34624656e-03  1.13155082e-01\n",
            " -1.10055078e-02 -6.33136183e-02 -2.44983621e-02  1.49941240e-02\n",
            " -2.65050549e-02 -6.11993745e-02  3.28427739e-02  2.17293296e-02\n",
            "  3.35216224e-02  1.99209899e-02  9.72115695e-02 -6.89710602e-02\n",
            "  7.42195100e-02 -2.97113173e-02 -3.73095684e-02 -2.16255784e-02\n",
            " -1.18681183e-02 -4.44394350e-02  3.78310382e-02  3.93763632e-02\n",
            " -3.26491632e-02  1.07421495e-01 -6.91715674e-03  3.37781124e-02\n",
            " -1.35379126e-02  1.39931049e-02 -1.69827752e-02  3.52267213e-02\n",
            "  2.85224896e-02 -2.97499355e-02 -5.62364049e-02 -4.13383600e-33\n",
            " -5.95651157e-02 -4.69553098e-02  4.99186963e-02  2.10182671e-03\n",
            "  7.14619309e-02 -5.30944467e-02  5.29476814e-02 -3.82042170e-04\n",
            " -7.95971900e-02 -3.88891473e-02 -3.38611268e-02  7.94590414e-02\n",
            " -1.99849196e-02  7.68563673e-02  6.59088045e-03 -1.72819607e-02\n",
            "  5.52492291e-02  6.31985813e-02  6.65351888e-03 -1.57679501e-03\n",
            "  9.02880058e-02  1.47454397e-04  4.24572080e-02  2.92815324e-02\n",
            "  1.78080183e-02 -5.19545078e-02  2.64052227e-02 -4.15359139e-02\n",
            "  7.64917731e-02  2.36786157e-02 -6.72081411e-02 -3.88811552e-03\n",
            " -6.24549948e-02  2.92217918e-02  2.23483294e-02 -4.45175776e-03\n",
            " -3.61916982e-02 -5.64179830e-02  2.37137079e-02  7.07194507e-02\n",
            " -1.95865911e-02  6.45884052e-02  2.16391142e-02 -2.77815759e-02\n",
            " -4.83531840e-02 -5.06295217e-03  1.36834877e-02  1.82447361e-03\n",
            "  8.28831340e-04 -1.21510364e-02 -2.73233652e-02 -5.33171818e-02\n",
            "  6.06793873e-02  4.95615043e-02 -2.10992116e-02  2.03725919e-02\n",
            "  1.39618507e-02  2.65104417e-02  4.87955427e-03 -5.99857755e-02\n",
            " -3.95426154e-02  4.52861637e-02  8.33627582e-02  2.08748188e-02\n",
            " -1.50737334e-02  7.36913234e-02  3.87555137e-02  7.76763707e-02\n",
            "  5.94009236e-02  6.29051179e-02 -2.27098428e-02  3.02259643e-02\n",
            " -1.71298981e-02  1.53177567e-02 -1.40244476e-02  1.66589674e-02\n",
            "  3.21645960e-02 -1.26892939e-01  4.50909548e-02  3.92358042e-02\n",
            " -3.51832919e-02 -4.69601303e-02  7.03316182e-03 -1.34333391e-02\n",
            "  1.96628328e-02 -3.56005505e-02 -1.21127637e-02  2.76564490e-02\n",
            " -1.00575890e-02 -3.45700160e-02 -7.30131418e-02 -4.63265218e-02\n",
            "  1.06083639e-02  2.82811243e-02 -5.01682311e-02  1.67845440e-33\n",
            " -4.11956348e-02 -9.37157962e-03 -3.57154161e-02  5.99487871e-02\n",
            " -2.73428131e-02 -3.09226140e-02  2.27745138e-02 -4.40216735e-02\n",
            "  6.64081872e-02  4.80954647e-02 -2.41212659e-02 -5.95974624e-02\n",
            "  1.11246087e-01  2.82865223e-02  5.40180616e-02  3.95633280e-02\n",
            " -7.30606169e-02 -2.53426805e-02 -5.30270375e-02  1.79474857e-02\n",
            " -1.02919042e-01  4.38487269e-02 -7.68340528e-02 -1.22188359e-01\n",
            "  1.60795581e-02 -3.71602103e-02 -7.04746693e-02 -2.84032598e-02\n",
            " -5.83015755e-03  5.79817258e-02 -2.94969250e-02  3.50140445e-02\n",
            " -6.63957223e-02  3.90099548e-02  8.78871307e-02  2.19021272e-02\n",
            "  5.99814281e-02 -7.56754577e-02 -6.43633865e-03 -1.11450078e-02\n",
            "  1.03886813e-01  4.63637859e-02  6.34765578e-03  4.70792577e-02\n",
            "  4.80436813e-03  3.89685854e-02 -6.53810203e-02  1.26548365e-01\n",
            " -3.34138572e-02 -5.27448915e-02 -9.76907555e-03  2.48545315e-02\n",
            "  2.50360724e-02 -6.06893189e-02 -3.27545591e-02 -1.42279649e-02\n",
            "  4.83402424e-02  5.59534281e-02 -1.14415675e-01  1.35067590e-02\n",
            " -9.44086835e-02 -5.33354580e-02  5.92016578e-02  6.82320027e-03\n",
            " -5.69625646e-02  5.83290532e-02 -9.09408033e-02 -1.25703150e-02\n",
            " -6.58161864e-02 -1.43005699e-01  1.15577132e-01  2.55574007e-02\n",
            " -1.68607216e-02  7.67784640e-02 -7.61947036e-02  3.69471274e-02\n",
            " -2.86371913e-02 -1.15220789e-02 -2.15001293e-02  9.01207775e-02\n",
            "  9.92629230e-02 -1.58842355e-02 -2.20956909e-03  2.05008611e-02\n",
            " -6.50705546e-02  2.73253489e-02 -1.28740789e-02  2.10957043e-03\n",
            " -1.06459782e-02  1.09665943e-02 -5.51102981e-02  6.99442020e-03\n",
            "  1.40729388e-02  1.82576571e-02 -4.62836511e-02 -1.81030266e-08\n",
            " -7.02789612e-03  6.06934214e-03  1.17061429e-01  4.36783545e-02\n",
            "  2.81113889e-02  8.19072872e-02 -1.85473226e-02  1.13238348e-04\n",
            " -4.27925028e-02  1.74253713e-02  9.54179466e-03 -6.09245412e-02\n",
            " -3.12316567e-02 -6.41117990e-02  1.98698230e-02  9.68015417e-02\n",
            "  4.27569747e-02 -8.23675022e-02  2.45993398e-02  1.85373686e-02\n",
            "  8.08327496e-02 -3.65415327e-02 -1.77106764e-02  4.09430861e-02\n",
            " -6.26695603e-02 -5.22883497e-02  5.41183539e-02  5.43911103e-03\n",
            " -5.37767373e-02 -9.02008787e-02 -1.95650104e-02 -9.02476385e-02\n",
            "  1.25186890e-02 -7.42936367e-03  8.25591087e-02  2.04072949e-02\n",
            "  6.72858581e-03 -6.84813038e-02 -2.76765320e-02 -5.52734942e-04\n",
            " -2.59659346e-02  8.23292658e-02  3.11275162e-02 -1.08847069e-02\n",
            "  5.32217361e-02  5.86937256e-02 -9.92478710e-03 -5.29050753e-02\n",
            "  9.09485016e-03 -1.64302047e-02 -1.33012692e-02 -3.73438895e-02\n",
            " -2.13962793e-02  1.13829440e-02  8.43969062e-02  6.74920455e-02\n",
            " -1.03823975e-01 -2.24657133e-02 -2.20047794e-02  4.15787734e-02\n",
            "  2.41896212e-02  1.34491146e-01  1.22157291e-01 -8.53224937e-03]\n",
            "Document 4 embedding shape : [-5.46357520e-02  1.27158244e-04 -7.70270173e-03  2.69743912e-02\n",
            " -5.42231761e-02  6.88595697e-02  1.04537457e-02 -1.67532787e-02\n",
            "  5.81600098e-03 -3.33996527e-02  2.81184055e-02  4.54580551e-03\n",
            "  4.92625833e-02 -3.80217284e-02 -1.58905890e-03  5.09764999e-02\n",
            "  1.81086846e-02  6.60578236e-02 -2.70782448e-02 -5.93721829e-02\n",
            " -1.59767997e-02  7.11852014e-02  2.94597503e-02 -3.46867479e-02\n",
            "  3.27738859e-02 -1.52558961e-03 -2.33830810e-02 -3.78404441e-03\n",
            "  1.11712620e-01 -1.98158398e-02  1.67522840e-02  1.30039155e-01\n",
            " -4.86467779e-02  5.03717028e-02 -6.70155436e-02  8.64468887e-02\n",
            " -1.12496890e-01  1.26502633e-01 -4.84905933e-04 -4.12528887e-02\n",
            " -3.81221808e-02  1.65307596e-02  5.57648353e-02 -3.51131372e-02\n",
            "  6.39713854e-02 -6.49264380e-02 -1.13633782e-01 -1.14484504e-02\n",
            " -2.17739139e-02 -1.75447557e-02 -3.49161625e-02 -6.48188358e-03\n",
            " -4.59704138e-02 -5.02182078e-03  2.59448984e-03  2.06552614e-02\n",
            "  2.08019558e-02 -1.67694185e-02 -6.27312958e-02 -6.51579201e-02\n",
            " -5.83333783e-02 -1.28433034e-01 -8.95716473e-02 -3.04010650e-03\n",
            "  1.03511333e-01 -3.71537171e-02  6.96535707e-02  3.66945080e-02\n",
            " -4.51173075e-02  2.69803777e-02 -1.28771156e-01 -1.94374286e-02\n",
            " -1.14249308e-02  1.43442228e-01  4.24371921e-02  1.26156256e-01\n",
            "  2.99411658e-02 -6.48378730e-02  4.09010090e-02  4.25189622e-02\n",
            " -3.57433259e-02  9.13919881e-03  4.38818522e-02  7.60017782e-02\n",
            "  1.98263507e-02  4.12222892e-02  2.66700611e-02 -1.30111426e-02\n",
            " -2.44123153e-02  1.47738832e-03 -4.82454244e-03 -6.40331730e-02\n",
            "  3.11710145e-02 -3.89383622e-02  1.92078413e-03  6.00805180e-03\n",
            "  7.75502771e-02 -1.76004285e-03 -6.44009677e-04  2.50302162e-02\n",
            "  8.90284404e-02  7.16205686e-02  1.74705684e-02 -1.46845058e-02\n",
            " -5.04415706e-02 -4.91310433e-02  2.10732259e-02 -3.25616187e-04\n",
            "  1.14327688e-02 -7.32405931e-02  9.62882210e-03  6.62152609e-03\n",
            "  6.56681880e-02 -4.44139652e-02 -2.79069934e-02  1.47027550e-02\n",
            " -1.05864182e-02 -3.20274048e-02  5.87791540e-02 -3.53999026e-02\n",
            " -7.15358416e-04  3.14661711e-02  1.77696627e-02  1.79199055e-02\n",
            " -3.27257402e-02 -1.64549593e-02  7.08858743e-02 -5.04324362e-33\n",
            "  3.09130345e-02 -5.15313633e-03  2.12155432e-02  1.02006912e-01\n",
            " -1.37459161e-03  2.32409015e-02  2.74263024e-02  3.85354683e-02\n",
            "  8.20449088e-03 -4.56706993e-02 -4.73798215e-02  5.55609465e-02\n",
            "  3.81087745e-03  6.63295761e-02  7.67208189e-02  9.69432108e-03\n",
            " -7.72124007e-02  4.04760540e-02  5.67096286e-03  3.70186269e-02\n",
            " -2.73494385e-02  8.48737732e-03  5.21140620e-02 -7.66922086e-02\n",
            " -3.53095494e-02  2.47848872e-02  7.70256072e-02 -4.62756120e-02\n",
            " -3.16907391e-02 -8.97666265e-04 -7.06283525e-02  2.68885680e-02\n",
            " -5.74465916e-02  3.10677476e-03 -7.63026485e-03  2.46573556e-02\n",
            " -2.78292783e-03 -1.39724920e-02  1.70878088e-03  1.01609128e-02\n",
            "  2.07385104e-02  7.15884147e-03  3.00273411e-02 -2.93784328e-02\n",
            " -2.01353878e-02 -1.68099941e-03  3.95284630e-02 -6.26594480e-03\n",
            " -3.45647931e-02  5.75441197e-02  4.39507663e-02  6.53509423e-02\n",
            " -7.81779587e-02 -9.40737948e-02  4.39044982e-02  3.98493446e-02\n",
            " -4.35556807e-02  2.42331717e-02 -6.68068184e-03  7.92278424e-02\n",
            "  4.80202697e-02  6.34845197e-02  7.19518661e-02  8.08375031e-02\n",
            "  5.29067367e-02  4.32134829e-02  2.06814497e-03 -7.12051475e-03\n",
            "  1.08972535e-01  1.30645093e-02  2.02371590e-02 -8.98959488e-02\n",
            " -8.31510965e-03 -2.02463809e-02  4.92943302e-02 -7.37305284e-02\n",
            "  9.56200808e-03 -3.20263654e-02  6.39032871e-02 -6.84846938e-02\n",
            "  4.13518697e-02 -4.06197784e-03 -9.00315419e-02 -7.16975778e-02\n",
            " -2.46912567e-03 -8.92799348e-02  3.63815650e-02 -1.33328423e-01\n",
            " -2.57240701e-02 -5.41805327e-02  2.82775797e-02  7.90754799e-03\n",
            " -2.61952002e-02  5.25953658e-02  1.82722732e-02  3.54067715e-33\n",
            "  5.13755120e-02 -5.57303242e-02 -3.66186276e-02  5.28501756e-02\n",
            "  6.15522778e-03 -9.83442180e-03  1.33805182e-02 -1.99425942e-03\n",
            " -8.40430185e-02  1.56702977e-02 -1.77212767e-02  3.34364511e-02\n",
            " -3.63173597e-02  1.01193665e-02 -4.79333568e-03 -7.27813831e-03\n",
            " -5.16504608e-02 -4.31693308e-02 -5.80610931e-02  7.60285556e-02\n",
            "  5.65473223e-03  5.99335581e-02  2.61878204e-02  1.22662568e-02\n",
            " -2.44035739e-02  3.77846286e-02  7.16548562e-02 -4.46662679e-02\n",
            " -2.67438367e-02  1.76409129e-02  3.69849466e-02 -3.43905799e-02\n",
            "  3.62202153e-02 -1.10243354e-02 -3.12932432e-02  4.53231391e-03\n",
            "  1.36003122e-01  5.55980578e-03 -1.01914942e-01  2.21101493e-02\n",
            " -3.63781974e-02  5.50885743e-04 -5.18695777e-03  6.31726086e-02\n",
            " -2.27542948e-02  1.73997432e-02 -9.26989913e-02 -9.15262941e-03\n",
            "  1.16767734e-02  3.90028991e-02  6.16094097e-02 -3.60274240e-02\n",
            " -2.15543378e-02 -1.26167879e-01 -4.86763604e-02 -8.32062662e-02\n",
            " -3.22044231e-02 -7.95516744e-02 -5.98625420e-03  5.70311509e-02\n",
            " -3.92052494e-02  2.21937516e-04 -2.31402298e-03 -5.09107336e-02\n",
            "  6.12646267e-02 -9.58357099e-03 -4.33077924e-02 -6.10137079e-03\n",
            " -1.34745374e-01  1.47780083e-04 -2.02482435e-04  1.65576674e-02\n",
            "  6.26907498e-02 -8.81883502e-02  1.03805274e-01  1.97437068e-04\n",
            "  3.10386494e-02  4.13434440e-03 -3.14289588e-03 -1.21190675e-01\n",
            " -1.03332765e-01 -2.23530289e-02  9.24946181e-03  1.32495612e-01\n",
            " -1.10125326e-01 -4.83140871e-02 -1.75064299e-02  6.51460662e-02\n",
            "  1.53522352e-02  2.28076167e-02 -1.11518819e-02  2.70635784e-02\n",
            " -1.41425738e-02 -1.87000316e-02  1.78122763e-02 -1.85311393e-08\n",
            " -1.09810410e-02 -1.60445385e-02 -4.13044915e-02  6.45752996e-02\n",
            " -4.40457882e-03  2.11372711e-02 -1.11994743e-01  6.74661174e-02\n",
            " -2.15241145e-02 -1.39679965e-02  5.33679780e-03  6.01632334e-03\n",
            " -7.39532411e-02  3.87553722e-02  6.79903999e-02 -2.84475423e-02\n",
            "  1.94434132e-02  4.14451472e-02 -6.74190372e-02 -6.64652139e-02\n",
            "  5.99422231e-02  9.94315296e-02  4.69670072e-02  5.23944665e-03\n",
            "  1.91584323e-02  1.89195797e-02 -1.08885858e-02  7.49018863e-02\n",
            "  6.49186671e-02 -3.30282263e-02  7.61585832e-02 -4.43893075e-02\n",
            " -4.66771200e-02 -5.88234887e-03  3.69317196e-02  1.08537450e-03\n",
            " -6.81564771e-03 -7.18016550e-02  6.40504360e-02 -1.20714139e-02\n",
            "  1.00819627e-02  5.42198084e-02 -7.45679578e-03  2.60529425e-02\n",
            " -1.19823832e-02 -2.74266489e-02 -2.94116680e-02 -3.93355675e-02\n",
            " -2.86453925e-02 -9.07878354e-02 -7.79111981e-02 -1.09395951e-01\n",
            "  5.50343879e-02  6.11105887e-03  7.18169734e-02 -6.43915171e-03\n",
            "  4.95684780e-02 -2.72401087e-02  6.05828874e-02  3.81605849e-02\n",
            "  1.45518020e-01  4.67337817e-02 -5.60232140e-02  3.96066718e-02]\n",
            "Document 5 embedding shape : [ 3.64890695e-02  2.43185535e-02 -9.58898664e-03  4.52007987e-02\n",
            " -1.05355438e-02 -1.75855961e-02 -9.01458636e-02  3.96138690e-02\n",
            " -1.03991469e-02  2.10804306e-02 -5.80845997e-02  4.11359072e-02\n",
            "  1.20233856e-02  5.85229276e-03 -1.00798652e-01 -8.29203241e-03\n",
            " -5.20715564e-02 -9.27521032e-04 -3.62592787e-02 -2.74952594e-02\n",
            "  8.50518718e-02  3.58295217e-02 -2.27171974e-03 -9.70483944e-02\n",
            " -2.58007795e-02  1.75036881e-02 -5.67751639e-02 -1.86394379e-02\n",
            "  1.43194692e-02 -3.51211019e-02 -1.22796157e-02 -3.97897586e-02\n",
            "  5.97408935e-02  1.15791097e-01 -1.08151145e-01  3.47706787e-02\n",
            " -1.57164615e-02 -1.51580842e-02 -1.86457392e-02  2.31554229e-02\n",
            " -3.31503414e-02 -1.99762881e-02 -7.04385489e-02 -6.41950816e-02\n",
            "  4.28762212e-02 -4.78005521e-02 -4.08833772e-02 -1.49068991e-02\n",
            "  4.55454830e-03  6.75189421e-02 -1.08839326e-01 -5.20038269e-02\n",
            " -2.44817417e-02 -1.63292736e-02  1.51839666e-02  4.87852953e-02\n",
            " -3.33499759e-02 -3.69841978e-02 -3.91835123e-02 -8.19910690e-02\n",
            "  9.19927210e-02 -2.34102514e-02 -1.73078049e-02  3.48651819e-02\n",
            "  2.74239536e-02  1.10841431e-02  8.91624317e-02  2.33260309e-03\n",
            "  8.64318758e-02 -1.33371606e-01  3.19878235e-02 -1.81165468e-02\n",
            " -2.86930054e-02  7.74825960e-02  7.96891749e-02  2.28351112e-02\n",
            "  3.75730917e-02  1.28457770e-02  7.15051517e-02  8.07793513e-02\n",
            " -1.47626363e-02 -8.31468627e-02 -6.61695749e-02  2.41211094e-02\n",
            "  2.32198481e-02 -7.24848360e-02  5.87804317e-02 -7.68734142e-02\n",
            "  2.76896562e-02  1.49858221e-02  3.31544802e-02 -6.69898093e-02\n",
            "  7.02358857e-02 -4.38135192e-02  4.46679704e-02  3.23023200e-02\n",
            " -8.64953548e-02  2.02934518e-02  1.71858147e-02 -1.72727555e-02\n",
            " -1.70455221e-02 -1.97774451e-03 -2.67119259e-02 -5.77284023e-02\n",
            " -7.83218890e-02  1.95523016e-02  1.53755080e-02  7.70557448e-02\n",
            "  4.09763977e-02 -3.90674584e-02 -6.41814386e-03  4.08604816e-02\n",
            "  4.32389695e-03 -1.76697709e-02 -1.65168308e-02  4.17987332e-02\n",
            " -2.38284803e-04 -1.10169090e-02  7.81349093e-02  9.79775190e-02\n",
            "  5.69216907e-02  2.80338954e-02  1.77253634e-02 -6.88015595e-02\n",
            " -1.85465422e-02  6.46557212e-02 -3.19615975e-02 -1.20659054e-34\n",
            "  4.97186854e-02  5.38902730e-02  8.62750516e-04 -4.10187729e-02\n",
            " -6.50952086e-02  1.05632916e-02  1.61576811e-02  9.29513872e-02\n",
            " -1.01150289e-01 -5.38379215e-02 -5.19392155e-02  1.48179680e-01\n",
            "  1.17648598e-02  1.57034863e-02  8.11475739e-02 -1.57767422e-02\n",
            "  1.33560356e-02  3.73372212e-02  4.20849882e-02  1.60488933e-02\n",
            "  9.52369571e-02 -9.41853505e-03 -2.34117731e-02 -6.05539232e-02\n",
            "  2.67729722e-02 -3.63881662e-02 -5.37195615e-03 -3.16445380e-02\n",
            "  2.19713245e-02  2.32384261e-02 -2.62783039e-02 -4.82318699e-02\n",
            " -6.61353096e-02 -1.98866380e-03  8.44675582e-03  3.83175872e-02\n",
            " -1.14122406e-01  5.23676686e-02  3.57706025e-02  4.10925737e-03\n",
            " -5.66693768e-02 -2.51379795e-02  1.89537019e-03 -4.93094586e-02\n",
            " -3.60151306e-02 -1.52766192e-03 -1.00886561e-01 -1.64638218e-02\n",
            "  1.27189130e-01  7.31228152e-03  4.71091531e-02 -2.45997068e-02\n",
            "  4.72770147e-02  5.82863316e-02  8.04947019e-02  1.21069305e-01\n",
            "  3.46153378e-02  8.54782239e-02 -4.78014871e-02  4.11608778e-02\n",
            " -1.77150182e-02 -1.35104423e-02  6.16610982e-02  5.39000332e-02\n",
            "  5.47858179e-02 -2.16573160e-02  3.23488563e-02  5.43663390e-02\n",
            "  1.06285641e-03  8.00160170e-02  1.56579278e-02  2.88901925e-02\n",
            "  1.11792862e-01 -2.09794622e-02 -4.28080037e-02 -2.06686277e-02\n",
            "  9.92331002e-03  1.36776902e-02 -4.12782580e-02 -3.30020227e-02\n",
            " -9.31719616e-02 -3.36541682e-02  2.75474861e-02  2.31034923e-02\n",
            " -1.73749849e-02  2.70736571e-02 -3.92900668e-02  1.37070019e-03\n",
            " -1.07601667e-02 -4.32345010e-02  1.45852671e-03  5.41391447e-02\n",
            " -7.24443495e-02 -4.38975915e-02 -2.27570366e-02 -4.32755077e-34\n",
            " -5.11531718e-02 -1.22774936e-01 -2.51536979e-03  9.55067500e-02\n",
            " -5.87000651e-03 -2.25444753e-02 -5.08226417e-02  3.23026837e-03\n",
            " -8.75295103e-02  4.55386862e-02  2.75189783e-02 -4.15755771e-02\n",
            "  2.95660961e-02 -3.03266607e-02 -7.22365901e-02  1.46545880e-02\n",
            "  3.50801414e-03 -1.10795073e-01 -1.61172543e-02  2.52258480e-02\n",
            " -8.07656571e-02  5.34472689e-02 -6.88950941e-02  1.27408914e-02\n",
            "  4.85004392e-03 -7.32936859e-02 -2.73562204e-02 -2.96785776e-02\n",
            " -9.36532095e-02  3.69704235e-03 -1.49965100e-02 -4.11449447e-02\n",
            "  4.17091288e-02  1.09202387e-02 -9.03810933e-02  7.22268745e-02\n",
            "  3.48257013e-02 -3.56184095e-02  2.74132639e-02  1.83880003e-03\n",
            " -2.46707071e-03  1.12800546e-01  2.50246245e-02 -4.10664417e-02\n",
            "  1.84483826e-02  4.92639765e-02 -8.40616450e-02  5.44032417e-02\n",
            "  1.89792700e-02 -4.26071659e-02 -1.75260659e-02  1.15695409e-02\n",
            "  3.27972844e-02 -4.61951271e-02 -3.80001180e-02 -2.34207250e-02\n",
            " -7.04936758e-02  4.65152860e-02 -7.45535716e-02  4.12009060e-02\n",
            " -4.49436530e-02  4.37605530e-02 -2.21034978e-02  6.99524134e-02\n",
            "  3.22111771e-02 -8.60543735e-03 -6.34161830e-02 -1.26854004e-02\n",
            " -1.31649911e-01 -9.17234123e-02  6.42196462e-02 -5.45065589e-02\n",
            "  7.08951801e-02  1.23970628e-01  7.57889729e-03 -4.02745418e-03\n",
            "  3.54956985e-02  2.24202368e-02 -6.52391813e-04 -1.93411540e-02\n",
            "  5.03223874e-02  3.13243791e-02  2.92997099e-02  2.61571649e-02\n",
            " -3.83340046e-02  9.59460661e-02 -1.40923122e-02  5.32534793e-02\n",
            " -5.27510010e-02  2.22748164e-02 -1.25625702e-02 -8.37855637e-02\n",
            " -7.53328651e-02 -5.69975935e-02 -2.27216799e-02 -1.66295120e-08\n",
            "  2.52113529e-02  1.66430809e-02  4.02357578e-02  4.44033667e-02\n",
            "  4.29148488e-02  2.06413567e-02  4.26254943e-02  1.27174661e-01\n",
            " -7.31414631e-02 -2.62328517e-02  8.10807757e-03 -2.50898041e-02\n",
            " -9.97600630e-02  3.19157951e-02  6.24847487e-02 -2.30639093e-02\n",
            "  5.27311489e-03  2.68771779e-02 -4.79155965e-02 -1.75510664e-02\n",
            " -5.13342582e-02  4.08189334e-02  8.86889268e-03  5.72843626e-02\n",
            "  7.87848234e-02  4.93438393e-02  5.95328165e-04 -1.43654747e-02\n",
            "  1.97047759e-02 -6.96587339e-02 -7.21849278e-02  8.09727237e-03\n",
            "  4.13703872e-03 -2.29326822e-02 -1.73680987e-02  8.87348577e-02\n",
            " -4.10196036e-02 -3.04971654e-02 -9.31305587e-02  8.23847279e-02\n",
            "  6.26402721e-02  9.38773155e-02  1.73888169e-02 -3.99620418e-04\n",
            "  1.84065606e-02 -5.12902765e-03  3.94161865e-02  6.43553212e-03\n",
            "  6.47711232e-02  4.40870551e-03 -9.94034857e-03 -4.50918600e-02\n",
            "  1.77118052e-02  1.90524925e-02 -3.92552167e-02  1.95352025e-02\n",
            " -2.33804211e-02 -3.89280692e-02  5.46142794e-02  1.53460940e-02\n",
            "  1.10464618e-01  1.36155391e-03  5.53710461e-02  4.98244166e-02]\n",
            "Document 6 embedding shape : [-3.93253192e-02  2.07073484e-02  1.17993001e-02  4.53809788e-03\n",
            "  2.11189296e-02 -3.30635370e-03  4.77206968e-02 -2.88932566e-02\n",
            "  9.05632228e-03 -3.17788050e-02  3.75054739e-02  7.63395503e-02\n",
            "  5.96735142e-02 -7.80272037e-02  3.62569615e-02 -1.87426992e-02\n",
            "  1.84915774e-02  1.00311689e-01 -9.11293626e-02 -4.94624488e-02\n",
            "  2.61914097e-02 -3.24814883e-03 -1.49220992e-02 -5.80540374e-02\n",
            "  1.02472566e-02  2.96921097e-03 -6.64433390e-02 -5.75711858e-03\n",
            "  4.58779000e-02  3.32192145e-02  2.44974159e-02  3.12939472e-02\n",
            "  1.26526475e-01  1.01889484e-01 -3.42914686e-02 -1.52545804e-02\n",
            " -9.62658748e-02  7.21311942e-02 -5.33492630e-03 -1.87255777e-02\n",
            " -7.43986741e-02 -1.66317131e-02 -3.20761651e-02  1.45382127e-02\n",
            "  8.48746896e-02  1.74327306e-02 -9.47940946e-02  3.33058946e-02\n",
            "  7.40561401e-03 -8.38968810e-03 -1.41423836e-01  5.15629686e-02\n",
            " -4.11029570e-02 -1.14245275e-02 -4.54121120e-02  7.26784617e-02\n",
            " -2.49773245e-02 -3.44863757e-02  1.49069661e-02 -6.20743111e-02\n",
            "  3.04495059e-02 -4.23111171e-02 -4.34814543e-02  8.42489488e-03\n",
            "  3.25921811e-02 -7.67109022e-02  3.43939550e-02 -3.25264595e-02\n",
            "  6.80417717e-02 -2.78219040e-02  2.39784382e-02  9.82614681e-02\n",
            " -1.81499626e-02  3.20419259e-02 -4.87132631e-02  6.28551915e-02\n",
            " -5.05867712e-02 -2.15619407e-03  3.52260619e-02  1.51481908e-02\n",
            "  3.50533490e-04 -7.82316551e-02  4.83365683e-03  3.31265554e-02\n",
            "  5.69287390e-02 -6.05278760e-02  7.50829428e-02 -7.36021176e-02\n",
            " -3.11463755e-02 -1.63388848e-02  5.01843020e-02 -1.75474375e-01\n",
            "  4.41733114e-02 -5.73814921e-02  4.83994223e-02 -1.21779144e-02\n",
            " -4.66891099e-03 -3.55516374e-02 -1.81394731e-04  3.68984565e-02\n",
            "  9.01588798e-03  5.30368015e-02 -7.56736845e-02 -1.31656587e-01\n",
            " -8.14595520e-02  4.02206443e-02  5.67942075e-02  4.28117961e-02\n",
            "  4.18325961e-02 -6.92884531e-03 -5.14510609e-02  7.01897144e-02\n",
            " -2.47132331e-02 -2.35696658e-02  1.69532485e-02  6.13205805e-02\n",
            "  5.33287041e-03  1.82785299e-02  6.34657741e-02  5.23699559e-02\n",
            " -4.27416638e-02 -1.91549435e-02 -3.93356979e-02 -7.08337547e-03\n",
            " -3.36179510e-02  1.75550543e-02 -4.18106318e-02 -6.64195726e-34\n",
            " -1.32479025e-02  5.37096150e-02 -7.32062310e-02 -8.19561183e-02\n",
            " -1.78813469e-02 -1.44538665e-02  1.76930577e-02  2.71548647e-02\n",
            "  1.36318197e-02  1.04237050e-02 -6.40229657e-02  3.98424268e-02\n",
            "  1.41688446e-02 -1.79260522e-02  5.94248436e-02  8.53800774e-03\n",
            " -3.16882320e-02  1.19652368e-01 -5.86022921e-02 -3.93872894e-02\n",
            "  9.45355967e-02 -7.51568228e-02  7.61561021e-02 -5.34429476e-02\n",
            "  3.63537064e-03 -5.17853126e-02 -3.31535973e-02 -3.48170176e-02\n",
            " -2.08264552e-02  2.47460548e-02 -2.47735735e-02 -7.04026893e-02\n",
            " -5.96522130e-02  1.16768165e-03  4.19823192e-02  2.89399084e-03\n",
            "  1.08406059e-02 -3.68768908e-02 -5.43140993e-02 -5.07316366e-02\n",
            " -1.25167698e-01  8.85267463e-03  7.93273896e-02 -7.75184482e-02\n",
            " -2.86373515e-02  3.71214338e-02 -1.08271815e-01 -9.91252717e-03\n",
            "  7.96145424e-02  2.87091061e-02  4.05911170e-02  7.76436478e-02\n",
            " -3.97702828e-02  3.39475907e-02  5.66784851e-02  6.22647069e-02\n",
            "  8.97010267e-02  3.86301912e-02  2.75077485e-02  3.85577902e-02\n",
            " -2.21071839e-02  2.75125708e-02  5.64455166e-02  7.39635900e-02\n",
            "  4.95826565e-02  3.26474085e-02  4.62518744e-02  5.90416789e-02\n",
            "  4.40412462e-02 -2.71017227e-04  3.87798883e-02 -6.41706511e-02\n",
            "  4.76143695e-02 -1.57217849e-02  2.03235559e-02  1.81325506e-02\n",
            "  5.49500659e-02 -7.79171884e-02  2.44914610e-02 -6.08633459e-02\n",
            " -4.84860921e-03 -6.36978680e-03  4.87810634e-02  2.37725172e-02\n",
            " -2.85521373e-02 -6.72790930e-02  2.59124245e-02 -9.10561755e-02\n",
            "  5.74406702e-03  1.54378619e-02  1.35838576e-02  8.15178081e-02\n",
            " -6.73029497e-02 -4.52447422e-02 -9.29569229e-02  4.41843623e-34\n",
            " -1.64114032e-02 -1.11687526e-01  4.53773066e-02  5.55224158e-03\n",
            " -1.13959890e-02  7.76215550e-03 -4.98646386e-02 -7.78966099e-02\n",
            " -1.15889115e-02 -4.25420143e-02 -3.42758521e-02  2.88823638e-02\n",
            "  5.14503047e-02 -5.20093516e-02  6.42789155e-02  1.49817439e-02\n",
            "  5.13691008e-02  5.83599806e-02 -5.47695626e-03  1.15124635e-01\n",
            "  1.96862454e-03 -2.89911008e-03 -1.19791515e-01  8.60939696e-02\n",
            " -2.18685511e-02  4.13640551e-02 -8.69423989e-03  6.61217868e-02\n",
            " -4.18422557e-02 -1.69822238e-02 -8.15109462e-02  9.37077701e-02\n",
            " -1.03858635e-01 -3.57400663e-02 -2.01416500e-02 -5.52936979e-02\n",
            " -3.02776862e-02 -8.79653543e-03  5.41396160e-03  8.83310735e-02\n",
            "  1.88401807e-02  7.77083486e-02 -3.65728475e-02 -2.24385206e-02\n",
            " -3.23408842e-02 -1.39928889e-02 -4.76553813e-02  4.98041883e-02\n",
            "  3.10262293e-02  1.80939250e-02  1.44424200e-01  1.81644391e-02\n",
            " -4.90663201e-02 -4.96031754e-02  3.20952833e-02 -1.84536690e-03\n",
            " -1.07146889e-01 -8.36460385e-03 -5.15916832e-02  2.70528868e-02\n",
            " -8.86521116e-02  4.90379930e-02 -2.60279719e-02  8.04295838e-02\n",
            "  5.90467378e-02 -8.42772499e-02 -3.36194760e-03  2.08743326e-02\n",
            " -2.53739934e-02 -6.78920895e-02  3.25892009e-02 -1.05015049e-02\n",
            " -2.32517626e-02  1.74847487e-02 -3.89081463e-02  3.55671272e-02\n",
            "  3.94483320e-02 -2.54345797e-02 -3.18387970e-02  8.62744264e-03\n",
            " -2.04323512e-02  4.33811210e-02  3.92691195e-02  2.80831605e-02\n",
            " -6.51102215e-02  5.72657734e-02 -2.59976573e-02  5.49581088e-03\n",
            "  3.37900706e-02 -1.81918461e-02  4.34197411e-02 -6.56595230e-02\n",
            " -2.98741441e-02  5.25191352e-02 -4.37826402e-02 -1.44068837e-08\n",
            "  1.30655859e-02  5.89629859e-02 -4.78696898e-02  4.88241203e-02\n",
            "  4.58139321e-03 -5.10699935e-02 -5.27470186e-02  1.25436991e-01\n",
            " -1.66469365e-02 -9.78101864e-02  5.41845970e-02 -1.19419154e-02\n",
            " -7.58830234e-02  3.19493823e-02  3.13882604e-02  4.62242067e-02\n",
            " -2.53742300e-02  1.30886771e-02 -3.41573842e-02 -1.70695800e-02\n",
            "  2.89814007e-02  6.82893395e-02  3.95236537e-02  1.88510343e-02\n",
            " -2.37178220e-03  5.46431094e-02 -4.75454517e-02  9.07937288e-02\n",
            "  4.64065857e-02  3.63625027e-02  1.96518712e-02  2.02382803e-02\n",
            " -6.96373284e-02 -1.85924559e-03  9.72372666e-02  1.64291970e-02\n",
            " -1.88916400e-02 -2.18073707e-02 -8.01114812e-02  5.80914393e-02\n",
            "  8.25843439e-02 -2.93314364e-03 -8.58876575e-03  3.52734551e-02\n",
            " -6.94501996e-02 -8.25548545e-03  2.34919228e-02  8.07921290e-02\n",
            "  4.56572361e-02 -2.92354021e-02 -5.44829331e-02  4.69181314e-03\n",
            " -5.53281382e-02 -6.12699464e-02  3.15788165e-02  4.89983484e-02\n",
            "  5.86265652e-03 -2.62223817e-02  2.60897484e-02 -3.56474072e-02\n",
            "  5.21793477e-02  3.61009967e-04 -8.02012719e-03  2.78734118e-02]\n",
            "Document 7 embedding shape : [-1.17312819e-02  1.65390857e-02 -5.01164198e-02  3.21906805e-02\n",
            " -1.06118964e-02 -4.64481767e-03  1.01748938e-02 -5.26346778e-03\n",
            "  5.02373017e-02 -6.03094362e-02  9.16142687e-02  4.14027199e-02\n",
            "  5.03314920e-02  5.58566228e-02 -1.48343118e-02  2.18899474e-02\n",
            "  1.00553930e-01  4.79729809e-02 -6.95632026e-02 -2.42071971e-02\n",
            "  4.69842739e-03  3.86661179e-02  7.30346292e-02 -1.16936369e-02\n",
            " -4.13443670e-02  1.27981808e-02 -8.74758046e-03  2.03366913e-02\n",
            "  2.72208569e-03 -4.67534363e-02  3.75673212e-02  1.01611167e-01\n",
            " -3.17390747e-02  1.80893224e-02 -4.07055393e-03 -1.30471541e-02\n",
            "  6.19756756e-03  7.06160255e-03  4.50681224e-02 -1.70049313e-02\n",
            " -4.15342413e-02 -4.52500731e-02 -2.69336067e-02  6.70132488e-02\n",
            " -6.73338817e-03  7.58854970e-02 -7.68306106e-02  3.16309184e-02\n",
            "  7.57075697e-02  4.08334509e-02 -8.92166048e-02  2.87297498e-02\n",
            " -6.74530268e-02 -5.00422269e-02  2.12427285e-02  3.47208530e-02\n",
            " -6.28903881e-02  1.92859881e-02 -5.67629710e-02 -9.64484364e-02\n",
            " -8.13489929e-02 -9.96240228e-02 -3.19539160e-02  1.98741183e-02\n",
            "  5.44887446e-02 -4.92259227e-02  5.05801402e-02 -7.18717054e-02\n",
            "  4.84916680e-02 -2.86763906e-02 -3.46072726e-02  1.13318205e-01\n",
            " -5.50092245e-03  7.25205839e-02 -2.07913350e-02  2.53682528e-02\n",
            "  3.30517105e-05  7.05807237e-03 -9.55957733e-03 -4.00981419e-02\n",
            " -3.47691663e-02 -4.47571538e-02  3.46532501e-02  5.09398282e-02\n",
            "  2.74431352e-02 -6.94935024e-02  1.22623093e-01 -1.20633036e-01\n",
            " -1.43540595e-02 -3.53362784e-02  4.54546371e-03 -6.67973980e-02\n",
            "  5.80981094e-03 -1.83225833e-02 -5.46642467e-02  6.97660120e-03\n",
            "  2.44541578e-02 -5.68562746e-03  9.20794625e-03  6.68296516e-02\n",
            "  7.82244727e-02  5.75480610e-03 -3.17649014e-04 -5.32394610e-02\n",
            "  6.34000730e-03  2.56585274e-02  4.64277864e-02  1.59710180e-02\n",
            "  5.39394021e-02 -1.40980750e-01  3.49518992e-02  2.26292312e-02\n",
            " -8.56554806e-02  1.75006259e-02 -7.94512499e-03  1.37171093e-02\n",
            "  3.40073183e-02 -5.38408896e-03  2.21171714e-02 -6.99190944e-02\n",
            "  3.64786983e-02  2.00477783e-02  2.17227899e-02 -5.81645854e-02\n",
            " -4.83565442e-02 -2.91238204e-02 -1.04791755e-02  7.02599345e-35\n",
            "  2.37430278e-02 -6.99953549e-03 -4.79659140e-02 -1.22769056e-02\n",
            "  9.15963762e-03 -1.74147859e-02 -6.19843975e-03  7.12819397e-02\n",
            " -7.84068555e-02 -6.13170117e-02 -1.12814665e-01  5.45684882e-02\n",
            "  1.60006769e-02 -3.17066945e-02 -1.04160598e-02  2.50270534e-02\n",
            " -1.24341264e-01  8.90208036e-02 -5.98966293e-02 -2.36779489e-02\n",
            "  6.47367388e-02 -1.86921773e-03  5.51177673e-02  7.99521629e-04\n",
            " -3.24390493e-02 -1.62396450e-02 -7.43843243e-02 -1.03404492e-01\n",
            "  3.40777822e-02 -9.82082635e-03  4.88227233e-02  4.13554050e-02\n",
            "  1.20822266e-02  9.68915119e-04  4.48083691e-03  2.38426458e-02\n",
            "  1.77077856e-02 -6.09312989e-02  8.14849604e-03 -7.95251224e-03\n",
            " -9.52686816e-02 -2.93299761e-02  6.25874028e-02 -1.06189691e-01\n",
            "  1.73177700e-02 -1.47828832e-02 -5.23589319e-03 -2.45315712e-02\n",
            "  3.20266970e-02 -4.77960929e-02  9.82024670e-02 -3.17743868e-02\n",
            "  5.61811496e-03  6.03603013e-02  1.05584346e-01 -7.50734564e-03\n",
            "  1.54785300e-02  8.89207944e-02  5.61354011e-02  9.10694972e-02\n",
            "  2.79572904e-02  1.30105317e-02  5.95228933e-02  2.99502630e-02\n",
            " -3.39690261e-02  4.16315300e-03  4.53264751e-02  6.16934113e-02\n",
            "  5.96240349e-02  7.63850436e-02  1.09570296e-02 -2.37304112e-03\n",
            "  5.19424044e-02 -6.58349469e-02  4.81657051e-02 -1.04820151e-02\n",
            " -4.13279012e-02 -5.39784320e-02 -7.59925321e-02 -8.33221991e-03\n",
            " -1.11101016e-01 -7.67949745e-02  2.30573770e-02 -8.82763267e-02\n",
            " -7.05984235e-02 -1.49038527e-02  8.59014466e-02 -8.02097693e-02\n",
            "  6.65523708e-02 -1.62034985e-02  6.33558631e-02  8.83650631e-02\n",
            " -1.88269224e-02 -4.66626324e-02  2.23219264e-02  1.41594558e-33\n",
            " -5.71760051e-02 -1.28168970e-01  5.55576086e-02  5.56771569e-02\n",
            " -4.00864929e-02 -5.95813245e-03  6.10453263e-03  6.35255035e-03\n",
            " -7.92724490e-02  7.02923583e-03  1.47384917e-02 -1.18835475e-02\n",
            " -4.53760624e-02 -3.23396362e-02  3.02682202e-02  6.75225109e-02\n",
            "  5.01260944e-02  2.62401178e-02 -3.29956338e-02  9.42772478e-02\n",
            "  5.07617835e-03  5.68934418e-02 -8.47898200e-02  3.99069712e-02\n",
            "  4.01464812e-02 -5.50419325e-03  3.82353831e-03 -4.73712198e-02\n",
            " -2.76620276e-02 -9.40077603e-02 -1.55994827e-02 -2.01331563e-02\n",
            " -5.97973280e-02 -2.14609485e-02 -3.62785868e-02 -3.09668314e-02\n",
            "  3.67688350e-02 -5.27706482e-02 -3.78924124e-02  8.46248642e-02\n",
            " -7.57172629e-02  3.24455649e-02 -2.58829258e-02  2.05637924e-02\n",
            " -2.26938911e-02 -1.91848464e-02 -1.06177516e-01 -1.77793205e-02\n",
            "  5.62063456e-02 -3.15154456e-02  1.00538298e-01  1.82187818e-02\n",
            " -1.29595017e-02 -3.41078825e-02 -8.42970703e-03 -2.46000420e-02\n",
            " -8.93554389e-02 -4.41823527e-02 -3.97802107e-02  4.90993895e-02\n",
            " -2.85120960e-02  5.93370013e-03 -4.59665246e-03  8.03495795e-02\n",
            "  7.43787661e-02 -7.47721717e-02 -3.77869532e-02  3.24371420e-02\n",
            " -2.96082571e-02  6.66462183e-02  1.32997986e-02 -7.75335589e-03\n",
            "  8.75225198e-03 -3.07396166e-02  8.42347890e-02 -6.31717732e-03\n",
            "  1.17253534e-01 -4.11136588e-03 -2.68282909e-02 -2.24134661e-02\n",
            " -5.16452007e-02  3.59169468e-02  2.13549528e-02  2.10757107e-02\n",
            " -5.45632467e-02  1.11633942e-01  5.27755991e-02  2.61179954e-02\n",
            "  6.60528056e-03  5.17490655e-02  3.52367163e-02 -1.98119432e-02\n",
            "  6.04739189e-02  1.94066316e-02  3.17009389e-02 -1.34691467e-08\n",
            " -8.10172036e-02  3.08403163e-03 -7.29759783e-02  2.47488376e-02\n",
            " -2.09103934e-02 -6.04691962e-03 -1.79727972e-02  1.43667310e-01\n",
            " -1.45760819e-01 -2.81714406e-02  9.09073353e-02  7.64116086e-03\n",
            " -4.96773683e-02  5.91623522e-02  2.95804683e-02  5.00203334e-02\n",
            " -7.90588744e-03  2.07936466e-02  1.57716833e-02  4.29680273e-02\n",
            "  2.14398075e-02  7.17050433e-02  1.77837107e-02  4.30910587e-02\n",
            "  3.26639377e-02  1.14959534e-02  1.77135561e-02  8.98237377e-02\n",
            "  9.66550484e-02 -1.69791430e-02 -6.09082766e-02 -1.57085538e-04\n",
            " -4.00422281e-03 -6.48099417e-03  7.77020305e-02  4.10458334e-02\n",
            "  2.14881971e-02 -3.11457063e-03 -1.21279813e-01  4.94695045e-02\n",
            "  4.79790345e-02 -3.65161225e-02  1.94211192e-02  1.81831960e-02\n",
            "  1.14188559e-01 -1.17854262e-02  3.44816111e-02  3.86583842e-02\n",
            "  4.59749661e-02  1.19022010e-02 -1.37043395e-03 -4.37946282e-02\n",
            " -2.02791058e-02 -3.43958214e-02  5.40969558e-02 -1.95257808e-03\n",
            " -5.79706728e-02 -9.42899380e-03  7.83752128e-02 -2.74946764e-02\n",
            "  3.46081294e-02  3.75344977e-02  3.11492980e-02  3.19956876e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX6_xsHsIPsY",
        "outputId": "f074f29f-4848-4a80-f624-01b59c4e96ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LangChain is a framework for building applications with large language models.',\n",
              " 'BM25 is a ranking function used by search engines to rank documents.',\n",
              " 'Python is a popular programming language for AI and data science.',\n",
              " 'Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.',\n",
              " 'Elasticsearch is a powerful search engine based on Lucene.',\n",
              " 'Efficient Keyword extraction enhances search accuracy',\n",
              " 'Semantic similarity improves document retrieval performance']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How to enhance the search accuracy?\""
      ],
      "metadata": {
        "id": "mEk_iloSIfYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = model.encode(query)"
      ],
      "metadata": {
        "id": "b_QGWMkhIlqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P8DiZ2oJMUi",
        "outputId": "ab117ed9-6c13-4c1f-df0f-b19f879aec25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "result = np.array([query_embedding])"
      ],
      "metadata": {
        "id": "ia5eIBtIJfDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQgUZ2DtJees",
        "outputId": "f1fe23af-ff23-43e1-851a-b85321205749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measuring the cosine similarity to get scores"
      ],
      "metadata": {
        "id": "6_oDFyWGIsAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "dIt3OD0XIng3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_scores = cosine_similarity(np.array([query_embedding]),document_embedding)"
      ],
      "metadata": {
        "id": "S9aiMxfBI3T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuZklM_rJJSt",
        "outputId": "cbb5e3bb-bedf-47e2-98ce-7ebf6a319e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09715149, 0.31864718, 0.05633681, 0.31351075, 0.38676763,\n",
              "        0.6528677 , 0.45183986]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_index = np.argmax(similarity_scores).item()"
      ],
      "metadata": {
        "id": "NkfgWoKCJdvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzdKvQqMJzx-",
        "outputId": "c97e6690-efac-41eb-c8bf-18cfe27bbef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_document = raw_docs[most_similar_index]"
      ],
      "metadata": {
        "id": "UnLlCc7JJ1et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar_document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_A84N00BJ6_-",
        "outputId": "c4892d85-54df-4ffb-caf6-f46ea09085f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Efficient Keyword extraction enhances search accuracy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices = np.argsort(similarity_scores)[0][::-1]"
      ],
      "metadata": {
        "id": "Z-BR9W0DJ95a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePjyeyM-KNp5",
        "outputId": "f37971f7-4de5-4fe8-b330-212e04458697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 4, 1, 3, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_documents= [(raw_docs[i],similarity_scores[0][i].item()) for i in sorted_indices ]"
      ],
      "metadata": {
        "id": "YimDFCotKSKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJCT2Cj1Koy-",
        "outputId": "c82f34ac-f183-487f-e0f9-630984d7df53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Efficient Keyword extraction enhances search accuracy', 0.6528676748275757),\n",
              " ('Semantic similarity improves document retrieval performance',\n",
              "  0.4518398642539978),\n",
              " ('Elasticsearch is a powerful search engine based on Lucene.',\n",
              "  0.3867676258087158),\n",
              " ('BM25 is a ranking function used by search engines to rank documents.',\n",
              "  0.318647176027298),\n",
              " ('Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.',\n",
              "  0.3135107457637787),\n",
              " ('LangChain is a framework for building applications with large language models.',\n",
              "  0.0971514880657196),\n",
              " ('Python is a popular programming language for AI and data science.',\n",
              "  0.05633681267499924)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Rank 4 Documents\")\n",
        "for i, (doc, score) in enumerate(ranked_documents[:4], 1):\n",
        "    print(f\"{i}. Document: {doc}, Similarity Score: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTSTNWddKtht",
        "outputId": "c2d38496-9984-4aa6-e387-cb444716050e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 4 Documents\n",
            "1. Document: Efficient Keyword extraction enhances search accuracy, Similarity Score: 0.6528676748275757\n",
            "2. Document: Semantic similarity improves document retrieval performance, Similarity Score: 0.4518398642539978\n",
            "3. Document: Elasticsearch is a powerful search engine based on Lucene., Similarity Score: 0.3867676258087158\n",
            "4. Document: BM25 is a ranking function used by search engines to rank documents., Similarity Score: 0.318647176027298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now performing reranking"
      ],
      "metadata": {
        "id": "hig1ha7JLOzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reanking using bm25 working on the token level working on the keyword level.\n",
        "top_4_documents = [doc[0] for doc in ranked_documents[:4]]"
      ],
      "metadata": {
        "id": "tRy8MOhyLUs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_4_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrgS8SSvLsXp",
        "outputId": "22d73d93-8bca-4738-fc49-b23909ea443c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Efficient Keyword extraction enhances search accuracy',\n",
              " 'Semantic similarity improves document retrieval performance',\n",
              " 'Elasticsearch is a powerful search engine based on Lucene.',\n",
              " 'BM25 is a ranking function used by search engines to rank documents.']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# performing the tokeniation\n",
        "tokenized_top_4_documents = [doc.split() for doc in top_4_documents]"
      ],
      "metadata": {
        "id": "e4ZLYe5dL9mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_top_4_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8alvScBFMVnF",
        "outputId": "79aef398-120a-4d38-de22-ab9c8e5cc64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Efficient', 'Keyword', 'extraction', 'enhances', 'search', 'accuracy'],\n",
              " ['Semantic',\n",
              "  'similarity',\n",
              "  'improves',\n",
              "  'document',\n",
              "  'retrieval',\n",
              "  'performance'],\n",
              " ['Elasticsearch',\n",
              "  'is',\n",
              "  'a',\n",
              "  'powerful',\n",
              "  'search',\n",
              "  'engine',\n",
              "  'based',\n",
              "  'on',\n",
              "  'Lucene.'],\n",
              " ['BM25',\n",
              "  'is',\n",
              "  'a',\n",
              "  'ranking',\n",
              "  'function',\n",
              "  'used',\n",
              "  'by',\n",
              "  'search',\n",
              "  'engines',\n",
              "  'to',\n",
              "  'rank',\n",
              "  'documents.']]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_query = query.split()"
      ],
      "metadata": {
        "id": "pzG0NeDFMYSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdZtO2p4Mo_P",
        "outputId": "022be091-92ec-4e96-a795-30e66632af32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How', 'to', 'enhance', 'the', 'search', 'accuracy?']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9iiDSx5NEED",
        "outputId": "ab30a3bb-2472-43f9-fdd6-f287cfbbdcdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bfb3f4b"
      },
      "source": [
        "# making the object of bm25\n",
        "from rank_bm25 import BM25Okapi\n",
        "bm25 = BM25Okapi(tokenized_top_4_documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c898a73"
      },
      "source": [
        "bm25_scores = bm25.get_scores(tokenize_query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "511b72dc",
        "outputId": "f3e857b8-f8dc-4e47-fcf5-2e21cf483a66"
      },
      "source": [
        "bm25_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2081534 , 0.        , 0.17543059, 0.8550156 ])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "530aa3b8"
      },
      "source": [
        "# Combine the documents and their BM25 scores\n",
        "ranked_documents_index = np.argsort(bm25_scores)[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranked_documents_with_scores = [(tokenized_top_4_documents[i] , bm25_scores[i].item()) for i in ranked_documents_index]"
      ],
      "metadata": {
        "id": "UvO2yvPkQwNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f23668",
        "outputId": "7773fee3-a2db-4530-bbe3-274139e8617a"
      },
      "source": [
        "reranked_documents_with_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['BM25',\n",
              "   'is',\n",
              "   'a',\n",
              "   'ranking',\n",
              "   'function',\n",
              "   'used',\n",
              "   'by',\n",
              "   'search',\n",
              "   'engines',\n",
              "   'to',\n",
              "   'rank',\n",
              "   'documents.'],\n",
              "  0.855015602771993),\n",
              " (['Efficient', 'Keyword', 'extraction', 'enhances', 'search', 'accuracy'],\n",
              "  0.20815339611084605),\n",
              " (['Elasticsearch',\n",
              "   'is',\n",
              "   'a',\n",
              "   'powerful',\n",
              "   'search',\n",
              "   'engine',\n",
              "   'based',\n",
              "   'on',\n",
              "   'Lucene.'],\n",
              "  0.17543059148206677),\n",
              " (['Semantic',\n",
              "   'similarity',\n",
              "   'improves',\n",
              "   'document',\n",
              "   'retrieval',\n",
              "   'performance'],\n",
              "  0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReRanking with cross Encoders, and Cohere API"
      ],
      "metadata": {
        "id": "xNsHV7ZCRKHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder"
      ],
      "metadata": {
        "id": "ahCAFo7fbsOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ufn0g2hbxCw",
        "outputId": "de90311a-8b58-46e8-ffac-cee5ca8b9d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_4_documents # that is the rank document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLzitTS2b5s7",
        "outputId": "fe22a179-e860-4379-f9e0-2ba9c5e07695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Efficient Keyword extraction enhances search accuracy',\n",
              " 'Semantic similarity improves document retrieval performance',\n",
              " 'Elasticsearch is a powerful search engine based on Lucene.',\n",
              " 'BM25 is a ranking function used by search engines to rank documents.']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will create a pair because we send the both sentence(quey and document) to the encoder at the same time and it gives the raw logits\n",
        "\n",
        "pairs = []\n",
        "for doc in top_4_documents :\n",
        "  pairs.append([query,doc])"
      ],
      "metadata": {
        "id": "xeIv-FxccbL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cRSMEEddl9O",
        "outputId": "0819063c-9958-40eb-86f6-912a31684521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['How to enhance the search accuracy?',\n",
              "  'Efficient Keyword extraction enhances search accuracy'],\n",
              " ['How to enhance the search accuracy?',\n",
              "  'Semantic similarity improves document retrieval performance'],\n",
              " ['How to enhance the search accuracy?',\n",
              "  'Elasticsearch is a powerful search engine based on Lucene.'],\n",
              " ['How to enhance the search accuracy?',\n",
              "  'BM25 is a ranking function used by search engines to rank documents.']]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_encoder.predict(pairs)"
      ],
      "metadata": {
        "id": "a-gBNcvfdmdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores # these are all the logits values."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIxbBVi1fFu7",
        "outputId": "fb8f1c41-e09c-4411-a0fa-0f4b92124927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.50540304, 0.50305945, 0.5058224 , 0.5019586 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scored_docs = zip(top_4_documents,scores)"
      ],
      "metadata": {
        "id": "TxaouuZqfGcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_documents_cross_encoder = sorted(scored_docs,reverse=True)"
      ],
      "metadata": {
        "id": "BMZU63W3fW9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxPsccRJfXwF",
        "outputId": "dec7c974-310e-4db9-fcb6-b5e9a3c26a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Efficient Keyword extraction enhances search accuracy', 0.6528676748275757),\n",
              " ('Semantic similarity improves document retrieval performance',\n",
              "  0.4518398642539978),\n",
              " ('Elasticsearch is a powerful search engine based on Lucene.',\n",
              "  0.3867676258087158),\n",
              " ('BM25 is a ranking function used by search engines to rank documents.',\n",
              "  0.318647176027298),\n",
              " ('Retrieval-augmented generation (RAG) combines retrieval and LLMs to improve answers.',\n",
              "  0.3135107457637787),\n",
              " ('LangChain is a framework for building applications with large language models.',\n",
              "  0.0971514880657196),\n",
              " ('Python is a popular programming language for AI and data science.',\n",
              "  0.05633681267499924)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mj6RMUEzfjmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# contextual compression retriever"
      ],
      "metadata": {
        "id": "Ljoic7qleWmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community langchain_openai faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD1LMG0veWj-",
        "outputId": "7ed05b8d-2b1d-4e5a-fc93-a4184b510f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.14)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.67.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, pydantic-settings, dataclasses-json, langchain_openai, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.12.0 httpx-sse-0.4.1 langchain-community-0.3.27 langchain_openai-0.3.30 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import ChatOpenAI , OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "ZGOuj83lfFwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = TextLoader('/content/state_of_the_union.txt').load()"
      ],
      "metadata": {
        "id": "ZmZj1tG1fqXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=500 , chunk_overlap=100)"
      ],
      "metadata": {
        "id": "Um_kaj17ghnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "UjHaIRPAgi1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "khBO-u9JhDf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = ChatOpenAI()\n",
        "embedding_model = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "1GtkqgpEjMIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = FAISS.from_documents(texts ,embedding_model).as_retriever()"
      ],
      "metadata": {
        "id": "T6QctxAei_3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.invoke('How is the United States supporting Ukraine economically and militarily?')"
      ],
      "metadata": {
        "id": "0xvy64fcjez6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Xb5kPmkhTq",
        "outputId": "13fbfbd6-3a6d-4f01-9fca-50b350fc7ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2b0194e0-c6b0-4472-b3cf-b56a71c29fa0', metadata={'source': '/content/state_of_the_union.txt'}, page_content='Together with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.'),\n",
              " Document(id='2567d862-23df-40c3-a0da-e34548eed35b', metadata={'source': '/content/state_of_the_union.txt'}, page_content='In the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security. \\n\\nThis is a real test. It’s going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people. \\n\\nTo our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \\n\\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people.'),\n",
              " Document(id='092a6e76-2e5c-4b66-9c92-48b60362b77d', metadata={'source': '/content/state_of_the_union.txt'}, page_content='Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.'),\n",
              " Document(id='75a18858-ce59-4b8a-921d-2e0da6158ab9', metadata={'source': '/content/state_of_the_union.txt'}, page_content='Our forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.  \\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def pretty_print(docs):\n",
        "  print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
      ],
      "metadata": {
        "id": "1_t6aB2nkP1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6a6jyHjkbP2",
        "outputId": "b13019dd-2f6f-4933-ac32-aaa82e90b739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Together with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \n",
            "\n",
            "We are giving more than $1 Billion in direct assistance to Ukraine. \n",
            "\n",
            "And we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \n",
            "\n",
            "Let me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "In the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security. \n",
            "\n",
            "This is a real test. It’s going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people. \n",
            "\n",
            "To our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \n",
            "\n",
            "Putin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \n",
            "\n",
            "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
            "\n",
            "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
            "\n",
            "They keep moving.   \n",
            "\n",
            "And the costs and the threats to America and the world keep rising.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "Our forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.  \n",
            "\n",
            "For that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \n",
            "\n",
            "As I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "Chain = RetrievalQA.from_chain_type(llm=llm_model , retriever=retriever)"
      ],
      "metadata": {
        "id": "MqswrPTxkdg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Chain.invoke('How is the United States supporting Ukraine economically and militarily?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4aWKyCgskFy",
        "outputId": "83493708-6e58-4b8b-e063-bbfa51a23046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How is the United States supporting Ukraine economically and militarily?',\n",
              " 'result': 'The United States is providing support to Ukraine by giving more than $1 billion in direct assistance. This assistance includes military, economic, and humanitarian aid to help the Ukrainian people defend their country and ease their suffering. Additionally, the United States has mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries, which indirectly supports Ukraine by countering any potential further aggression by Russia.'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ],
      "metadata": {
        "id": "Kr67BUECsoyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressor = LLMChainExtractor.from_llm(llm_model)"
      ],
      "metadata": {
        "id": "vpUkyhJltoNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressor_retrieval = ContextualCompressionRetriever(base_compressor = compressor , base_retriever  = retriever) # firs the base retrievre get the rank documents and then pass to the base compressor and it will compress the document and then will fectch the compress information to the model\n"
      ],
      "metadata": {
        "id": "LoyjbMEEt_MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comprossed_docs = compressor_retrieval.invoke('What were the top three priorities outlined in the most recent state of the union address?')"
      ],
      "metadata": {
        "id": "EIWYatk4ubtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print(comprossed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-3BO8rnugWX",
        "outputId": "c6750fe4-a6b5-46a6-b69e-9a536c2eaaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Invest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up \n",
            "and the middle out, not from the top down.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "First, beat the opioid epidemic.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "More infrastructure and innovation in America.\n",
            "More goods moving faster and cheaper in America.\n",
            "More jobs where you can earn a good living in America.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.document_compressors import LLMChainFilter"
      ],
      "metadata": {
        "id": "Xqo0b8bgukL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_2 = LLMChainFilter.from_llm(llm_model)"
      ],
      "metadata": {
        "id": "OrPKNvv8wAEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_retriever_2 = ContextualCompressionRetriever(base_compressor = filter_2 , base_retriever = retriever)"
      ],
      "metadata": {
        "id": "QiYLXBo8wF9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comprossed_docs_2 = compressed_retriever_2.invoke('What were the top three priorities outlined in the most recent state of the union address?')"
      ],
      "metadata": {
        "id": "xnsf0baPwL0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print(comprossed_docs_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeYD_WcXwQGO",
        "outputId": "fedc98bc-cc0c-4cd5-f1cc-894faeebdfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "More infrastructure and innovation in America. \n",
            "\n",
            "More goods moving faster and cheaper in America. \n",
            "\n",
            "More jobs where you can earn a good living in America. \n",
            "\n",
            "And instead of relying on foreign supply chains, let’s make it in America. \n",
            "\n",
            "Economists call it “increasing the productive capacity of our economy.” \n",
            "\n",
            "I call it building a better America. \n",
            "\n",
            "My plan to fight inflation will lower your costs and lower the deficit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original context len\n",
        "original_context_len = len(\"\\n\\n\".join([d.page_content for i, d in enumerate(docs)]))"
      ],
      "metadata": {
        "id": "xVZILQDUwToQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_context_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njwp3nejxheD",
        "outputId": "7a3c596c-b2cb-430a-ae2e-1db272b5132f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1878"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_context_len = len(\"\\n\\n\".join([d.page_content for i, d in enumerate(comprossed_docs)]))"
      ],
      "metadata": {
        "id": "QgLwe4AZxmia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_context_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaO4Gq3jxueP",
        "outputId": "40ce0ad0-c77d-4706-f274-19b608838194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.document_compressors import EmbeddingsFilter"
      ],
      "metadata": {
        "id": "Fk2CznhgyE7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_filter = EmbeddingsFilter(embeddings=embedding_model , similarity_threshold=0.76)"
      ],
      "metadata": {
        "id": "Ep_PIUUnyo8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressor_retriever_3 = ContextualCompressionRetriever(base_compressor = embedding_filter , base_retriever = retriever)"
      ],
      "metadata": {
        "id": "ayT1tuUAzphN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs_3 = compressor_retriever_3.invoke('What were the top three priorities outlined in the most recent state of the union address?')"
      ],
      "metadata": {
        "id": "2IJHhT_M0D_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print(compressed_docs_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivLBm_Ao0Pst",
        "outputId": "bc7da888-b350-4eee-c63e-11d3867e1881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Because I see the future that is within our grasp. \n",
            "\n",
            "Because I know there is simply nothing beyond our capacity. \n",
            "\n",
            "We are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \n",
            "\n",
            "The only nation that can be defined by a single word: possibilities. \n",
            "\n",
            "So on this night, in our 245th year as a nation, I have come to report on the State of the Union. \n",
            "\n",
            "And my report is this: the State of the Union is strong—because you, the American people, are strong.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Vice President Harris and I ran for office with a new economic vision for America. \n",
            "\n",
            "Invest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \n",
            "and the middle out, not from the top down.  \n",
            "\n",
            "Because we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \n",
            "\n",
            "America used to have the best roads, bridges, and airports on Earth. \n",
            "\n",
            "Now our infrastructure is ranked 13th in the world.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "And soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \n",
            "\n",
            "So tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \n",
            "\n",
            "First, beat the opioid epidemic. \n",
            "\n",
            "There is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "More infrastructure and innovation in America. \n",
            "\n",
            "More goods moving faster and cheaper in America. \n",
            "\n",
            "More jobs where you can earn a good living in America. \n",
            "\n",
            "And instead of relying on foreign supply chains, let’s make it in America. \n",
            "\n",
            "Economists call it “increasing the productive capacity of our economy.” \n",
            "\n",
            "I call it building a better America. \n",
            "\n",
            "My plan to fight inflation will lower your costs and lower the deficit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
        "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
        "from langchain_text_splitters import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "qKbrC57m0RMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = CharacterTextSplitter(chunk_size=500 , chunk_overlap=0 , separator=\". \")"
      ],
      "metadata": {
        "id": "pOIGDaVM1mMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "redundant_filter = EmbeddingsRedundantFilter(embeddings=embedding_model)"
      ],
      "metadata": {
        "id": "QQKATix_13vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevent_filter = EmbeddingsFilter(embeddings=embedding_model , similarity_threshold=0.76)"
      ],
      "metadata": {
        "id": "dEtDI0QO189B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_compressor = DocumentCompressorPipeline(transformers=[splitter,redundant_filter,relevent_filter])\n"
      ],
      "metadata": {
        "id": "kcrN3zHf2Epy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressorion_retriever = ContextualCompressionRetriever(base_compressor = pipeline_compressor , base_retriever = retriever)"
      ],
      "metadata": {
        "id": "9R4bmxue2Nv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_docs_4 = compressorion_retriever.invoke('What were the top three priorities outlined in the most recent state of the union address?')"
      ],
      "metadata": {
        "id": "7-pJuVd32R4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretty_print(compressed_docs_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_EcLrKb2Vkd",
        "outputId": "11041114-ee75-46a7-a2a5-359b96d3bcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "Because I see the future that is within our grasp. \n",
            "\n",
            "Because I know there is simply nothing beyond our capacity. \n",
            "\n",
            "We are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \n",
            "\n",
            "The only nation that can be defined by a single word: possibilities. \n",
            "\n",
            "So on this night, in our 245th year as a nation, I have come to report on the State of the Union. \n",
            "\n",
            "And my report is this: the State of the Union is strong—because you, the American people, are strong.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "Vice President Harris and I ran for office with a new economic vision for America. \n",
            "\n",
            "Invest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \n",
            "and the middle out, not from the top down.  \n",
            "\n",
            "Because we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \n",
            "\n",
            "America used to have the best roads, bridges, and airports on Earth. \n",
            "\n",
            "Now our infrastructure is ranked 13th in the world.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "And soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \n",
            "\n",
            "So tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \n",
            "\n",
            "First, beat the opioid epidemic. \n",
            "\n",
            "There is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "More infrastructure and innovation in America. \n",
            "\n",
            "More goods moving faster and cheaper in America. \n",
            "\n",
            "More jobs where you can earn a good living in America. \n",
            "\n",
            "And instead of relying on foreign supply chains, let’s make it in America. \n",
            "\n",
            "Economists call it “increasing the productive capacity of our economy.” \n",
            "\n",
            "I call it building a better America. \n",
            "\n",
            "My plan to fight inflation will lower your costs and lower the deficit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = Chain.invoke(\"What were the top three priorities outlined in the most recent state of the union address?\")"
      ],
      "metadata": {
        "id": "2MDgc58F2XCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "r0_LH2Zr3KDL",
        "outputId": "f945472b-5472-4858-c853-d97b485e68a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The top three priorities outlined in the most recent State of the Union address were:\\n1. Beating the opioid epidemic through increased funding for prevention, treatment, harm reduction, and recovery.\\n2. Strengthening infrastructure and innovation in America to facilitate faster and cheaper goods movement and create more well-paying jobs to increase the country's productive capacity.\\n3. Implementing a plan to fight inflation that would lower costs for individuals and reduce the deficit.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pmh3Xlj33V42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self query Retriever"
      ],
      "metadata": {
        "id": "KYZJxs3d90wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-chroma langchain_openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfb8PFk295R4",
        "outputId": "e491111f-2067-4671-f93b-7b2842997766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.12/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma) (2.0.2)\n",
            "Requirement already satisfied: chromadb>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from langchain-chroma) (1.0.20)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.14.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.21.4)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.74.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (9.1.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (3.11.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.25.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.36.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma) (0.57b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings , ChatOpenAI"
      ],
      "metadata": {
        "id": "VCxMtnb-99ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
        "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
        "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
        "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Toys come alive and have a blast doing so\",\n",
        "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A hacker discovers reality is a simulation and leads a rebellion against the machines controlling it.\",\n",
        "        metadata={\"year\": 1999, \"director\": \"Lana Wachowski, Lilly Wachowski\", \"rating\": 8.7, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A young lion prince flees his kingdom only to learn the true meaning of responsibility and bravery.\",\n",
        "        metadata={\"year\": 1994, \"rating\": 8.5, \"genre\": \"animated\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Batman faces off against the Joker, a criminal mastermind who plunges Gotham into chaos.\",\n",
        "        metadata={\"year\": 2008, \"director\": \"Christopher Nolan\", \"rating\": 9.0, \"genre\": \"action\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A team of explorers travel through a wormhole in space in an attempt to ensure humanity's survival.\",\n",
        "        metadata={\"year\": 2014, \"director\": \"Christopher Nolan\", \"rating\": 8.6, \"genre\": \"science fiction\"},\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "gWDi-FL__YbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "5rnido9c_2gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = ChatOpenAI()\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "XRVKXual_pUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(docs,embeddings)"
      ],
      "metadata": {
        "id": "xaBEWUaT_eTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.query_constructor.schema import AttributeInfo\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever"
      ],
      "metadata": {
        "id": "q1McO0Z4AFRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"genre\",\n",
        "        description=\"The genre of the movie. One of ['science fiction', 'comedy', 'drama', 'thriller', 'romance', 'action', 'animated']\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"year\",\n",
        "        description=\"The year the movie was released\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"director\",\n",
        "        description=\"The name of the movie director\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "yE7Rr_voA7Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_content_description = \"Brief summary of a movie\""
      ],
      "metadata": {
        "id": "u34d8hviBN19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqROgFFTRzjP",
        "outputId": "646367b2-610d-445b-b728-eb709a2e8d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm_model, vectorstore, document_content_description, metadata_field_info, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "agVi-TTcRTvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"Whar are some movies about dinosaurs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OimmeEEWRkOB",
        "outputId": "2314d297-5ad3-4100-bd71-5a64e33b8da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='107cea74-ebd8-403c-8bfd-6a648698b644', metadata={'genre': 'science fiction', 'rating': 7.7, 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
              " Document(id='96f5f18f-8a00-4f27-a92a-edac5b418728', metadata={'rating': 7.7, 'genre': 'science fiction', 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
              " Document(id='ae600400-af9c-417b-a24d-0748b00576e1', metadata={'rating': 7.7, 'genre': 'science fiction', 'year': 1993}, page_content='A bunch of scientists bring back dinosaurs and mayhem breaks loose'),\n",
              " Document(id='9cad2b8c-761e-4934-b838-25ecad14ab4b', metadata={'genre': 'animated', 'year': 1995}, page_content='Toys come alive and have a blast doing so')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This example only specifies a filter\n",
        "retriever.invoke(\"I want to watch a movie rated higher than 8.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJeL_nOOSJJj",
        "outputId": "11b89b3b-2db7-4a1d-e320-cc4ce408ea34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='6bbcf9fc-f00d-46ff-8cdd-09411272dfc9', metadata={'director': 'Christopher Nolan', 'rating': 9.0, 'genre': 'action', 'year': 2008}, page_content='Batman faces off against the Joker, a criminal mastermind who plunges Gotham into chaos.'),\n",
              " Document(id='6fddc15e-92d5-4f7b-9709-7dceee8d166d', metadata={'genre': 'action', 'rating': 9.0, 'year': 2008, 'director': 'Christopher Nolan'}, page_content='Batman faces off against the Joker, a criminal mastermind who plunges Gotham into chaos.'),\n",
              " Document(id='dc4f865c-7b63-4a2d-9064-b100be7cd77a', metadata={'director': 'Christopher Nolan', 'year': 2008, 'rating': 9.0, 'genre': 'action'}, page_content='Batman faces off against the Joker, a criminal mastermind who plunges Gotham into chaos.'),\n",
              " Document(id='37e83552-512f-485d-98c6-a406900d4e75', metadata={'director': 'Christopher Nolan', 'year': 2014, 'rating': 8.6, 'genre': 'science fiction'}, page_content=\"A team of explorers travel through a wormhole in space in an attempt to ensure humanity's survival.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This example specifies a query and a filter\n",
        "retriever.invoke(\"Has Greta Gerwig directed any movies about women\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSV1JJoaSdVg",
        "outputId": "e1378d88-10ec-494c-81d3-c986069c77b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='388620ae-57f7-4b9b-994b-1dd1cd537bf6', metadata={'year': 2019, 'rating': 8.3, 'director': 'Greta Gerwig'}, page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them'),\n",
              " Document(id='90e01397-e09a-4f99-81b8-f21217835ab2', metadata={'year': 2019, 'director': 'Greta Gerwig', 'rating': 8.3}, page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them'),\n",
              " Document(id='2db6f3bb-31c8-4f25-b3df-2b2adda46be0', metadata={'director': 'Greta Gerwig', 'year': 2019, 'rating': 8.3}, page_content='A bunch of normal-sized women are supremely wholesome and some men pine after them')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This example specifies a query and composite filter\n",
        "retriever.invoke(\n",
        "    \"What's a movie after 1990 but before 2005 that's all about toys, and preferably is animated\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmmBV3GySka4",
        "outputId": "a04946f5-df63-4126-c57a-14e5792ee9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2a08feac-1e1f-4131-912c-790a84a0d540', metadata={'genre': 'animated', 'year': 1995}, page_content='Toys come alive and have a blast doing so'),\n",
              " Document(id='fc6285b3-1ced-45ba-a7c4-11d97f4003f8', metadata={'year': 1995, 'genre': 'animated'}, page_content='Toys come alive and have a blast doing so'),\n",
              " Document(id='9cad2b8c-761e-4934-b838-25ecad14ab4b', metadata={'year': 1995, 'genre': 'animated'}, page_content='Toys come alive and have a blast doing so'),\n",
              " Document(id='52f0aefd-8c49-413f-a98f-1f8ea3d47f93', metadata={'year': 1994, 'rating': 8.5, 'genre': 'animated'}, page_content='A young lion prince flees his kingdom only to learn the true meaning of responsibility and bravery.')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWd1Bn0iSqQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QSAU10tDUh73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Child to parent Retrievers"
      ],
      "metadata": {
        "id": "b5ZJzX1XUh-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-community langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLhFpY-oVbdJ",
        "outputId": "8391784e-7b2c-4643-fdb4-e7a28fc33659",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI , OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.retrievers import ParentDocumentRetriever"
      ],
      "metadata": {
        "id": "5h426KLcVdXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = [\n",
        "    TextLoader('/content/Document_texts/paul_graham_essay.txt'),\n",
        "    TextLoader('/content/Document_texts/state_of_the_union.txt')\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "inJUCb91V1QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "\n",
        "for doc in loaders :\n",
        "  docs.extend(doc.load())"
      ],
      "metadata": {
        "id": "gyfrzPu6XvX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Y7fmROX7d-",
        "outputId": "00127ff1-f70c-4012-c2f9-981f9785278a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Document_texts/paul_graham_essay.txt'}, page_content='December 2014\\n\\nAmerican technology companies want the government to make immigration easier because they say they can\\'t find enough programmers in the US. Anti-immigration people say that instead of letting foreigners take these jobs, we should train more Americans to be programmers. Who\\'s right?\\n\\nThe technology companies are right. What the anti-immigration people don\\'t understand is that there is a huge variation in ability between competent programmers and exceptional ones, and while you can train people to be competent, you can\\'t train them to be exceptional. Exceptional programmers have an aptitude for and interest in programming that is not merely the product of training. [1]\\n\\nThe US has less than 5% of the world\\'s population. Which means if the qualities that make someone a great programmer are evenly distributed, 95% of great programmers are born outside the US.\\n\\nThe anti-immigration people have to invent some explanation to account for all the effort technology companies have expended trying to make immigration easier. So they claim it\\'s because they want to drive down salaries. But if you talk to startups, you find practically every one over a certain size has gone through legal contortions to get programmers into the US, where they then paid them the same as they\\'d have paid an American. Why would they go to extra trouble to get programmers for the same price? The only explanation is that they\\'re telling the truth: there are just not enough great programmers to go around. [2]\\n\\nI asked the CEO of a startup with about 70 programmers how many more he\\'d hire if he could get all the great programmers he wanted. He said \"We\\'d hire 30 tomorrow morning.\" And this is one of the hot startups that always win recruiting battles. It\\'s the same all over Silicon Valley. Startups are that constrained for talent.\\n\\nIt would be great if more Americans were trained as programmers, but no amount of training can flip a ratio as overwhelming as 95 to 5. Especially since programmers are being trained in other countries too. Barring some cataclysm, it will always be true that most great programmers are born outside the US. It will always be true that most people who are great at anything are born outside the US. [3]\\n\\nExceptional performance implies immigration. A country with only a few percent of the world\\'s population will be exceptional in some field only if there are a lot of immigrants working in it.\\n\\nBut this whole discussion has taken something for granted: that if we let more great programmers into the US, they\\'ll want to come. That\\'s true now, and we don\\'t realize how lucky we are that it is. If we want to keep this option open, the best way to do it is to take advantage of it: the more of the world\\'s great programmers are here, the more the rest will want to come here.\\n\\nAnd if we don\\'t, the US could be seriously fucked. I realize that\\'s strong language, but the people dithering about this don\\'t seem to realize the power of the forces at work here. Technology gives the best programmers huge leverage. The world market in programmers seems to be becoming dramatically more liquid. And since good people like good colleagues, that means the best programmers could collect in just a few hubs. Maybe mostly in one hub.\\n\\nWhat if most of the great programmers collected in one hub, and it wasn\\'t here? That scenario may seem unlikely now, but it won\\'t be if things change as much in the next 50 years as they did in the last 50.\\n\\nWe have the potential to ensure that the US remains a technology superpower just by letting in a few thousand great programmers a year. What a colossal mistake it would be to let that opportunity slip. It could easily be the defining mistake this generation of American politicians later become famous for. And unlike other potential mistakes on that scale, it costs nothing to fix.\\n\\nSo please, get on with it.\\n'),\n",
              " Document(metadata={'source': '/content/Document_texts/state_of_the_union.txt'}, page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters. \\n\\nPutin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland. \\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains. \\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.  \\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay. \\n\\nWhen the history of this era is written Putin’s war on Ukraine will have left Russia weaker and the rest of the world stronger. \\n\\nWhile it shouldn’t have taken something so terrible for people around the world to see what’s at stake now everyone sees it clearly. \\n\\nWe see the unity among leaders of nations and a more unified Europe a more unified West. And we see unity among the people who are gathering in cities in large crowds around the world even in Russia to demonstrate their support for Ukraine.  \\n\\nIn the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security. \\n\\nThis is a real test. It’s going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people. \\n\\nTo our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \\n\\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people. \\n\\nHe will never extinguish their love of freedom. He will never weaken the resolve of the free world. \\n\\nWe meet tonight in an America that has lived through two of the hardest years this nation has ever faced. \\n\\nThe pandemic has been punishing. \\n\\nAnd so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more. \\n\\nI understand. \\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it. \\n\\nThat’s why one of the first things I did as President was fight to pass the American Rescue Plan.  \\n\\nBecause people were hurting. We needed to act, and we did. \\n\\nFew pieces of legislation have done more in a critical moment in our history to lift us out of crisis. \\n\\nIt fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.  \\n\\nHelped put food on their table, keep a roof over their heads, and cut the cost of health insurance. \\n\\nAnd as my Dad used to say, it gave people a little breathing room. \\n\\nAnd unlike the $2 Trillion tax cut passed in the previous administration that benefitted the top 1% of Americans, the American Rescue Plan helped working people—and left no one behind. \\n\\nAnd it worked. It created jobs. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America. \\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.  \\n\\nFor the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America. \\n\\nInvest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \\nand the middle out, not from the top down.  \\n\\nBecause we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \\n\\nAmerica used to have the best roads, bridges, and airports on Earth. \\n\\nNow our infrastructure is ranked 13th in the world. \\n\\nWe won’t be able to compete for the jobs of the 21st Century if we don’t fix that. \\n\\nThat’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history. \\n\\nThis was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen. \\n\\nWe’re done talking about infrastructure weeks. \\n\\nWe’re going to have an infrastructure decade. \\n\\nIt is going to transform America and put us on a path to win the economic competition of the 21st Century that we face with the rest of the world—particularly with China.  \\n\\nAs I’ve told Xi Jinping, it is never a good bet to bet against the American people. \\n\\nWe’ll create good jobs for millions of Americans, modernizing roads, airports, ports, and waterways all across America. \\n\\nAnd we’ll do it all to withstand the devastating effects of the climate crisis and promote environmental justice. \\n\\nWe’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school, provide affordable high-speed internet for every American—urban, suburban, rural, and tribal communities. \\n\\n4,000 projects have already been announced. \\n\\nAnd tonight, I’m announcing that this year we will start fixing over 65,000 miles of highway and 1,500 bridges in disrepair. \\n\\nWhen we use taxpayer dollars to rebuild America – we are going to Buy American: buy American products to support American jobs. \\n\\nThe federal government spends about $600 Billion a year to keep the country safe and secure. \\n\\nThere’s been a law on the books for almost a century \\nto make sure taxpayers’ dollars support American jobs and businesses. \\n\\nEvery Administration says they’ll do it, but we are actually doing it. \\n\\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \\n\\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors. \\n\\nThat’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing. \\n\\nLet me give you one example of why it’s so important to pass it. \\n\\nIf you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land. \\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill. \\n\\nSo let’s not wait any longer. Send it to my desk. I’ll sign it.  \\n\\nAnd we will really take off. \\n\\nAnd Intel is not alone. \\n\\nThere’s something happening in America. \\n\\nJust look around and you’ll see an amazing story. \\n\\nThe rebirth of the pride that comes from stamping products “Made In America.” The revitalization of American manufacturing.   \\n\\nCompanies are choosing to build new factories here, when just a few years ago, they would have built them overseas. \\n\\nThat’s what is happening. Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. \\n\\nGM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan. \\n\\nAll told, we created 369,000 new manufacturing jobs in America just last year. \\n\\nPowered by people I’ve met like JoJo Burgess, from generations of union steelworkers from Pittsburgh, who’s here with us tonight. \\n\\nAs Ohio Senator Sherrod Brown says, “It’s time to bury the label “Rust Belt.” \\n\\nIt’s time. \\n\\nBut with all the bright spots in our economy, record job growth and higher wages, too many families are struggling to keep up with the bills.  \\n\\nInflation is robbing them of the gains they might otherwise feel. \\n\\nI get it. That’s why my top priority is getting prices under control. \\n\\nLook, our economy roared back faster than most predicted, but the pandemic meant that businesses had a hard time hiring enough workers to keep up production in their factories. \\n\\nThe pandemic also disrupted global supply chains. \\n\\nWhen factories close, it takes longer to make goods and get them from the warehouse to the store, and prices go up. \\n\\nLook at cars. \\n\\nLast year, there weren’t enough semiconductors to make all the cars that people wanted to buy. \\n\\nAnd guess what, prices of automobiles went up. \\n\\nSo—we have a choice. \\n\\nOne way to fight inflation is to drive down wages and make Americans poorer.  \\n\\nI have a better plan to fight inflation. \\n\\nLower your costs, not your wages. \\n\\nMake more cars and semiconductors in America. \\n\\nMore infrastructure and innovation in America. \\n\\nMore goods moving faster and cheaper in America. \\n\\nMore jobs where you can earn a good living in America. \\n\\nAnd instead of relying on foreign supply chains, let’s make it in America. \\n\\nEconomists call it “increasing the productive capacity of our economy.” \\n\\nI call it building a better America. \\n\\nMy plan to fight inflation will lower your costs and lower the deficit. \\n\\n17 Nobel laureates in economics say my plan will ease long-term inflationary pressures. Top business leaders and most Americans support my plan. And here’s the plan: \\n\\nFirst – cut the cost of prescription drugs. Just look at insulin. One in ten Americans has diabetes. In Virginia, I met a 13-year-old boy named Joshua Davis.  \\n\\nHe and his Dad both have Type 1 diabetes, which means they need insulin every day. Insulin costs about $10 a vial to make.  \\n\\nBut drug companies charge families like Joshua and his Dad up to 30 times more. I spoke with Joshua’s mom. \\n\\nImagine what it’s like to look at your child who needs insulin and have no idea how you’re going to pay for it.  \\n\\nWhat it does to your dignity, your ability to look your child in the eye, to be the parent you expect to be. \\n\\nJoshua is here with us tonight. Yesterday was his birthday. Happy birthday, buddy.  \\n\\nFor Joshua, and for the 200,000 other young people with Type 1 diabetes, let’s cap the cost of insulin at $35 a month so everyone can afford it.  \\n\\nDrug companies will still do very well. And while we’re at it let Medicare negotiate lower prices for prescription drugs, like the VA already does. \\n\\nLook, the American Rescue Plan is helping millions of families on Affordable Care Act plans save $2,400 a year on their health care premiums. Let’s close the coverage gap and make those savings permanent. \\n\\nSecond – cut energy costs for families an average of $500 a year by combatting climate change.  \\n\\nLet’s provide investments and tax credits to weatherize your homes and businesses to be energy efficient and you get a tax credit; double America’s clean energy production in solar, wind, and so much more;  lower the price of electric vehicles, saving you another $80 a month because you’ll never have to pay at the gas pump again. \\n\\nThird – cut the cost of child care. Many families pay up to $14,000 a year for child care per child.  \\n\\nMiddle-class and working families shouldn’t have to pay more than 7% of their income for care of young children.  \\n\\nMy plan will cut the cost in half for most families and help parents, including millions of women, who left the workforce during the pandemic because they couldn’t afford child care, to be able to get back to work. \\n\\nMy plan doesn’t stop there. It also includes home and long-term care. More affordable housing. And Pre-K for every 3- and 4-year-old.  \\n\\nAll of these will lower costs. \\n\\nAnd under my plan, nobody earning less than $400,000 a year will pay an additional penny in new taxes. Nobody.  \\n\\nThe one thing all Americans agree on is that the tax system is not fair. We have to fix it.  \\n\\nI’m not looking to punish anyone. But let’s make sure corporations and the wealthiest Americans start paying their fair share. \\n\\nJust last year, 55 Fortune 500 corporations earned $40 billion in profits and paid zero dollars in federal income tax.  \\n\\nThat’s simply not fair. That’s why I’ve proposed a 15% minimum tax rate for corporations. \\n\\nWe got more than 130 countries to agree on a global minimum tax rate so companies can’t get out of paying their taxes at home by shipping jobs and factories overseas. \\n\\nThat’s why I’ve proposed closing loopholes so the very wealthy don’t pay a lower tax rate than a teacher or a firefighter.  \\n\\nSo that’s my plan. It will grow the economy and lower costs for families. \\n\\nSo what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted. \\n\\nBut in my administration, the watchdogs have been welcomed back. \\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year. \\n\\nLowering your costs also means demanding more competition. \\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism. \\n\\nIt’s exploitation—and it drives up prices. \\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \\n\\nWe see it happening with ocean carriers moving goods in and out of America. \\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits. \\n\\nTonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet’s pass the Paycheck Fairness Act and paid leave.  \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges. \\n\\nAnd let’s pass the PRO Act when a majority of workers want to form a union—they shouldn’t be stopped.  \\n\\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven’t done in a long time: build a better America. \\n\\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \\n\\nAnd I know you’re tired, frustrated, and exhausted. \\n\\nBut I also know this. \\n\\nBecause of the progress we’ve made, because of your resilience and the tools we have, tonight I can say  \\nwe are moving forward safely, back to more normal routines.  \\n\\nWe’ve reached a new moment in the fight against COVID-19, with severe cases down to a level not seen since last July.  \\n\\nJust a few days ago, the Centers for Disease Control and Prevention—the CDC—issued new mask guidelines. \\n\\nUnder these new guidelines, most Americans in most of the country can now be mask free.   \\n\\nAnd based on the projections, more of the country will reach that point across the next couple of weeks. \\n\\nThanks to the progress we have made this past year, COVID-19 need no longer control our lives.  \\n\\nI know some are talking about “living with COVID-19”. Tonight – I say that we will never just accept living with COVID-19. \\n\\nWe will continue to combat the virus as we do other diseases. And because this is a virus that mutates and spreads, we will stay on guard. \\n\\nHere are four common sense steps as we move forward safely.  \\n\\nFirst, stay protected with vaccines and treatments. We know how incredibly effective vaccines are. If you’re vaccinated and boosted you have the highest degree of protection. \\n\\nWe will never give up on vaccinating more Americans. Now, I know parents with kids under 5 are eager to see a vaccine authorized for their children. \\n\\nThe scientists are working hard to get that done and we’ll be ready with plenty of vaccines when they do. \\n\\nWe’re also ready with anti-viral treatments. If you get COVID-19, the Pfizer pill reduces your chances of ending up in the hospital by 90%.  \\n\\nWe’ve ordered more of these pills than anyone in the world. And Pfizer is working overtime to get us 1 Million pills this month and more than double that next month.  \\n\\nAnd we’re launching the “Test to Treat” initiative so people can get tested at a pharmacy, and if they’re positive, receive antiviral pills on the spot at no cost.  \\n\\nIf you’re immunocompromised or have some other vulnerability, we have treatments and free high-quality masks. \\n\\nWe’re leaving no one behind or ignoring anyone’s needs as we move forward. \\n\\nAnd on testing, we have made hundreds of millions of tests available for you to order for free.   \\n\\nEven if you already ordered free tests tonight, I am announcing that you can order more from covidtests.gov starting next week. \\n\\nSecond – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants. \\n\\nIf necessary, we’ll be able to deploy new vaccines within 100 days instead of many more months or years.  \\n\\nAnd, if Congress provides the funds we need, we’ll have new stockpiles of tests, masks, and pills ready if needed. \\n\\nI cannot promise a new variant won’t come. But I can promise you we’ll do everything within our power to be ready if it does.  \\n\\nThird – we can end the shutdown of schools and businesses. We have the tools we need. \\n\\nIt’s time for Americans to get back to work and fill our great downtowns again.  People working from home can feel safe to begin to return to the office.   \\n\\nWe’re doing that here in the federal government. The vast majority of federal workers will once again work in person. \\n\\nOur schools are open. Let’s keep it that way. Our kids need to be in school. \\n\\nAnd with 75% of adult Americans fully vaccinated and hospitalizations down by 77%, most Americans can remove their masks, return to work, stay in the classroom, and move forward safely. \\n\\nWe achieved this because we provided free vaccines, treatments, tests, and masks. \\n\\nOf course, continuing this costs money. \\n\\nI will soon send Congress a request. \\n\\nThe vast majority of Americans have used these tools and may want to again, so I expect Congress to pass it quickly.   \\n\\nFourth, we will continue vaccinating the world.     \\n\\nWe’ve sent 475 Million vaccine doses to 112 countries, more than any other nation. \\n\\nAnd we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves. \\n\\nI’ve worked on these issues a long time. \\n\\nI know what works: Investing in crime prevention and community police officers who’ll walk the beat, who’ll know the neighborhood, and who can restore trust and safety. \\n\\nSo let’s not abandon our streets. Or choose between safety and equal justice. \\n\\nLet’s come together to protect our communities, restore trust, and hold law enforcement accountable. \\n\\nThat’s why the Justice Department required body cameras, banned chokeholds, and restricted no-knock warrants for its officers. \\n\\nThat’s why the American Rescue Plan provided $350 Billion that cities, states, and counties can use to hire more police and invest in proven strategies like community violence interruption—trusted messengers breaking the cycle of violence and trauma and giving young people hope.  \\n\\nWe should all agree: The answer is not to Defund the police. The answer is to FUND the police with the resources and training they need to protect our communities. \\n\\nI ask Democrats and Republicans alike: Pass my budget and keep our neighborhoods safe.  \\n\\nAnd I will keep doing everything in my power to crack down on gun trafficking and ghost guns you can buy online and make at home—they have no serial numbers and can’t be traced. \\n\\nAnd I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon? \\n\\nBan assault weapons and high-capacity magazines. \\n\\nRepeal the liability shield that makes gun manufacturers the only industry in America that can’t be sued. \\n\\nThese laws don’t infringe on the Second Amendment. They save lives. \\n\\nThe most fundamental right in America is the right to vote – and to have it counted. And it’s under assault. \\n\\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \\n\\nWe cannot let this happen. \\n\\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \\n\\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders. \\n\\nWe can do all this while keeping lit the torch of liberty that has led generations of immigrants to this land—my forefathers and so many of yours. \\n\\nProvide a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. \\n\\nRevise our laws so businesses have the workers they need and families don’t wait decades to reunite. \\n\\nIt’s not only the right thing to do—it’s the economically smart thing to do. \\n\\nThat’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \\n\\nLet’s get it done once and for all. \\n\\nAdvancing liberty and justice also requires protecting the rights of women. \\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before. \\n\\nIf we want to go forward—not backward—we must protect access to health care. Preserve a woman’s right to choose. And let’s continue to advance maternal health care in America. \\n\\nAnd for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic. \\n\\nThere is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.  \\n\\nGet rid of outdated rules that stop doctors from prescribing treatments. And stop the flow of illicit drugs by working with state and local law enforcement to go after traffickers. \\n\\nIf you’re suffering from addiction, know you are not alone. I believe in recovery, and I celebrate the 23 million Americans in recovery. \\n\\nSecond, let’s take on mental health. Especially among our children, whose lives and education have been turned upside down.  \\n\\nThe American Rescue Plan gave schools money to hire teachers and help students make up for lost learning.  \\n\\nI urge every parent to make sure your school does just that. And we can all play a part—sign up to be a tutor or a mentor. \\n\\nChildren were also struggling before the pandemic. Bullying, violence, trauma, and the harms of social media. \\n\\nAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they’re conducting on our children for profit. \\n\\nIt’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \\n\\nAnd let’s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \\n\\nThird, support our veterans. \\n\\nVeterans are the best of us. \\n\\nI’ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \\n\\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \\n\\nOur troops in Iraq and Afghanistan faced many dangers. \\n\\nOne was stationed at bases and breathing in toxic smoke from “burn pits” that incinerated wastes of war—medical and hazard material, jet fuel, and more. \\n\\nWhen they came home, many of the world’s fittest and best trained warriors were never the same. \\n\\nHeadaches. Numbness. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. \\n\\nI know. \\n\\nOne of those soldiers was my son Major Beau Biden. \\n\\nWe don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. \\n\\nBut I’m committed to finding out everything we can. \\n\\nCommitted to military families like Danielle Robinson from Ohio. \\n\\nThe widow of Sergeant First Class Heath Robinson.  \\n\\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq. \\n\\nStationed near Baghdad, just yards from burn pits the size of football fields. \\n\\nHeath’s widow Danielle is here with us tonight. They loved going to Ohio State football games. He loved building Legos with their daughter. \\n\\nBut cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body. \\n\\nDanielle says Heath was a fighter to the very end. \\n\\nHe didn’t know how to stop fighting, and neither did she. \\n\\nThrough her pain she found purpose to demand we do better. \\n\\nTonight, Danielle—we are. \\n\\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits. \\n\\nAnd tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers. \\n\\nI’m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve. \\n\\nAnd fourth, let’s end cancer as we know it. \\n\\nThis is personal to me and Jill, to Kamala, and to so many of you. \\n\\nCancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.  \\n\\nWe will meet the test. \\n\\nTo protect freedom and liberty, to expand fairness and opportunity. \\n\\nWe will save democracy. \\n\\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life. \\n\\nBecause I see the future that is within our grasp. \\n\\nBecause I know there is simply nothing beyond our capacity. \\n\\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\n\\nThe only nation that can be defined by a single word: possibilities. \\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union. \\n\\nAnd my report is this: the State of the Union is strong—because you, the American people, are strong. \\n\\nWe are stronger today than we were a year ago. \\n\\nAnd we will be stronger a year from now than we are today. \\n\\nNow is our moment to meet and overcome the challenges of our time. \\n\\nAnd we will, as one people. \\n\\nOne America. \\n\\nThe United States of America. \\n\\nMay God bless you all. May God protect our troops.')]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text splitter to create the child documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)"
      ],
      "metadata": {
        "id": "QmvvZnwgX7--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.storage import InMemoryStore\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "oKwhAl7XYT04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  The vectorstore to use the index the child chunks\n",
        "\n",
        "vectorstore = Chroma(collection_name=\"full_documents\" , embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# creates the chroma collection where child chunks will be embed and store\n"
      ],
      "metadata": {
        "id": "bu8CV3XoY-2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the docstre for parents\n",
        "\n",
        "store = InMemoryStore()  # hold the parent documents by ID , in memory and is non persistent"
      ],
      "metadata": {
        "id": "WmJiIQ2slXVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever =  ParentDocumentRetriever(\n",
        "    vectorstore = vectorstore, # where to embed/search chroma (childern only)\n",
        "    docstore = store, # from where to fecth the full parents\n",
        "    child_splitter = child_splitter, # how to create the childern from parent\n",
        ")\n"
      ],
      "metadata": {
        "id": "nCiX0Dk-nPvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index making (add documents)\n",
        "retriever.add_documents(docs)"
      ],
      "metadata": {
        "id": "sTjuGdSsn-oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# insoect the parent IDs\n",
        "list(store.yield_keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOevvwJTogtM",
        "outputId": "6464ed2b-a589-491d-ca9e-4f1c9e4f77da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f3bc5685-6bb4-4c7a-af64-d5234867e4ac',\n",
              " '13ecb79a-2f07-4986-bd5f-983f29b3562b']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# query the vector store directly(children, not parents)"
      ],
      "metadata": {
        "id": "ygcnF9f9oq9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_docs = vectorstore.similarity_search(\"What did the president say about Ketanji Brown Jackson\")"
      ],
      "metadata": {
        "id": "WeBvgDCMpLsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AA8FDUrqPvw",
        "outputId": "6c9817c4-930d-48d4-fea8-b2cefdb1ed03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='9c9489ec-4de7-4d68-b13c-6f10138b73f8', metadata={'doc_id': '15fca149-c74c-4972-86c3-99a8f50dfac2', 'source': '/content/Document_texts/state_of_the_union.txt'}, page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.'),\n",
              " Document(id='95580386-12a8-42dd-ae6e-6b78f02a1a3f', metadata={'source': '/content/Document_texts/state_of_the_union.txt', 'doc_id': 'a8a14b9e-73db-40f7-8d7d-7efdfe4a6d84'}, page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.'),\n",
              " Document(id='8e33214c-d166-451d-852e-6a6e7b3e2cab', metadata={'source': '/content/Document_texts/state_of_the_union.txt', 'doc_id': '13ecb79a-2f07-4986-bd5f-983f29b3562b'}, page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.'),\n",
              " Document(id='474c33fd-47a1-441d-89e2-a6a68b0ac1a7', metadata={'doc_id': 'efb4e3a6-d555-4d23-8644-38229ad1274a', 'source': '/content/Document_texts/state_of_the_union.txt'}, page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.')]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sub_docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYkUkfHvpe2p",
        "outputId": "33049664-94b8-4b8e-9305-bddb95f15d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrievrs_docs = retriever.invoke(\"What did the president say about Ketanji Brown Jackson\")"
      ],
      "metadata": {
        "id": "5YYiq6kNqGdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrievrs_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSXN1FNuqe9k",
        "outputId": "167c7e2e-f007-4a44-dbb3-ebafba8a235d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Document_texts/state_of_the_union.txt'}, page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters. \\n\\nPutin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland. \\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains. \\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.  \\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay. \\n\\nWhen the history of this era is written Putin’s war on Ukraine will have left Russia weaker and the rest of the world stronger. \\n\\nWhile it shouldn’t have taken something so terrible for people around the world to see what’s at stake now everyone sees it clearly. \\n\\nWe see the unity among leaders of nations and a more unified Europe a more unified West. And we see unity among the people who are gathering in cities in large crowds around the world even in Russia to demonstrate their support for Ukraine.  \\n\\nIn the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security. \\n\\nThis is a real test. It’s going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people. \\n\\nTo our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \\n\\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people. \\n\\nHe will never extinguish their love of freedom. He will never weaken the resolve of the free world. \\n\\nWe meet tonight in an America that has lived through two of the hardest years this nation has ever faced. \\n\\nThe pandemic has been punishing. \\n\\nAnd so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more. \\n\\nI understand. \\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it. \\n\\nThat’s why one of the first things I did as President was fight to pass the American Rescue Plan.  \\n\\nBecause people were hurting. We needed to act, and we did. \\n\\nFew pieces of legislation have done more in a critical moment in our history to lift us out of crisis. \\n\\nIt fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.  \\n\\nHelped put food on their table, keep a roof over their heads, and cut the cost of health insurance. \\n\\nAnd as my Dad used to say, it gave people a little breathing room. \\n\\nAnd unlike the $2 Trillion tax cut passed in the previous administration that benefitted the top 1% of Americans, the American Rescue Plan helped working people—and left no one behind. \\n\\nAnd it worked. It created jobs. Lots of jobs. \\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year  \\nthan ever before in the history of America. \\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.  \\n\\nFor the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else. \\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century. \\n\\nVice President Harris and I ran for office with a new economic vision for America. \\n\\nInvest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up  \\nand the middle out, not from the top down.  \\n\\nBecause we know that when the middle class grows, the poor have a ladder up and the wealthy do very well. \\n\\nAmerica used to have the best roads, bridges, and airports on Earth. \\n\\nNow our infrastructure is ranked 13th in the world. \\n\\nWe won’t be able to compete for the jobs of the 21st Century if we don’t fix that. \\n\\nThat’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history. \\n\\nThis was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen. \\n\\nWe’re done talking about infrastructure weeks. \\n\\nWe’re going to have an infrastructure decade. \\n\\nIt is going to transform America and put us on a path to win the economic competition of the 21st Century that we face with the rest of the world—particularly with China.  \\n\\nAs I’ve told Xi Jinping, it is never a good bet to bet against the American people. \\n\\nWe’ll create good jobs for millions of Americans, modernizing roads, airports, ports, and waterways all across America. \\n\\nAnd we’ll do it all to withstand the devastating effects of the climate crisis and promote environmental justice. \\n\\nWe’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school, provide affordable high-speed internet for every American—urban, suburban, rural, and tribal communities. \\n\\n4,000 projects have already been announced. \\n\\nAnd tonight, I’m announcing that this year we will start fixing over 65,000 miles of highway and 1,500 bridges in disrepair. \\n\\nWhen we use taxpayer dollars to rebuild America – we are going to Buy American: buy American products to support American jobs. \\n\\nThe federal government spends about $600 Billion a year to keep the country safe and secure. \\n\\nThere’s been a law on the books for almost a century \\nto make sure taxpayers’ dollars support American jobs and businesses. \\n\\nEvery Administration says they’ll do it, but we are actually doing it. \\n\\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \\n\\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors. \\n\\nThat’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing. \\n\\nLet me give you one example of why it’s so important to pass it. \\n\\nIf you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land. \\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill. \\n\\nSo let’s not wait any longer. Send it to my desk. I’ll sign it.  \\n\\nAnd we will really take off. \\n\\nAnd Intel is not alone. \\n\\nThere’s something happening in America. \\n\\nJust look around and you’ll see an amazing story. \\n\\nThe rebirth of the pride that comes from stamping products “Made In America.” The revitalization of American manufacturing.   \\n\\nCompanies are choosing to build new factories here, when just a few years ago, they would have built them overseas. \\n\\nThat’s what is happening. Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. \\n\\nGM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan. \\n\\nAll told, we created 369,000 new manufacturing jobs in America just last year. \\n\\nPowered by people I’ve met like JoJo Burgess, from generations of union steelworkers from Pittsburgh, who’s here with us tonight. \\n\\nAs Ohio Senator Sherrod Brown says, “It’s time to bury the label “Rust Belt.” \\n\\nIt’s time. \\n\\nBut with all the bright spots in our economy, record job growth and higher wages, too many families are struggling to keep up with the bills.  \\n\\nInflation is robbing them of the gains they might otherwise feel. \\n\\nI get it. That’s why my top priority is getting prices under control. \\n\\nLook, our economy roared back faster than most predicted, but the pandemic meant that businesses had a hard time hiring enough workers to keep up production in their factories. \\n\\nThe pandemic also disrupted global supply chains. \\n\\nWhen factories close, it takes longer to make goods and get them from the warehouse to the store, and prices go up. \\n\\nLook at cars. \\n\\nLast year, there weren’t enough semiconductors to make all the cars that people wanted to buy. \\n\\nAnd guess what, prices of automobiles went up. \\n\\nSo—we have a choice. \\n\\nOne way to fight inflation is to drive down wages and make Americans poorer.  \\n\\nI have a better plan to fight inflation. \\n\\nLower your costs, not your wages. \\n\\nMake more cars and semiconductors in America. \\n\\nMore infrastructure and innovation in America. \\n\\nMore goods moving faster and cheaper in America. \\n\\nMore jobs where you can earn a good living in America. \\n\\nAnd instead of relying on foreign supply chains, let’s make it in America. \\n\\nEconomists call it “increasing the productive capacity of our economy.” \\n\\nI call it building a better America. \\n\\nMy plan to fight inflation will lower your costs and lower the deficit. \\n\\n17 Nobel laureates in economics say my plan will ease long-term inflationary pressures. Top business leaders and most Americans support my plan. And here’s the plan: \\n\\nFirst – cut the cost of prescription drugs. Just look at insulin. One in ten Americans has diabetes. In Virginia, I met a 13-year-old boy named Joshua Davis.  \\n\\nHe and his Dad both have Type 1 diabetes, which means they need insulin every day. Insulin costs about $10 a vial to make.  \\n\\nBut drug companies charge families like Joshua and his Dad up to 30 times more. I spoke with Joshua’s mom. \\n\\nImagine what it’s like to look at your child who needs insulin and have no idea how you’re going to pay for it.  \\n\\nWhat it does to your dignity, your ability to look your child in the eye, to be the parent you expect to be. \\n\\nJoshua is here with us tonight. Yesterday was his birthday. Happy birthday, buddy.  \\n\\nFor Joshua, and for the 200,000 other young people with Type 1 diabetes, let’s cap the cost of insulin at $35 a month so everyone can afford it.  \\n\\nDrug companies will still do very well. And while we’re at it let Medicare negotiate lower prices for prescription drugs, like the VA already does. \\n\\nLook, the American Rescue Plan is helping millions of families on Affordable Care Act plans save $2,400 a year on their health care premiums. Let’s close the coverage gap and make those savings permanent. \\n\\nSecond – cut energy costs for families an average of $500 a year by combatting climate change.  \\n\\nLet’s provide investments and tax credits to weatherize your homes and businesses to be energy efficient and you get a tax credit; double America’s clean energy production in solar, wind, and so much more;  lower the price of electric vehicles, saving you another $80 a month because you’ll never have to pay at the gas pump again. \\n\\nThird – cut the cost of child care. Many families pay up to $14,000 a year for child care per child.  \\n\\nMiddle-class and working families shouldn’t have to pay more than 7% of their income for care of young children.  \\n\\nMy plan will cut the cost in half for most families and help parents, including millions of women, who left the workforce during the pandemic because they couldn’t afford child care, to be able to get back to work. \\n\\nMy plan doesn’t stop there. It also includes home and long-term care. More affordable housing. And Pre-K for every 3- and 4-year-old.  \\n\\nAll of these will lower costs. \\n\\nAnd under my plan, nobody earning less than $400,000 a year will pay an additional penny in new taxes. Nobody.  \\n\\nThe one thing all Americans agree on is that the tax system is not fair. We have to fix it.  \\n\\nI’m not looking to punish anyone. But let’s make sure corporations and the wealthiest Americans start paying their fair share. \\n\\nJust last year, 55 Fortune 500 corporations earned $40 billion in profits and paid zero dollars in federal income tax.  \\n\\nThat’s simply not fair. That’s why I’ve proposed a 15% minimum tax rate for corporations. \\n\\nWe got more than 130 countries to agree on a global minimum tax rate so companies can’t get out of paying their taxes at home by shipping jobs and factories overseas. \\n\\nThat’s why I’ve proposed closing loopholes so the very wealthy don’t pay a lower tax rate than a teacher or a firefighter.  \\n\\nSo that’s my plan. It will grow the economy and lower costs for families. \\n\\nSo what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted. \\n\\nBut in my administration, the watchdogs have been welcomed back. \\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year. \\n\\nLowering your costs also means demanding more competition. \\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism. \\n\\nIt’s exploitation—and it drives up prices. \\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \\n\\nWe see it happening with ocean carriers moving goods in and out of America. \\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits. \\n\\nTonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \\n\\nThat ends on my watch. \\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect. \\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees. \\n\\nLet’s pass the Paycheck Fairness Act and paid leave.  \\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty. \\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges. \\n\\nAnd let’s pass the PRO Act when a majority of workers want to form a union—they shouldn’t be stopped.  \\n\\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven’t done in a long time: build a better America. \\n\\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation. \\n\\nAnd I know you’re tired, frustrated, and exhausted. \\n\\nBut I also know this. \\n\\nBecause of the progress we’ve made, because of your resilience and the tools we have, tonight I can say  \\nwe are moving forward safely, back to more normal routines.  \\n\\nWe’ve reached a new moment in the fight against COVID-19, with severe cases down to a level not seen since last July.  \\n\\nJust a few days ago, the Centers for Disease Control and Prevention—the CDC—issued new mask guidelines. \\n\\nUnder these new guidelines, most Americans in most of the country can now be mask free.   \\n\\nAnd based on the projections, more of the country will reach that point across the next couple of weeks. \\n\\nThanks to the progress we have made this past year, COVID-19 need no longer control our lives.  \\n\\nI know some are talking about “living with COVID-19”. Tonight – I say that we will never just accept living with COVID-19. \\n\\nWe will continue to combat the virus as we do other diseases. And because this is a virus that mutates and spreads, we will stay on guard. \\n\\nHere are four common sense steps as we move forward safely.  \\n\\nFirst, stay protected with vaccines and treatments. We know how incredibly effective vaccines are. If you’re vaccinated and boosted you have the highest degree of protection. \\n\\nWe will never give up on vaccinating more Americans. Now, I know parents with kids under 5 are eager to see a vaccine authorized for their children. \\n\\nThe scientists are working hard to get that done and we’ll be ready with plenty of vaccines when they do. \\n\\nWe’re also ready with anti-viral treatments. If you get COVID-19, the Pfizer pill reduces your chances of ending up in the hospital by 90%.  \\n\\nWe’ve ordered more of these pills than anyone in the world. And Pfizer is working overtime to get us 1 Million pills this month and more than double that next month.  \\n\\nAnd we’re launching the “Test to Treat” initiative so people can get tested at a pharmacy, and if they’re positive, receive antiviral pills on the spot at no cost.  \\n\\nIf you’re immunocompromised or have some other vulnerability, we have treatments and free high-quality masks. \\n\\nWe’re leaving no one behind or ignoring anyone’s needs as we move forward. \\n\\nAnd on testing, we have made hundreds of millions of tests available for you to order for free.   \\n\\nEven if you already ordered free tests tonight, I am announcing that you can order more from covidtests.gov starting next week. \\n\\nSecond – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants. \\n\\nIf necessary, we’ll be able to deploy new vaccines within 100 days instead of many more months or years.  \\n\\nAnd, if Congress provides the funds we need, we’ll have new stockpiles of tests, masks, and pills ready if needed. \\n\\nI cannot promise a new variant won’t come. But I can promise you we’ll do everything within our power to be ready if it does.  \\n\\nThird – we can end the shutdown of schools and businesses. We have the tools we need. \\n\\nIt’s time for Americans to get back to work and fill our great downtowns again.  People working from home can feel safe to begin to return to the office.   \\n\\nWe’re doing that here in the federal government. The vast majority of federal workers will once again work in person. \\n\\nOur schools are open. Let’s keep it that way. Our kids need to be in school. \\n\\nAnd with 75% of adult Americans fully vaccinated and hospitalizations down by 77%, most Americans can remove their masks, return to work, stay in the classroom, and move forward safely. \\n\\nWe achieved this because we provided free vaccines, treatments, tests, and masks. \\n\\nOf course, continuing this costs money. \\n\\nI will soon send Congress a request. \\n\\nThe vast majority of Americans have used these tools and may want to again, so I expect Congress to pass it quickly.   \\n\\nFourth, we will continue vaccinating the world.     \\n\\nWe’ve sent 475 Million vaccine doses to 112 countries, more than any other nation. \\n\\nAnd we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves. \\n\\nI’ve worked on these issues a long time. \\n\\nI know what works: Investing in crime prevention and community police officers who’ll walk the beat, who’ll know the neighborhood, and who can restore trust and safety. \\n\\nSo let’s not abandon our streets. Or choose between safety and equal justice. \\n\\nLet’s come together to protect our communities, restore trust, and hold law enforcement accountable. \\n\\nThat’s why the Justice Department required body cameras, banned chokeholds, and restricted no-knock warrants for its officers. \\n\\nThat’s why the American Rescue Plan provided $350 Billion that cities, states, and counties can use to hire more police and invest in proven strategies like community violence interruption—trusted messengers breaking the cycle of violence and trauma and giving young people hope.  \\n\\nWe should all agree: The answer is not to Defund the police. The answer is to FUND the police with the resources and training they need to protect our communities. \\n\\nI ask Democrats and Republicans alike: Pass my budget and keep our neighborhoods safe.  \\n\\nAnd I will keep doing everything in my power to crack down on gun trafficking and ghost guns you can buy online and make at home—they have no serial numbers and can’t be traced. \\n\\nAnd I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon? \\n\\nBan assault weapons and high-capacity magazines. \\n\\nRepeal the liability shield that makes gun manufacturers the only industry in America that can’t be sued. \\n\\nThese laws don’t infringe on the Second Amendment. They save lives. \\n\\nThe most fundamental right in America is the right to vote – and to have it counted. And it’s under assault. \\n\\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \\n\\nWe cannot let this happen. \\n\\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \\n\\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders. \\n\\nWe can do all this while keeping lit the torch of liberty that has led generations of immigrants to this land—my forefathers and so many of yours. \\n\\nProvide a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. \\n\\nRevise our laws so businesses have the workers they need and families don’t wait decades to reunite. \\n\\nIt’s not only the right thing to do—it’s the economically smart thing to do. \\n\\nThat’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce. \\n\\nLet’s get it done once and for all. \\n\\nAdvancing liberty and justice also requires protecting the rights of women. \\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before. \\n\\nIf we want to go forward—not backward—we must protect access to health care. Preserve a woman’s right to choose. And let’s continue to advance maternal health care in America. \\n\\nAnd for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong. \\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice. \\n\\nAnd soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things. \\n\\nSo tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.  \\n\\nFirst, beat the opioid epidemic. \\n\\nThere is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.  \\n\\nGet rid of outdated rules that stop doctors from prescribing treatments. And stop the flow of illicit drugs by working with state and local law enforcement to go after traffickers. \\n\\nIf you’re suffering from addiction, know you are not alone. I believe in recovery, and I celebrate the 23 million Americans in recovery. \\n\\nSecond, let’s take on mental health. Especially among our children, whose lives and education have been turned upside down.  \\n\\nThe American Rescue Plan gave schools money to hire teachers and help students make up for lost learning.  \\n\\nI urge every parent to make sure your school does just that. And we can all play a part—sign up to be a tutor or a mentor. \\n\\nChildren were also struggling before the pandemic. Bullying, violence, trauma, and the harms of social media. \\n\\nAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they’re conducting on our children for profit. \\n\\nIt’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children. \\n\\nAnd let’s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care. \\n\\nThird, support our veterans. \\n\\nVeterans are the best of us. \\n\\nI’ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home. \\n\\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \\n\\nOur troops in Iraq and Afghanistan faced many dangers. \\n\\nOne was stationed at bases and breathing in toxic smoke from “burn pits” that incinerated wastes of war—medical and hazard material, jet fuel, and more. \\n\\nWhen they came home, many of the world’s fittest and best trained warriors were never the same. \\n\\nHeadaches. Numbness. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. \\n\\nI know. \\n\\nOne of those soldiers was my son Major Beau Biden. \\n\\nWe don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. \\n\\nBut I’m committed to finding out everything we can. \\n\\nCommitted to military families like Danielle Robinson from Ohio. \\n\\nThe widow of Sergeant First Class Heath Robinson.  \\n\\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq. \\n\\nStationed near Baghdad, just yards from burn pits the size of football fields. \\n\\nHeath’s widow Danielle is here with us tonight. They loved going to Ohio State football games. He loved building Legos with their daughter. \\n\\nBut cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body. \\n\\nDanielle says Heath was a fighter to the very end. \\n\\nHe didn’t know how to stop fighting, and neither did she. \\n\\nThrough her pain she found purpose to demand we do better. \\n\\nTonight, Danielle—we are. \\n\\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits. \\n\\nAnd tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers. \\n\\nI’m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve. \\n\\nAnd fourth, let’s end cancer as we know it. \\n\\nThis is personal to me and Jill, to Kamala, and to so many of you. \\n\\nCancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.  \\n\\nWe will meet the test. \\n\\nTo protect freedom and liberty, to expand fairness and opportunity. \\n\\nWe will save democracy. \\n\\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life. \\n\\nBecause I see the future that is within our grasp. \\n\\nBecause I know there is simply nothing beyond our capacity. \\n\\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity. \\n\\nThe only nation that can be defined by a single word: possibilities. \\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union. \\n\\nAnd my report is this: the State of the Union is strong—because you, the American people, are strong. \\n\\nWe are stronger today than we were a year ago. \\n\\nAnd we will be stronger a year from now than we are today. \\n\\nNow is our moment to meet and overcome the challenges of our time. \\n\\nAnd we will, as one people. \\n\\nOne America. \\n\\nThe United States of America. \\n\\nMay God bless you all. May God protect our troops.')]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AcCm2K35qgZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It should create documents smaller than the parent\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500)"
      ],
      "metadata": {
        "id": "ZaSS8gQPrnyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)"
      ],
      "metadata": {
        "id": "J6t4Qvu_rz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store1 = InMemoryStore()"
      ],
      "metadata": {
        "id": "QhN8Josmr5Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore1 = Chroma(collection_name=\"full_documents\" , embedding_function=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "_vTsi_nIr_p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever1 = ParentDocumentRetriever(\n",
        "    vectorstore = vectorstore1, # where to embed/search chroma\n",
        "    docstore = store1, # from where to fecth the full parents\n",
        "    child_splitter = child_splitter, # how to create the childern from parent\n",
        "    parent_splitter = parent_splitter, # how to create the parents from parent\n",
        "    )"
      ],
      "metadata": {
        "id": "rvHSpmFRsKGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making the index\n",
        "retriever1.add_documents(docs)"
      ],
      "metadata": {
        "id": "ECE0QtgZsSms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(store1.yield_keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhfPep4ws0AA",
        "outputId": "c68d7c1e-2d02-4483-cf35-45e24b800a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_2 = retriever1.invoke(\"What did the president say about Ketanji Brown Jackson\")"
      ],
      "metadata": {
        "id": "7yWiiyPWs3bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2LpK4q6tPRZ",
        "outputId": "726c7d5b-4323-4e04-affb-7118e4978d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Document_texts/state_of_the_union.txt'}, page_content='In state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \\n\\nWe cannot let this happen. \\n\\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \\n\\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.')]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=llm_model,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=retriever1)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\""
      ],
      "metadata": {
        "id": "GV0MMG-Otfqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa.invoke(query)"
      ],
      "metadata": {
        "id": "zvSbS1jOtkZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4swh_thtrWg",
        "outputId": "c6e1e5cf-f45e-4e9b-ee3f-d4c16ef19580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The President praised Judge Ketanji Brown Jackson as one of the nation's top legal minds who will continue Justice Breyer's legacy of excellence. He highlighted her background as a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also mentioned that since she's been nominated, she received broad support ranging from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1YTjSq-7q_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypothetical Document Embeddings"
      ],
      "metadata": {
        "id": "n8sd1ESigqVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_chroma langchain_community langchain_openai langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAc0LFC9guan",
        "outputId": "9c386671-6d57-448c-e6b0-e809043c8b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain_chroma) (0.3.74)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain_chroma) (2.0.2)\n",
            "Collecting chromadb>=1.0.9 (from langchain_chroma)\n",
            "  Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.100.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.36.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.4)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m892.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (3.11.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.25.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain_chroma) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.70->langchain_chroma) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.70->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.27.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.3.1)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma) (0.57b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.34.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=e6e2ab9372201bf1ab705ccaa9e3dff4467668f628f24db0098f61f6592d9966\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, dataclasses-json, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, chromadb, langchain_community, langchain_chroma\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.20 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain_chroma-0.2.5 langchain_community-0.3.27 langchain_openai-0.3.30 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "ewQ683ASg1Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI , OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "YkDW-lxThL3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = ChatOpenAI()\n",
        "embedding_model = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "B6eAcxi6hBIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA LOADING"
      ],
      "metadata": {
        "id": "eHtn_XIwhKfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf1gKnRehYdM",
        "outputId": "4e3e7dc3-ab57-4f4b-e7ae-319313b9e83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader('https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/')"
      ],
      "metadata": {
        "id": "3ERBwoTDhfzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "LtI62uL1h43j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCJOdDKRh7_Y",
        "outputId": "5767aa0e-db84-4e21-a6f5-c473e2392165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\nPrompt Engineering | Lil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil\\'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Prompt Engineering\\n    \\nDate: March 15, 2023  |  Estimated Reading Time: 21 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nBasic Prompting\\n\\nZero-Shot\\n\\nFew-shot\\n\\nTips for Example Selection\\n\\nTips for Example Ordering\\n\\n\\n\\nInstruction Prompting\\n\\nSelf-Consistency Sampling\\n\\nChain-of-Thought (CoT)\\n\\nTypes of CoT prompts\\n\\nTips and Extensions\\n\\n\\nAutomatic Prompt Design\\n\\nAugmented Language Models\\n\\nRetrieval\\n\\nProgramming Language\\n\\nExternal APIs\\n\\n\\nCitation\\n\\nUseful Resources\\n\\nReferences\\n\\n\\n\\n\\n\\nPrompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.\\n[My personal spicy take] In my opinion, some prompt engineering papers are not worthy 8 pages long, since those tricks can be explained in one or a few sentences and the rest is all about benchmarking. An easy-to-use and shared benchmark infrastructure should be more beneficial to the community. Iterative prompting or external tool use would not be trivial to set up. Also non-trivial to align the whole research community to adopt it.\\nBasic Prompting#\\nZero-shot and few-shot learning are two most basic approaches for prompting the model, pioneered by many LLM papers and commonly used for benchmarking LLM performance.\\nZero-Shot#\\nZero-shot learning is to simply feed the task text to the model and ask for results.\\n(All the sentiment analysis examples are from SST-2)\\nText: i\\'ll bet the video game is a lot more fun than the film.\\nSentiment:\\nFew-shot#\\nFew-shot learning presents a set of high-quality demonstrations, each consisting of both input and desired output, on the target task. As the model first sees good examples, it can better understand human intention and criteria for what kinds of answers are wanted. Therefore, few-shot learning often leads to better performance than zero-shot. However, it comes at the cost of more token consumption and may hit the context length limit when input and output text are long.\\nText: (lawrence bounces) all over the stage, dancing, running, sweating, mopping his face and generally displaying the wacky talent that brought him fame in the first place.\\nSentiment: positive\\n\\nText: despite all evidence to the contrary, this clunker has somehow managed to pose as an actual feature movie, the kind that charges full admission and gets hyped on tv and purports to amuse small children and ostensible adults.\\nSentiment: negative\\n\\nText: for the first time in years, de niro digs deep emotionally, perhaps because he\\'s been stirred by the powerful work of his co-stars.\\nSentiment: positive\\n\\nText: i\\'ll bet the video game is a lot more fun than the film.\\nSentiment:\\nMany studies looked into how to construct in-context examples to maximize the performance and observed that choice of prompt format, training examples, and the order of the examples can lead to dramatically different performance, from near random guess to near SoTA.\\nZhao et al. (2021) investigated the case of few-shot classification and proposed that several biases with LLM (they use GPT-3 in the experiments) contribute to such high variance: (1) Majority label bias exists if distribution of labels among the examples is unbalanced; (2) Recency bias refers to the tendency where the model may repeat the label at the end; (3) Common token bias indicates that LLM tends to produce common tokens more often than rare tokens. To conquer such bias, they proposed a method to calibrate the label probabilities output by the model to be uniform when the input string is N/A.\\nTips for Example Selection#\\n\\n\\nChoose examples that are semantically similar to the test example using $k$-NN clustering in the embedding space (Liu et al., 2021)\\n\\n\\nTo select a diverse and representative set of examples, Su et al. (2022) proposed to use a graph-based approach: (1) First, construct a directed graph $G=(V, E)$ based on the embedding (e.g. by SBERT or other embedding models) cosine similarity between samples, where each node points to its $k$ nearest neighbors; (2) Start with a set of selected samples $\\\\mathcal{L}=\\\\emptyset$ and a set of remaining samples $\\\\mathcal{U}$. Each sample $u \\\\in \\\\mathcal{U}$ is scored by $$\\n\\\\text{score}(u) = \\\\sum_{v \\\\in \\\\{v \\\\mid (u, v) \\\\in E, v\\\\in \\\\mathcal{U}\\\\}} s(v)\\\\quad\\\\text{where }s(v)=\\\\rho^{- \\\\vert \\\\{\\\\ell \\\\in \\\\mathcal{L} \\\\vert (v, \\\\ell)\\\\in E \\\\}\\\\vert},\\\\quad\\\\rho > 1\\n$$ such that $s(v)$ is low if many of $v$’s neighbors are selected and thus the scoring encourages to pick diverse samples.\\n\\n\\nRubin et al. (2022) proposed to train embeddings via contrastive learning specific to one training dataset for in-context learning sample selection.  Given each training pair $(x, y)$, the quality of one example $e_i$ (formatted input-output pair) can be measured by a conditioned probability assigned by LM: $\\\\text{score}(e_i) = P_\\\\text{LM}(y \\\\mid e_i, x)$. We can identify other examples with top-$k$ and bottom-$k$ scores as positive and negative sets of candidates for every training pair and use that for contrastive learning.\\n\\n\\nSome researchers tried Q-Learning to do sample selection. (Zhang et al. 2022)\\n\\n\\nMotivated by uncertainty-based active learning, Diao et al. (2023) suggested to identify examples with high disagreement or entropy among multiple sampling trials. Then annotate these examples to be used in few-shot prompts.\\n\\n\\nTips for Example Ordering#\\n\\nA general suggestion is to keep the selection of examples diverse, relevant to the test sample and in random order to avoid majority label bias and recency bias.\\nIncreasing model sizes or including more training examples does not reduce variance among different permutations of in-context examples. Same order may work well for one model but badly for another. When the validation set is limited, consider choosing the order such that the model does not produce extremely unbalanced predictions or being overconfident about its predictions. (Lu et al. 2022)\\n\\nInstruction Prompting#\\nThe purpose of presenting few-shot examples in the prompt is to explain our intent to the model; in other words, describe the task instruction to the model in the form of demonstrations. However, few-shot can be expensive in terms of token usage and restricts the input length due to limited context length. So, why not just give the instruction directly?\\nInstructed LM (e.g. InstructGPT, natural instruction) finetunes a pretrained model with high-quality tuples of (task instruction, input, ground truth output) to make LM better understand user intention and follow instruction. RLHF (Reinforcement Learning from Human Feedback) is a common method to do so. The benefit of instruction following style fine-tuning improves the model to be more aligned with human intention and greatly reduces the cost of communication.\\nWhen interacting with instruction models, we should describe the task requirement in details, trying to be specific and precise and avoiding say “not do something” but rather specify what to do.\\nPlease label the sentiment towards the movie of the given movie review. The sentiment label should be \"positive\" or \"negative\". \\nText: i\\'ll bet the video game is a lot more fun than the film. \\nSentiment:\\nExplaining the desired audience is another smart way to give instructions\\n\\nFor example to produce education materials for kids,\\n\\nDescribe what is quantum physics to a 6-year-old.\\n\\nAnd safe content,\\n\\n... in language that is safe for work.\\nIn-context instruction learning (Ye et al. 2023) combines few-shot learning with instruction prompting. It incorporates multiple demonstration examples across different tasks in the prompt, each demonstration consisting of instruction, task input and output. Note that their experiments were only on classification tasks and the instruction prompt contains all label options.\\nDefinition: Determine the speaker of the dialogue, \"agent\" or \"customer\".\\nInput: I have successfully booked your tickets.\\nOuput: agent\\n\\nDefinition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location\\n\\nDefinition: Classify the sentiment of the given movie review, \"positive\" or \"negative\".\\nInput: i\\'ll bet the video game is a lot more fun than the film.\\nOutput:\\nSelf-Consistency Sampling#\\nSelf-consistency sampling (Wang et al. 2022a) is to sample multiple outputs with temperature > 0 and then selecting the best one out of these candidates.\\nThe criteria for selecting the best candidate can vary from task to task. A general solution is to pick majority vote. For tasks that are easy to validate such as a programming question with unit tests, we can simply run through the interpreter and verify the correctness with unit tests.\\nChain-of-Thought (CoT)#\\nChain-of-thought (CoT) prompting (Wei et al. 2022) generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. The benefit of CoT is more pronounced for complicated reasoning tasks, while using large models (e.g. with more than 50B parameters). Simple tasks only benefit slightly from CoT prompting.\\nTypes of CoT prompts#\\nTwo main types of CoT prompting:\\n\\nFew-shot CoT. It is to prompt the model with a few demonstrations, each containing manually written (or model-generated) high-quality reasoning chains.\\n\\n(All the math reasoning examples are from GSM8k)\\nQuestion: Tom and Elizabeth have a competition to climb a hill. Elizabeth takes 30 minutes to climb the hill. Tom takes four times as long as Elizabeth does to climb the hill. How many hours does it take Tom to climb up the hill?\\nAnswer: It takes Tom 30*4 = <<30*4=120>>120 minutes to climb the hill.\\nIt takes Tom 120/60 = <<120/60=2>>2 hours to climb the hill.\\nSo the answer is 2.\\n===\\nQuestion: Jack is a soccer player. He needs to buy two pairs of socks and a pair of soccer shoes. Each pair of socks cost $9.50, and the shoes cost $92. Jack has $40. How much more money does Jack need?\\nAnswer: The total cost of two pairs of socks is $9.50 x 2 = $<<9.5*2=19>>19.\\nThe total cost of the socks and the shoes is $19 + $92 = $<<19+92=111>>111.\\nJack need $111 - $40 = $<<111-40=71>>71 more.\\nSo the answer is 71.\\n===\\nQuestion: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?\\nAnswer:\\n\\nZero-shot CoT. Use natural language statement like Let\\'s think step by step to explicitly encourage the model to first generate reasoning chains and then to prompt with Therefore, the answer is to produce answers (Kojima et al. 2022 ). Or a similar statement Let\\'s work this out it a step by step to be sure we have the right answer (Zhou et al. 2022).\\n\\nQuestion: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?\\nAnswer: Let\\'s think step by step.\\nTips and Extensions#\\n\\n\\nSelf-consistency sampling can improve reasoning accuracy by sampling a number of diverse answers and then taking the majority vote. (Wang et al. 2022a)\\n\\n\\nAnother approach for ensemble learning is to alter the example order or use model generated rationales to replace human-written ones to introduce randomness during multiple sample trials. Then aggregate model outputs with a majority vote to get final answer. (Wang et al. 2022b)\\n\\n\\nIf training examples are only associated with true answers (easy to verify!) but no rationales, we can follow the STaR (Self-Taught Reasoner; Zelikman et al. 2022) method : (1) Ask LLM to generate reasoning chains and only keep those leading to correct answers; (2) Then fine-tune the model with generated rationales and repeat the process until convergence. Note that higher temperature is more likely to generate incorrect rationales with correct answers. If training examples do not have ground truth answers, maybe consider using majority votes as the “correct” answers.\\n\\n\\nPrompts with demonstrations of higher reasoning complexity can achieve better performance, where complexity is measured by the number of reasoning steps in the chains. When separating reasoning steps, newline \\\\n symbol works better than step i, period . or semicolon ;. (Fu et al. 2023)\\n\\n\\nComplexity-based consistency is to explicitly prefer complex chains among all the generations by taking majority vote among only top $k$ complex chains. (Fu et al. 2023)\\n\\n\\nLater, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)\\n\\n\\nYe & Durrett (2022) found that the benefit of including explanations in the prompt is small to moderate for NLP tasks that involve reasoning over text (i.e. QA and NLI) and the effects vary by models. They observed that explanations are more likely to be nonfactual than be inconsistent (i.e. whether explanation entails prediction). Nonfactual explanations most likely lead to incorrect predictions.\\n\\n\\nSelf-Ask (Press et al. 2022) is a method to repeatedly prompt the model to ask following-up questions to construct the thought process iteratively. Follow-up questions can be answered by search engine results. Similarly, IRCoT (Interleaving Retrieval CoT; Trivedi et al. 2022) and ReAct (Reason + Act; Yao et al. 2023) combines iterative CoT prompting with queries to Wikipedia APIs to search for relevant entities and content and then add it back into the context.\\n\\n\\n\\n\\nHow Self-Ask works with external search queries.(Image source: Press et al. 2022).\\n\\n\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, essentially creating a tree structure. The search process can be BFS or DFS while each state is evaluated by a classifier (via a prompt) or majority vote.\\n\\n\\n\\nHow Self-Ask works with external search queries.(Image source: Yao et al. 2022).\\n\\nAutomatic Prompt Design#\\nPrompt is a sequence of prefix tokens that increase the probability of getting  desired output given input. Therefore we can treat them as trainable parameters and optimize them directly on the embedding space via gradient descent, such as AutoPrompt (Shin et al., 2020, Prefix-Tuning (Li & Liang (2021)), P-tuning (Liu et al. 2021) and Prompt-Tuning (Lester et al. 2021). This section in my “Controllable Neural Text Generation” post has a good coverage of them. The trend from AutoPrompt to Prompt-Tuning is that the setup gets gradually simplified.\\nAPE (Automatic Prompt Engineer; Zhou et al. 2022) is a method to search over a pool of model-generated instruction candidates and then filters the candidate set according to a chosen score function to ultimately choose the best candidate with highest score.\\n\\n\\nPrompt LLM to generate instruction candidates based on a small set of demonstrations in the form of input-output pairs. E.g. {{Given desired input-output pairs}}\\\\n\\\\nThe instruction is.\\n\\n\\nGiven a dataset of $\\\\mathcal{D}_\\\\text{train} = \\\\{(x, y)\\\\}$, we would like to find an instruction $\\\\rho$ such that $\\\\rho^* = \\\\arg\\\\max_\\\\rho \\\\mathbb{E}_{(x, y) \\\\in \\\\mathcal{D}_\\\\text{train}} [f(\\\\rho, x, y)]$, where $f(.)$ is a per-sample score function, such as execution accuracy $\\\\mathbb{1}[\\\\text{LM}(.\\\\vert \\\\rho, x)=y]$ or log probability: $p_\\\\text{LM}(y \\\\mid \\\\rho, x)$.\\n\\n\\nUse an iterative Monte Carlo search method to improve the best candidates by proposing semantically similar variants via prompts like Generate a variation of the following instruction while keeping the semantic meaning.\\\\n\\\\nInput: ...\\\\n\\\\nOutput:...\\n\\n\\nTo construct chain-of-thought prompts automatically, Shum et al. (2023) suggested augment-prune-select, a three-step process:\\n\\nAugment: Generate multiple pseudo-chains of thought given question using few-shot or zero-shot CoT prompts;\\nPrune: Prune pseudo chains based on whether generated answers match ground truths.\\nSelect: Apply a variance-reduced policy gradient strategy to learn the probability distribution over selected examples, while considering the probability distribution over examples as policy and the validation set accuracy as reward.\\n\\nZhang et al. (2023) instead adopted clustering techniques to sample questions and then generates chains. They observed that LLMs tend to make certain types of mistakes. One type of errors can be similar in the emebedding space and thus get grouped together. By only sampling one or a few from frequent-error clusters, we can prevent too many wrong demonstrations of one error type and collect a diverse set of examples.\\n\\nQuestion clustering: Embed questions and run $k$-means for clustering.\\nDemonstration selection: Select a set of representative questions from each cluster; i.e. one demonstration from one cluster. Samples in each cluster are sorted by distance to the cluster centroid and those closer to the centroid are selected first.\\nRationale generation: Use zero-shot CoT to generate reasoning chains for selected questions and construct few-shot prompt to run inference.\\n\\nAugmented Language Models#\\nA survey on augmented language models by Mialon et al. (2023) has great coverage over multiple categories of language models augmented with reasoning skills and the ability of using external tools. Recommend it.\\nRetrieval#\\nOften we need to complete tasks that require latest knowledge after the model pretraining time cutoff or internal/private knowledge base. In that case, the model would not know the context if we don’t explicitly provide it in the prompt. Many methods for Open Domain Question Answering depend on first doing retrieval over a knowledge base and then incorporating the retrieved content as part of the prompt. The accuracy of such a process depends on the quality of both retrieval and generation steps.\\nLazaridou et al. (2022) studied how to use Google Search for document retrieval to augment LLMs. Given a question $q$, clean text is extracted out of 20 URLs returned by Google, resulting in a set of documents. Because these documents are long, each document is split into paragraphs of 6 sentences, $\\\\{p\\\\}$. Paragraphs are ranked by TF-IDF based cosine similarity between evidence paragraphs and the query. Only the most relevant paragraph is used in the prompt to produce an answer $a$.\\nFor closed-book QA, each demonstration is formatted as follows to construct few-shot prompts. Swapping the question with the evidence (longer distance between questions and answers) is found to consistently yield lower results across all datasets.\\nEvidence: ...\\nQuestion: ...\\nAnswer: ...\\nThe answer probability is computed in three ways:\\n\\nRAG style, $p(a_i \\\\mid q) = \\\\sum_{i=1}^n p_\\\\text{tf-idf} (p_i \\\\mid q) \\\\cdot p_\\\\text{LM}(a_i \\\\mid q, p_i)$, where $p_\\\\text{tf-idf} (p_i \\\\mid q)$ is the normalized cosine similarities between the TF-IDF passage and question representations.\\nNoisy channel inference, $p(a_i\\\\mid q) = \\\\frac{p_\\\\text{LM}(q \\\\mid a_i, p_i) \\\\cdot p_\\\\text{LM}(a_i \\\\mid p_i)}{p_\\\\text{LM}(q \\\\mid p_i)}$\\nProduct-of-Experts (PoE), combines all probabilities used above in addition to $p_\\\\text{LM}(p_i \\\\mid q)$.\\n\\nAccording to their experiments on generation and classification tasks, among three answer reranking scores - PoE > Noisy channel > RAG. Among individual probabilities, $p_\\\\text{LM}(a \\\\mid q, p_i)$ and $p_\\\\text{LM}(q \\\\mid p_i, a)$ are found to be most informative. $p_\\\\text{LM}(q \\\\mid p_i, a)$ captures how well the question can be explained by LM given evidence paragraph and answer and can reliably be used for reranking answer candidates.\\nOne observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.\\nInterestingly it is found to be beneficial even with only “internal retrieval”, that is, to generate knowledge about a topic before answering the question (Liu et al. 2022). First we can use  the following template to extract knowledge:\\nGenerate some knowledge about the input. Examples:\\n\\nInput: What type of water formation is formed by clouds?\\nKnowledge: Clouds are made of water vapor.\\n\\nInput: {question}\\nKnowledge:\\nAnd then with model-generated knowledge, prompt the LM further to get the answer.\\nProgramming Language#\\nBoth PAL (Program-aided language models); Gao et al. 2022) and PoT (Program of Thoughts prompting; Chen et al. 2022) ask LLM to generate programming language statements to resolve natural language reasoning problems, hence offloading the solution step to a runtime such as a Python interpreter. Such setup decouples complex computation and reasoning. It relies on a LM with good enough coding skills.\\n\\n\\nComparing CoT and PoT. (Image source: Chen et al. 2022).\\n\\nExternal APIs#\\nTALM (Tool Augmented Language Models; Parisi et al. 2022) is a language model augmented with text-to-text API calls. LM is guided to generate |tool-call and tool input text conditioned on task input text to construct API call requests. When |result shows up, the specified tool API is called and the returned result gets appended to the text sequence. The final output is generated following |output token.\\n\\n\\nThe format of API calls in TALM. (Image source: Parisi et al. 2022).\\n\\nTALM adopts a self-play approach to iteratively bootstrap the dataset of tool use examples and finetune LM with it. This self-play, defined as a model interacting with a tool API, iteratively expands the dataset based on whether a newly added tool API can improve the model outputs. Same idea is adopted in Toolformer too, described in more details below. The pipeline loosely mimics a RL process where LM is the policy network and it is trained by policy gradient with a binary reward signal.\\n\\n\\nSelf-play iterations help boost the model performance.(Image source: Parisi et al. 2022).\\n\\nToolformer (Schick et al. 2023) is a LM that can use external tools via simple APIs, which is built in a self-supervised manner and only requires a handful of demonstrations for each API. The toolbox of Toolformer includes:\\n\\nCalculator to help LM with the lack of precise math skills;\\nQ&A system to help with unfaithful content and hallucination;\\nSearch engine to provide up-to-date information after pretraining cut off time;\\nTranslation system to improve performance on low resource language;\\nCalendar to make LM be aware of time progression.\\n\\n\\n\\nIllustration of how to build Toolformer.(Image source: Schick et al. 2023).\\n\\nToolformer is trained as follows:\\n\\n\\nPrompting to annotate potential API calls. Ask a pre-trained LM to annotate a dataset via few-shot learning with API call usage examples. Formatting example:\\n\\n\\nHow dataset is annotated to do API calls.(Image source: Schick et al. 2023).\\n\\n\\n\\n- Each API call is represented as a tuple of (API name, corresponding input), $c=(a_c, i_c)$ and its corresponding result is denoted as $r$. The API call sequences with and without results are labeled as follows, respectively:\\n\\n    <div>\\n    $$\\n    \\\\begin{aligned}\\n    e(c) &= \\\\langle\\\\texttt{API}\\\\rangle a_c(i_c) \\\\langle\\\\texttt{/API}\\\\rangle \\\\\\\\\\n    e(c, r) &= \\\\langle\\\\texttt{API}\\\\rangle a_c(i_c) \\\\to r \\\\langle\\\\texttt{/API}\\\\rangle\\n    \\\\end{aligned}\\n    $$\\n    </div>\\n\\n- Sample API calls based on the probabilities $p_\\\\text{LM}(\\\\langle\\\\texttt{API}\\\\rangle \\\\mid \\\\text{prompt}(\\\\mathbf{x}), \\\\mathbf{x}_{1:i})$ and select top $k$ candidate positions for doing API calls at position $i$ if the probability is larger than a threshold.\\n\\n- Then we sample potential API calls from the LM given the sequence $[\\\\text{prompt}(\\\\mathbf{x}), x_1, \\\\dots, x_{i-1}, \\\\langle\\\\texttt{API}\\\\rangle]$ as prefix and $\\\\langle\\\\texttt{/API}\\\\rangle$ as suffix.\\n\\n\\n\\nFilter annotations based on whether API calls help model predict future tokens. Use a self-supervised loss to decide which API calls are actually helpful.\\n\\n\\nExecute each API call $c_i$ to get corresponding result $r_i$.\\n\\n\\nCompute weighted cross entropy loss for the LM over tokens $x_i, \\\\dots, x_n$ when the model is prefixed with the prompt. Two versions are computed, one with API result and the other with empty sequence $\\\\varepsilon$.\\n\\n  $$\\n  \\\\begin{aligned}\\n  L^+_i &= L_i(e(c_i, r_i)) \\\\\\\\\\n  L^-_i &= \\\\min(L_i(\\\\varepsilon), L_i(e(c_i, \\\\varepsilon))) \\\\\\\\\\n  \\\\end{aligned}\\n  $$\\n  \\nOnly API calls with $L^-_i - L^+_i$ larger than a threshold are kept, meaning that adding this API call and its results help the model predict future tokens.\\n\\n\\n\\n\\nFine-tune LM on this annotated dataset. The new training sequences are constructed as $\\\\mathbf{x}^* = x_{1:i-1}, e(c_i, r_i), x_{i:n}$ . The training data is a combination of the original dataset (e.g. a subset of CCNet, as in the paper) and its augmented version.\\n\\n\\nAt inference time, decoding runs until the model produces “$\\\\to$ \" token, indicating that it is expecting response from an API call next.\\nToolformer currently does not support tool use in a chain (i.e. using the output of one tool as an input for another tool) or in an interactive way (i.e. adopt API response after human selection). Both are interesting future directions to expand the model for.\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Mar 2023). Prompt Engineering. Lil’Log. https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/.\\n\\nOr\\n@article{weng2023prompt,\\n  title   = \"Prompt Engineering\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Mar\",\\n  url     = \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\"\\n}\\nUseful Resources#\\n\\nOpenAI Cookbook has many in-depth examples for how to utilize LLM efficiently.\\nLangChain, a library for combining language models with other components to build applications.\\nPrompt Engineering Guide repo contains a pretty comprehensive collection of education materials on prompt engineering.\\nlearnprompting.org\\nPromptPerfect\\nSemantic Kernel\\n\\nReferences#\\n[1] Zhao et al. “Calibrate Before Use: Improving Few-shot Performance of Language Models.” ICML 2021\\n[2] Liu et al. “What Makes Good In-Context Examples for GPT-3?” arXiv preprint arXiv:2101.06804 (2021).\\n[3] Lu et al. “Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity.” ACL 2022\\n[4] Ye et al. “In-Context Instruction Learning.” arXiv preprint arXiv:2302.14691 (2023).\\n[5] Su et al. “Selective annotation makes language models better few-shot learners.” arXiv preprint arXiv:2209.01975 (2022).\\n[6] Rubin et al. “Learning to retrieve prompts for in-context learning.” NAACL-HLT 2022\\n[7] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[8] Wang et al. “Self-Consistency Improves Chain of Thought Reasoning in Language Models.” ICLR 2023.\\n[9] Diao et al. “Active Prompting with Chain-of-Thought for Large Language Models.” arXiv preprint arXiv:2302.12246 (2023).\\n[10] Zelikman et al. “STaR: Bootstrapping Reasoning With Reasoning.” arXiv preprint arXiv:2203.14465 (2022).\\n[11] Ye & Durrett. “The unreliability of explanations in few-shot in-context learning.” arXiv preprint arXiv:2205.03401 (2022).\\n[12] Trivedi et al. “Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions.” arXiv preprint arXiv:2212.10509 (2022).\\n[13] Press et al. “Measuring and narrowing the compositionality gap in language models.” arXiv preprint arXiv:2210.03350 (2022).\\n[14] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[15] Fu et al. “Complexity-based prompting for multi-step reasoning.” arXiv preprint arXiv:2210.00720 (2022).\\n[16] Wang et al. “Rationale-augmented ensembles in language models.” arXiv preprint arXiv:2207.00747 (2022).\\n[17] Zhang et al. “Automatic chain of thought prompting in large language models.” arXiv preprint arXiv:2210.03493 (2022).\\n[18] Shum et al. “Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data.” arXiv preprint arXiv:2302.12822 (2023).\\n[19] Zhou et al. “Large Language Models Are Human-Level Prompt Engineers.” ICLR 2023.\\n[20] Lazaridou et al. “Internet augmented language models through few-shot prompting for open-domain question answering.” arXiv preprint arXiv:2203.05115 (2022).\\n[21] Chen et al. “Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks.” arXiv preprint arXiv:2211.12588 (2022).\\n[22] Gao et al. “PAL: Program-aided language models.” arXiv preprint arXiv:2211.10435 (2022).\\n[23] Parisi et al. “TALM: Tool Augmented Language Models” arXiv preprint arXiv:2205.12255 (2022).\\n[24] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[25] Mialon et al. “Augmented Language Models: a Survey” arXiv preprint arXiv:2302.07842 (2023).\\n[26] Yao et al. “Tree of Thoughts: Deliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n\\n\\n\\nNlp\\nLanguage-Model\\nAlignment\\nSteerability\\nPrompting\\n\\n\\n\\n« \\n\\nLLM Powered Autonomous Agents\\n\\n\\n »\\n\\nThe Transformer Family Version 2.0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Splitting / Creating Chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 300 , chunk_overlap = 50)\n",
        "\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "MqTk_Eazh-w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the documents\n",
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "UbpkSr9Si_rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=splits ,collection_name='my-collection',embedding = embedding_model)"
      ],
      "metadata": {
        "id": "73h2mwE_jLY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type='similarity' , search_kwargs={'k':2})"
      ],
      "metadata": {
        "id": "n3WJKMuuje8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a prompt template for generating HyDE"
      ],
      "metadata": {
        "id": "ztpG6bE1jpzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "For the given question try to generate a hypothetical answer\\\n",
        "only generate the answer and nothing else:\n",
        "Question : {question}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yn4eUjhJjznd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =  ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "MG8CGMS8kJa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = prompt.format_prompt(question='What are the differents Chain of Thought (CoT) Prompting ?')"
      ],
      "metadata": {
        "id": "fdxrgY1bkoFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_answer = llm_model.invoke(query).content"
      ],
      "metadata": {
        "id": "N9RwfY0akL61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothetical_answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XINseUqQk_1l",
        "outputId": "4758c3a2-4073-4780-e862-91ea3e8dbb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Some possible CoT Prompting techniques could include using analogy, asking probing questions, exploring different perspectives, brainstorming solutions, and challenging assumptions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieveral with hypothetical answer/document"
      ],
      "metadata": {
        "id": "7gvKUTLflBqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs = retriever.invoke(hypothetical_answer)"
      ],
      "metadata": {
        "id": "Gp4nK-H7lmoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEH4VXo8lpoL",
        "outputId": "9fa59513-9c52-49be-a9c1-6951b51890e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'language': 'en', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/'}, page_content='Types of CoT prompts#\\nTwo main types of CoT prompting:'),\n",
              " Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Table of Contents\\n\\n\\n\\nBasic Prompting\\n\\nZero-Shot\\n\\nFew-shot\\n\\nTips for Example Selection\\n\\nTips for Example Ordering\\n\\n\\n\\nInstruction Prompting\\n\\nSelf-Consistency Sampling\\n\\nChain-of-Thought (CoT)\\n\\nTypes of CoT prompts\\n\\nTips and Extensions\\n\\n\\nAutomatic Prompt Design\\n\\nAugmented Language Models')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Answer the following question in deatailed based on this context\n",
        "\n",
        "{context}\n",
        "\n",
        "Question : {question}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AAXNat0CluC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs (docs)  :\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "hQMY7SEDmKy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_docs = format_docs(similar_docs)"
      ],
      "metadata": {
        "id": "j379EJySmRrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_prompt_1 = prompt.format(context = formatted_docs , question = 'What are the differents Chain of Thought (CoT) Prompting ?')"
      ],
      "metadata": {
        "id": "xI4e5wjOmVZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_prompt_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlLXy8b8mlhM",
        "outputId": "45220619-3189-448d-a089-99ddc6d1b679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: \n",
            "For the given question try to generate a hypothetical answeronly generate the answer and nothing else:\n",
            "Question : What are the differents Chain of Thought (CoT) Prompting ?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_model.invoke(query_prompt_1)"
      ],
      "metadata": {
        "id": "TihLVBrFmnsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mQcoLC3zm4ML",
        "outputId": "6e45a1ae-36ef-4300-d2d9-e19a17303858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Different Chain of Thought (CoT) Prompting include:\\n1. Association Prompting\\n2. Comparison Prompting\\n3. Question Prompting\\n4. Analogy Prompting\\n5. Visualization Prompting\\n6. Cause and Effect Prompting.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZNchL6vm50e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}